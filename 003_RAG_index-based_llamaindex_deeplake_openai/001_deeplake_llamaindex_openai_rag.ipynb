{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이프라인 1: 문서 수집과 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "urls = [\n",
    "    \"https://github.com/VisDrone/VisDrone-Dataset\",\n",
    "    \"https://paperswithcode.com/dataset/visdrone\",\n",
    "    \"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Zhu_VisDrone-DET2018_The_Vision_Meets_Drone_Object_Detection_in_Image_Challenge_ECCVW_2018_paper.pdf\",\n",
    "    \"https://github.com/VisDrone/VisDrone2018-MOT-toolkit\",\n",
    "    \"https://en.wikipedia.org/wiki/Object_detection\",\n",
    "    \"https://en.wikipedia.org/wiki/Computer_vision\",\n",
    "    \"https://en.wikipedia.org/wiki/Convolutional_neural_network\",\n",
    "    \"https://en.wikipedia.org/wiki/Unmanned_aerial_vehicle\",\n",
    "    \"https://www.faa.gov/uas/\",\n",
    "    \"https://www.tensorflow.org/\",\n",
    "    \"https://pytorch.org/\",\n",
    "    \"https://keras.io/\",\n",
    "    \"https://arxiv.org/abs/1804.06985\",\n",
    "    \"https://arxiv.org/abs/2202.11983\",\n",
    "    \"https://motchallenge.net/\",\n",
    "    \"http://www.cvlibs.net/datasets/kitti/\",\n",
    "    \"https://www.dronedeploy.com/\",\n",
    "    \"https://www.dji.com/\",\n",
    "    \"https://arxiv.org/\",\n",
    "    \"https://openaccess.thecvf.com/\",\n",
    "    \"https://roboflow.com/\",\n",
    "    \"https://www.kaggle.com/\",\n",
    "    \"https://paperswithcode.com/\",\n",
    "    \"https://github.com/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(content):\n",
    "    content = re.sub(r'\\[\\d+\\]', '', content) # 참조 제거\n",
    "    content = re.sub(r'[^\\w\\s\\.]', '', content) # 문장부호 제거 (마침표 제외)\n",
    "    return content\n",
    "\n",
    "def fetch_and_clean(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() # 나쁜 응답에 대한 예외 발생 (예: 404)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        content = soup.find('div', {'class': 'mw-parser-output'}) or soup.find('div', {'id': 'content'})\n",
    "        if content is None:\n",
    "            return None\n",
    "\n",
    "        for section_title in ['References', 'Bibliography', 'External links', 'See also', 'Notes']:\n",
    "            section = content.find('span', id=section_title)\n",
    "            while section:\n",
    "                for sib in section.parent.find_next_siblings():\n",
    "                    sib.decompose()\n",
    "                section.parent.decompose()\n",
    "                section = content.find('span', id=section_title)\n",
    "            \n",
    "            text = content.get_text(separator=' ', strip=True)\n",
    "            text = clean_text(text)\n",
    "            return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching content from {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content(ones that were possible) written to files in the './data directory.\n"
     ]
    }
   ],
   "source": [
    "output_dir = './data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for url in urls:\n",
    "    article_name = url.split('/')[-1].replace('.html', '')\n",
    "    filename = os.path.join(output_dir, f'{article_name}.txt')\n",
    "\n",
    "    clean_article_text = fetch_and_clean(url)\n",
    "    if clean_article_text:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(clean_article_text)\n",
    "\n",
    "print(f\"Content(ones that were possible) written to files in the '{output_dir} directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_formatted(text):\n",
    "    # Wrap text to 80 characters width\n",
    "    wrapped_text = textwrap.fill(text, width=80)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF Abstract A new solution of fourdimensional vacuum General Relativity is presented. It describes the near horizon region of the extreme maximally spinning binary black hole system with two identical extreme Kerr black holes held in equilibrium by a massless strut. This is the first example of a nonsupersymmetric asymptotically flat near horizon extreme binary black hole geometry of two uncharged black holes. The black holes are corotating and the solution is uniquely specified by the mass. The binary extreme system has finite entropy. The distance between the black holes is fixed but there is a zerodistance limit where the objects collapse into one. This limiting geometry corresponds to the near horizon extreme Kerr NHEK black hole. Comments 1 figure Subjects High Energy Physics  Theory hepth  High Energy Astrophysical Phenomena astroph.HE General Relativity and Quantum Cosmology grqc Cite as arXiv1804.06985 hepth or arXiv1804.06985v1 hepth for this version httpsdoi.org10.48550arXiv.1804.06985 Focus to learn more arXivissued DOI via DataCite Related DOI  httpsdoi.org10.1140epjcs1005201971883 Focus to learn more DOIs linking to related resources Submission history From Maria J. Rodriguez  view email  v1 Thu 19 Apr 2018 031545 UTC 173 KB Fulltext links Access Paper View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF TeX Source Other Formats view license Current browse context hepth \\xa0prev  next\\xa0 new  recent  201804 Change to browse by astroph astroph.HE grqc References  Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation  loading... Data provided by Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer  What is the Explorer  Connected Papers Toggle Connected Papers  What is Connected Papers  Litmaps Toggle Litmaps  What is Litmaps  scite.ai Toggle scite Smart Citations  What are Smart Citations  Code Data Media Code Data and Media Associated with this Article alphaXiv Toggle alphaXiv  What is alphaXiv  Links to Code Toggle CatalyzeX Code Finder for Papers  What is CatalyzeX  DagsHub Toggle DagsHub  What is DagsHub  GotitPub Toggle Gotit.pub  What is GotitPub  Huggingface Toggle Hugging Face  What is Huggingface  Links to Code Toggle Papers with Code  What is Papers with Code  ScienceCast Toggle ScienceCast  What is ScienceCast  Demos Demos Replicate Toggle Replicate  What is Replicate  Spaces Toggle Hugging Face Spaces  What is Spaces  Spaces Toggle TXYZ.AI  What is TXYZ.AI  Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower  What are Influence Flowers  Core recommender toggle CORE Recommender  What is CORE  IArxiv recommender toggle IArxiv Recommender  What is IArxiv  Author Venue Institution Topic About arXivLabs arXivLabs experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness community excellence and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXivs community Learn more about arXivLabs . Which authors of this paper are endorsers  Disable MathJax  What is MathJax '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이프라인 2: 벡터 저장소 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_store_path = \"hub://secufibre/drone_v2\"\n",
    "dataset_path = \"hub://secufibre/drone_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:02<00:00, 40.80it/s]\n",
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://secufibre/drone_v2', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (90, 1)      str     None   \n",
      " metadata     json      (90, 1)      str     None   \n",
      " embedding  embedding  (90, 1536)  float32   None   \n",
      "    id        text      (90, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='b73ced47-88b3-4d67-9999-7bedd6d96266', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/1804.06985.txt', 'file_name': '1804.06985.txt', 'file_type': 'text/plain', 'file_size': 3798, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF Abstract A new solution of fourdimensional vacuum General Relativity is presented. It describes the near horizon region of the extreme maximally spinning binary black hole system with two identical extreme Kerr black holes held in equilibrium by a massless strut. This is the first example of a nonsupersymmetric asymptotically flat near horizon extreme binary black hole geometry of two uncharged black holes. The black holes are corotating and the solution is uniquely specified by the mass. The binary extreme system has finite entropy. The distance between the black holes is fixed but there is a zerodistance limit where the objects collapse into one. This limiting geometry corresponds to the near horizon extreme Kerr NHEK black hole. Comments 1 figure Subjects High Energy Physics  Theory hepth  High Energy Astrophysical Phenomena astroph.HE General Relativity and Quantum Cosmology grqc Cite as arXiv1804.06985 hepth or arXiv1804.06985v1 hepth for this version httpsdoi.org10.48550arXiv.1804.06985 Focus to learn more arXivissued DOI via DataCite Related DOI  httpsdoi.org10.1140epjcs1005201971883 Focus to learn more DOIs linking to related resources Submission history From Maria J. Rodriguez  view email  v1 Thu 19 Apr 2018 031545 UTC 173 KB Fulltext links Access Paper View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF TeX Source Other Formats view license Current browse context hepth \\xa0prev  next\\xa0 new  recent  201804 Change to browse by astroph astroph.HE grqc References  Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation  loading... Data provided by Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer  What is the Explorer  Connected Papers Toggle Connected Papers  What is Connected Papers  Litmaps Toggle Litmaps  What is Litmaps  scite.ai Toggle scite Smart Citations  What are Smart Citations  Code Data Media Code Data and Media Associated with this Article alphaXiv Toggle alphaXiv  What is alphaXiv  Links to Code Toggle CatalyzeX Code Finder for Papers  What is CatalyzeX  DagsHub Toggle DagsHub  What is DagsHub  GotitPub Toggle Gotit.pub  What is GotitPub  Huggingface Toggle Hugging Face  What is Huggingface  Links to Code Toggle Papers with Code  What is Papers with Code  ScienceCast Toggle ScienceCast  What is ScienceCast  Demos Demos Replicate Toggle Replicate  What is Replicate  Spaces Toggle Hugging Face Spaces  What is Spaces  Spaces Toggle TXYZ.AI  What is TXYZ.AI  Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower  What are Influence Flowers  Core recommender toggle CORE Recommender  What is CORE  IArxiv recommender toggle IArxiv Recommender  What is IArxiv  Author Venue Institution Topic About arXivLabs arXivLabs experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness community excellence and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXivs community Learn more about arXivLabs . Which authors of this paper are endorsers  Disable MathJax  What is MathJax ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='875f2a16-36fa-40e1-9f70-7b5acaf9b6d7', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/2202.11983.txt', 'file_name': '2202.11983.txt', 'file_type': 'text/plain', 'file_size': 4078, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Computer Science  Computer Vision and Pattern Recognition arXiv2202.11983 cs Submitted on 24 Feb 2022 Title GIAOTracker A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021 Authors Yunhao Du  Junfeng Wan  Yanyun Zhao  Binyu Zhang  Zhihang Tong  Junhao Dong View a PDF of the paper titled GIAOTracker A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021 by Yunhao Du and 5 other authors View PDF Abstract In recent years algorithms for multiple object tracking tasks have benefited from great progresses in deep models and video quality. However in challenging scenarios like drone videos they still suffer from problems such as small objects camera movements and view changes. In this paper we propose a new multiple object tracker which employs Global Information And some Optimizing strategies named GIAOTracker. It consists of three stages i.e. online tracking global link and postprocessing. Given detections in every frame the first stage generates reliable tracklets using information of camera motion object motion and object appearance. Then they are associated into trajectories by exploiting global clues and refined through four postprocessing methods. With the effectiveness of the three stages GIAOTracker achieves stateoftheart performance on the VisDrone MOT dataset and wins the 3rd place in the VisDrone2021 MOT Challenge. Comments ICCV 2021 Workshop Subjects Computer Vision and Pattern Recognition cs.CV Cite as arXiv2202.11983 cs.CV or arXiv2202.11983v1 cs.CV for this version httpsdoi.org10.48550arXiv.2202.11983 Focus to learn more arXivissued DOI via DataCite Journal\\xa0reference Proceedings of the IEEECVF International Conference on Computer Vision. 2021 28092819 Submission history From Yunhao Du  view email  v1 Thu 24 Feb 2022 094200 UTC 663 KB Fulltext links Access Paper View a PDF of the paper titled GIAOTracker A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021 by Yunhao Du and 5 other authors View PDF TeX Source Other Formats view license Current browse context cs.CV \\xa0prev  next\\xa0 new  recent  202202 Change to browse by cs References  Citations NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation  loading... Data provided by Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer  What is the Explorer  Connected Papers Toggle Connected Papers  What is Connected Papers  Litmaps Toggle Litmaps  What is Litmaps  scite.ai Toggle scite Smart Citations  What are Smart Citations  Code Data Media Code Data and Media Associated with this Article alphaXiv Toggle alphaXiv  What is alphaXiv  Links to Code Toggle CatalyzeX Code Finder for Papers  What is CatalyzeX  DagsHub Toggle DagsHub  What is DagsHub  GotitPub Toggle Gotit.pub  What is GotitPub  Huggingface Toggle Hugging Face  What is Huggingface  Links to Code Toggle Papers with Code  What is Papers with Code  ScienceCast Toggle ScienceCast  What is ScienceCast  Demos Demos Replicate Toggle Replicate  What is Replicate  Spaces Toggle Hugging Face Spaces  What is Spaces  Spaces Toggle TXYZ.AI  What is TXYZ.AI  Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower  What are Influence Flowers  Core recommender toggle CORE Recommender  What is CORE  Author Venue Institution Topic About arXivLabs arXivLabs experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness community excellence and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXivs community Learn more about arXivLabs . Which authors of this paper are endorsers  Disable MathJax  What is MathJax ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='727273cf-0947-4566-9904-b9e0cd13ca95', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Computer_vision.txt', 'file_name': 'Computer_vision.txt', 'file_type': 'text/plain', 'file_size': 54866, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Computerized information extraction from images Part of a series on Artificial intelligence AI Major goals Artificial general intelligence Intelligent agent Recursive selfimprovement Planning Computer vision General game playing Knowledge reasoning Natural language processing Robotics AI safety Approaches Machine learning Symbolic Deep learning Bayesian networks Evolutionary algorithms Hybrid intelligent systems Systems integration Applications Bioinformatics Deepfake Earth sciences Finance Generative AI Art Audio Music Government Healthcare Mental health Industry Translation Military Physics Projects Philosophy Artificial consciousness Chinese room Friendly AI Control problem  Takeover Ethics Existential risk Turing test Uncanny valley History Timeline Progress AI winter AI boom Glossary Glossary v t e Computer vision tasks include methods for acquiring  processing  analyzing  and understanding digital images  and extraction of highdimensional data from the real world in order to produce numerical or symbolic information e.g. in the form of decisions.  1   2   3   4  Understanding in this context signifies the transformation of visual images the input to the retina  into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry physics statistics and learning theory. The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. Image data can take many forms such as video sequences views from multiple cameras multidimensional data from a 3D scanner 3D point clouds from LiDaR sensors or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems. Subdisciplines of computer vision include scene reconstruction  object detection  event detection  activity recognition  video tracking  object recognition  3D pose estimation  learning indexing motion estimation  visual servoing  3D scene modeling and image restoration . Definition  edit  Computer vision is an interdisciplinary field that deals with how computers can be made to gain highlevel understanding from digital images or videos . From the perspective of engineering  it seeks to automate tasks that the human visual system can do.  5   6   7  Computer vision is concerned with the automatic extraction analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.  8  As a scientific discipline  computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms such as video sequences views from multiple cameras or multidimensional data from a medical scanner .  9  As a technological discipline computer vision seeks to apply its theories and models for the construction of computer vision systems. Machine vision refers to a systems engineering discipline especially in the context of factory automation. In more recent times the terms computer vision and machine vision have converged to a greater degree.  10  \\u200a13 History  edit  In the late 1960s computer vision began at universities that were pioneering artificial intelligence . It was meant to mimic the human visual system as a stepping stone to endowing robots with intelligent behavior.  11  In 1966 it was believed that this could be achieved through an undergraduate summer project  12  by attaching a camera to a computer and having it describe what it saw.  13   14  What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract threedimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today including extraction of edges from images labeling of lines nonpolyhedral and polyhedral modeling  representation of objects as interconnections of smaller structures optical flow  and motion estimation .  11  The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scalespace  the inference of shape from various cues such as shading  texture and focus and contour models known as snakes . Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields .  15  By the 1990s some of the previous research topics became more active than others. Research in projective 3D reconstructions led to better understanding of camera calibration . With the advent of optimization methods for camera calibration it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry . This led to methods for sparse 3D reconstructions of scenes from multiple images . Progress was made on the dense stereo correspondence problem and further multiview stereo techniques. At the same time variations of graph cut were used to solve image segmentation . This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images see Eigenface . Toward the end of the 1990s a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included imagebased rendering  image morphing  view interpolation panoramic image stitching and early lightfield rendering .  11  Recent work has seen the resurgence of feature based methods used in conjunction with machine learning techniques and complex optimization frameworks.  16   17  The advancement of Deep Learning techniques has brought further life to the field of computer vision. The accuracy of deep learning algorithms on several benchmark computer vision data sets for tasks ranging from classification  18  segmentation and optical flow has surpassed prior methods.  citation needed   19  Related fields  edit  Object detection in a photograph Solidstate physics  edit  Solidstate physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors  which detect electromagnetic radiation  which is typically in the form of either visible  infrared or ultraviolet light . The sensors are designed using quantum physics . The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process.  11  Also various measurement problems in physics can be addressed using computer vision for example motion in fluids. Neurobiology  edit  Simplified example of training a neural network in object detection The network is trained by multiple images that are known to depict starfish and sea urchins  which are correlated with nodes that represent visual features . The starfish match with a ringed texture and a star outline whereas most sea urchins match with a striped texture and oval shape. However the instance of a ringtextured sea urchin creates a weakly weighted association between them. Subsequent run of the network on an input image left  20  The network correctly detects the starfish. However the weakly weighted association between ringed texture and sea urchin also confers a weak signal to the latter from one of two intermediate nodes. In addition a shell that was not included in the training gives a weak signal for the oval shape also resulting in a weak signal for the sea urchin output. These weak signals may result in a false positive result for sea urchin. In reality textures and outlines would not be represented by single nodes but rather by associated weight patterns of multiple nodes. Neurobiology has greatly influenced the development of computer vision algorithms. Over the last century there has been an extensive study of eyes neurons and brain structures devoted to the processing of visual stimuli in both humans and various animals. This has led to a coarse yet convoluted description of how natural vision systems operate in order to solve certain visionrelated tasks. These results have led to a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems at different levels of complexity. Also some of the learningbased methods developed within computer vision  e.g. neural net and deep learning based image and feature analysis and classification have their background in neurobiology.  The Neocognitron  a neural network developed in the 1970s by Kunihiko Fukushima  is an early example of computer vision taking direct inspiration from neurobiology specifically the primary visual cortex . Some strands of computer vision research are closely related to the study of biological vision indeed just as many strands of AI research are closely tied with research into human intelligence and the use of stored knowledge to interpret integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision on the other hand develops and describes the algorithms implemented in software and hardware behind artificial vision systems. An interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.  21  Signal processing  edit  Yet another field related to computer vision is signal processing . Many methods for processing onevariable signals typically temporal signals can be extended in a natural way to the processing of twovariable signals or multivariable signals in computer vision. However because of the specific nature of images there are many methods developed within computer vision that have no counterpart in the processing of onevariable signals. Together with the multidimensionality of the signal this defines a subfield in signal processing as a part of computer vision. Robotic navigation  edit  Robot navigation sometimes deals with autonomous path planning or deliberation for robotic systems to navigate through an environment .  22  A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system acting as a vision sensor and providing highlevel information about the environment and the robot Visual computing  edit  This section is an excerpt from Visual computing .  edit  Visual computing is a generic term for all computer science disciplines dealing with images and 3D models  such as computer graphics  image processing  visualization  computer vision virtual and augmented reality  video processing  and computational visualistics . Visual computing also includes aspects of pattern recognition  human computer interaction machine learning and digital libraries. The core challenges are the acquisition processing analysis and rendering of visual information mainly images and video. Application areas include industrial quality control medical image processing and visualization surveying robotics multimedia systems virtual heritage special effects in movies and television and computer games. Other fields  edit  Besides the abovementioned views on computer vision many of the related research topics can also be studied from a purely mathematical point of view. For example many methods in computer vision are based on statistics  optimization or geometry . Finally a significant part of the field is devoted to the implementation aspect of computer vision how existing methods can be realized in various combinations of software and hardware or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion eCommerce inventory management patent search furniture and the beauty industry.  23  Distinctions  edit  The fields most closely related to computer vision are image processing  image analysis and machine vision . There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar something which can be interpreted as there is only one field with different names. On the other hand it appears to be necessary for research groups scientific journals conferences and companies to present or market themselves as belonging specifically to one of these fields and hence various characterizations which distinguish each of the fields from the others have been presented. In image processing the input and output are both images whereas in computer vision the input is an image or video and the output could be an enhanced image an analysis of the images content or even a systems behavior based on that analysis. Computer graphics produces image data from 3D models and computer vision often produces 3D models from image data.  24  There is also a trend towards a combination of the two disciplines e.g.  as explored in augmented reality . The following characterizations appear relevant but should not be taken as universally accepted Image processing and image analysis tend to focus on 2D images how to transform one image to another e.g.  by pixelwise operations such as contrast enhancement local operations such as edge extraction or noise removal or geometrical transformations such as rotating the image. This characterization implies that image processinganalysis neither requires assumptions nor produces interpretations about the image content. Computer vision includes 3D analysis from 2D images. This analyzes the 3D scene projected onto one or several images e.g.  how to reconstruct structure or other information about the 3D scene from one or several images. Computer vision often relies on more or less complex assumptions about the scene depicted in an image. Machine vision is the process of applying a range of technologies and methods to provide imagingbased automatic inspection process control and robot guidance  25  in industrial applications.  21  Machine vision tends to focus on applications mainly in manufacturing e.g.  visionbased robots and systems for visionbased inspection measurement or picking such as bin picking  26  . This implies that image sensor technologies and control theory often are integrated with the processing of image data to control a robot and that realtime processing is emphasized by means of efficient implementations in hardware and software. It also implies that external conditions such as lighting can be and are often more controlled in machine vision than they are in general computer vision which can enable the use of different algorithms. There is also a field called imaging which primarily focuses on the process of producing images but sometimes also deals with the processing and analysis of images. For example medical imaging includes substantial work on the analysis of image data in medical applications. Progress in convolutional neural networks CNNs has improved the accurate detection of disease in medical images particularly in cardiology pathology dermatology and radiology.  27  Finally pattern recognition is a field that uses various methods to extract information from signals in general mainly based on statistical approaches and artificial neural networks .  28  A significant part of this field is devoted to applying these methods to image data. Photogrammetry also overlaps with computer vision e.g. stereophotogrammetry vs. computer stereo vision . Applications  edit  Applications range from tasks such as industrial machine vision systems which say inspect bottles speeding by on a production line to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computervision applications computers are preprogrammed to solve a particular task but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for Learning 3D shapes has been a challenging task in computer vision. Recent advances in deep learning have enabled researchers to build models that are able to generate and reconstruct 3D shapes from single or multiview depth maps or silhouettes seamlessly and efficiently.  24  Automatic inspection e.g.  in manufacturing applications Assisting humans in identification tasks e.g. a species identification system  29  Controlling processes e.g.  an industrial robot  Detecting events  e.g.  for visual surveillance or people counting  e.g. in the restaurant industry  Interaction e.g.  as the input to a device for computerhuman interaction  monitoring agricultural crops e.g. an opensource vision transformers model  30  has been developed to help farmers automatically detect strawberry diseases with 98.4 accuracy.  31  Modeling objects or environments e.g.  medical image analysis or topographical modeling Navigation e.g.  by an autonomous vehicle or mobile robot  Organizing information e.g.  for indexing databases of images and image sequences. Tracking surfaces or planes in 3D coordinates for allowing Augmented Reality experiences. Medicine  edit  DARPA s Visual Media Reasoning concept video One of the most prominent application fields is medical computer vision  or medical image processing characterized by the extraction of information from image data to diagnose a patient . An example of this is the detection of tumours  arteriosclerosis or other malign changes and a variety of dental pathologies measurements of organ dimensions blood flow etc. are another example. It also supports medical research by providing new information e.g.  about the structure of the brain or the quality of medical treatments. Applications of computer vision in the medical area also include enhancement of images interpreted by humansultrasonic images or Xray images for exampleto reduce the influence of noise. Machine vision  edit  A second application area in computer vision is in industry sometimes called machine vision  where information is extracted for the purpose of supporting a production process. One example is quality control where details or final products are being automatically inspected in order to find defects. One of the most prevalent fields for such inspection is the Wafer industry in which every single Wafer is being measured and inspected for inaccuracies or defects to prevent a computer chip from coming to market in an unusable manner. Another example is a measurement of the position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in the agricultural processes to remove undesirable foodstuff from bulk material a process called optical sorting .  32  Military  edit  Military applications are probably one of the largest areas of computer vision  citation needed  . The obvious examples are the detection of enemy soldiers or vehicles and missile guidance . More advanced systems for missile guidance send the missile to an area rather than a specific target and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts such as battlefield awareness imply that various sensors including image sensors provide a rich set of information about a combat scene that can be used to support strategic decisions. In this case automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability. Autonomous vehicles  edit  Artists concept of Curiosity  an example of an uncrewed landbased vehicle. The stereo camera is mounted on top of the rover. One of the newer application areas is autonomous vehicles which include submersibles  landbased vehicles small robots with wheels cars or trucks aerial vehicles and unmanned aerial vehicles  UAV . The level of autonomy ranges from fully autonomous unmanned vehicles to vehicles where computervisionbased systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation e.g. for knowing where they are or mapping their environment  SLAM  for detecting obstacles. It can also be used for detecting certain taskspecific events e.g.  a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars cameras and LiDAR sensors in vehicles and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars . There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision e.g.  NASA s Curiosity and CNSA s Yutu2 rover. Tactile feedback  edit  Rubber artificial skin layer with the flexible structure for the shape estimation of microundulation surfaces Above is a silicon mold with a camera inside containing many different point markers. When this sensor is pressed against the surface the silicon deforms and the position of the point markers shifts. A computer can then take this data and determine how exactly the mold is pressed against the surface. This can be used to calibrate robotic hands in order to make sure they can grasp objects effectively. Materials such as rubber and silicon are being used to create sensors that allow for applications such as detecting microundulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins are being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data on imperfections on a very large surface.  33  Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.  34  Other application areas include Support of visual effects creation for cinema and broadcast e.g.  camera tracking match moving. Surveillance . Driver drowsiness detection  35   36   37  Tracking and counting organisms in the biological sciences  38  Typical tasks  edit  Each of the application areas described above employ a range of computer vision tasks more or less welldefined measurement problems or processing problems which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below. Computer vision tasks include methods for acquiring  processing  analyzing and understanding digital images and extraction of highdimensional data from the real world in order to produce numerical or symbolic information e.g.  in the forms of decisions.  1   2   3   4  Understanding in this context means the transformation of visual images the input of the retina into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry physics statistics and learning theory.  39  Recognition  edit  The classical problem in computer vision image processing and machine vision is that of determining whether or not the image data contains some specific object feature or activity. Different varieties of recognition problem are described in the literature.  40  Object recognition also called object classification \\xa0 one or several prespecified or learned objects or object classes can be recognized usually together with their 2D positions in the image or 3D poses in the scene. Blippar Google Goggles  and LikeThat provide standalone programs that illustrate this functionality. Identification  an individual instance of an object is recognized. Examples include identification of a specific persons face or fingerprint identification of handwritten digits  or the identification of a specific vehicle. Detection  the image data are scanned for specific objects along with their locations. Examples include the detection of an obstacle in the cars field of view and possible abnormal cells or tissues in medical images or the detection of a vehicle in an automatic road toll system. Detection based on relatively simple and fast computations is sometimes used for finding smaller regions of interesting image data which can be further analyzed by more computationally demanding techniques to produce a correct interpretation. Currently the best algorithms for such tasks are based on convolutional neural networks . An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge  this is a benchmark in object classification and detection with millions of images and 1000 object classes used in the competition.  41  Performance of convolutional neural networks on the ImageNet tests is now close to that of humans.  41  The best algorithms still struggle with objects that are small or thin such as a small ant on the stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters an increasingly common phenomenon with modern digital cameras. By contrast those kinds of images rarely trouble humans. Humans however tend to have trouble with other issues. For example they are not good at classifying objects into finegrained classes such as the particular breed of dog or species of bird whereas convolutional neural networks handle this with ease.  citation needed  Several specialized tasks based on recognition exist such as Contentbased image retrieval  finding all images in a larger set of images which have a specific content. The content can be specified in different ways for example in terms of similarity relative to a target image give me all images similar to image X by utilizing reverse image search techniques or in terms of highlevel search criteria given as text input give me all images which contain many houses are taken during winter and have no cars in them. Computer vision for people counter purposes in public places malls shopping centers Pose estimation  estimating the position or orientation of a specific object relative to the camera. An example application for this technique would be assisting a robot arm in retrieving objects from a conveyor belt in an assembly line situation or picking parts from a bin. Optical character recognition OCR\\xa0 identifying characters in images of printed or handwritten text usually with a view to encoding the text in a format more amenable to editing or indexing  e.g. ASCII . A related task is reading of 2D codes such as data matrix and QR codes. Facial recognition  a technology that enables the matching of faces in digital images or video frames to a face database which is now widely used for mobile phone facelock smart door locking etc.  42  Emotion recognition  a subset of facial recognition emotion recognition refers to the process of classifying human emotions. Psychologists caution however that internal emotions cannot be reliably detected from faces.  43  Shape Recognition Technology SRT in people counter systems differentiating human beings head and shoulder patterns from objects. Human activity recognition  deals with recognizing the activity from a series of video frames such as if the person is picking up an object or walking. Motion analysis  edit  Several tasks relate to motion estimation where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene or even of the camera that produces the images. Examples of such tasks are Egomotion  determining the 3D rigid motion rotation and translation of the camera from an image sequence produced by the camera. Tracking  following the movements of a usually smaller set of interest points or objects  e.g.  vehicles objects humans or other organisms  38   in the image sequence. This has vast industry applications as most highrunning machinery can be monitored in this way. Optical flow  to determine for each point in the image how that point is moving relative to the image plane i.e.  its apparent motion. This motion is a result of both how the corresponding 3D point is moving in the scene and how the camera is moving relative to the scene. Scene reconstruction  edit  Given one or typically more images of a scene or a video scene reconstruction aims at computing a 3D model of the scene. In the simplest case the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning and related processing algorithms is enabling rapid advances in this field. Gridbased 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.  24  Image restoration  edit  Image restoration comes into the picture when the original image is degraded or damaged due to some external factors like lens wrong positioning transmission interference low lighting or motion blurs etc. which is referred to as noise. When the images are degraded or damaged the information to be extracted from them also gets damaged. Therefore we need to recover or restore the image as it was intended to be. The aim of image restoration is the removal of noise sensor noise motion blur etc. from images. The simplest possible approach for noise removal is various types of filters such as lowpass filters or median filters. More sophisticated methods assume a model of how the local image structures look to distinguish them from noise. By first analyzing the image data in terms of the local image structures such as lines or edges and then controlling the filtering based on local information from the analysis step a better level of noise removal is usually obtained compared to the simpler approaches. An example in this field is inpainting . System methods  edit  The organization of a computer vision system is highly applicationdependent. Some systems are standalone applications that solve a specific measurement or detection problem while others constitute a subsystem of a larger design which for example also contains subsystems for control of mechanical actuators planning information databases manmachine interfaces etc. The specific implementation of a computer vision system also depends on whether its functionality is prespecified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are however typical functions that are found in many computer vision systems. Image acquisition  A digital image is produced by one or several image sensors  which besides various types of lightsensitive cameras include range sensors  tomography devices radar ultrasonic cameras etc. Depending on the type of sensor the resulting image data is an ordinary 2D image a 3D volume or an image sequence. The pixel values typically correspond to light intensity in one or several spectral bands gray images or colour images but can also be related to various physical measures such as depth absorption or reflectance of sonic or electromagnetic waves or magnetic resonance imaging .  32  Preprocessing  Before a computer vision method can be applied to image data in order to extract some specific piece of information it is usually necessary to process the data in order to ensure that it satisfies certain assumptions implied by the method. Examples are Resampling to ensure that the image coordinate system is correct. Noise reduction to ensure that sensor noise does not introduce false information. Contrast enhancement to ensure that relevant information can be detected. Scale space representation to enhance image structures at locally appropriate scales. Feature extraction  Image features at various levels of complexity are extracted from the image data.  32  Typical examples of such features are Lines edges and ridges . Localized interest points such as corners  blobs or points. More complex features may be related to texture shape or motion. Detection  segmentation  At some point in the processing a decision is made about which image points or regions of the image are relevant for further processing.  32  Examples are Selection of a specific set of interest points. Segmentation of one or multiple image regions that contain a specific object of interest. Segmentation of image into nested scene architecture comprising foreground object groups single objects or salient object  44  parts also referred to as spatialtaxon scene hierarchy  45  while the visual salience is often implemented as spatial and temporal attention . Segmentation or cosegmentation of one or multiple videos into a series of perframe foreground masks while maintaining its temporal semantic continuity.  46   47  Highlevel processing  At this step the input is typically a small set of data for example a set of points or an image region which is assumed to contain a specific object.  32  The remaining processing deals with for example Verification that the data satisfies modelbased and applicationspecific assumptions. Estimation of applicationspecific parameters such as object pose or object size. Image recognition  classifying a detected object into different categories. Image registration  comparing and combining two different views of the same object. Decision making Making the final decision required for the application  32  for example Passfail on automatic inspection applications. Matchnomatch in recognition applications. Flag for further human review in medical military security and recognition applications. Imageunderstanding systems  edit  Imageunderstanding systems IUS include three levels of abstraction as follows low level includes image primitives such as edges texture elements or regions intermediate level includes boundaries surfaces and volumes and high level includes objects scenes or events. Many of these requirements are entirely topics for further research. The representational requirements in the designing of IUS for these levels are representation of prototypical concepts concept organization spatial knowledge temporal knowledge scaling and description by comparison and differentiation. While inference refers to the process of deriving new not explicitly represented facts from currently known facts control refers to the process that selects which of the many inference search and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are search and hypothesis activation matching and hypothesis testing generation and use of expectations change and focus of attention certainty and strength of belief inference and goal satisfaction.  48  Hardware  edit  A 2020 model iPad Pro with a LiDAR sensor There are many kinds of computer vision systems however all of them contain these basic elements a power source at least one image acquisition device camera ccd etc. a processor and control and communication cables or some kind of wireless interconnection mechanism. In addition a practical vision system contains software as well as a display in order to monitor the system. Vision systems for inner spaces as most industrial ones contain an illumination system and may be placed in a controlled environment. Furthermore a completed system includes many accessories such as camera supports cables and connectors. Most computer vision systems use visiblelight cameras passively viewing a scene at frame rates of at most 60 frames per second usually far slower. A few computer vision systems use imageacquisition hardware with active illumination or something other than visible light or both such as structuredlight 3D scanners  thermographic cameras  hyperspectral imagers  radar imaging  lidar scanners magnetic resonance images  sidescan sonar  synthetic aperture sonar  etc. Such hardware captures images that are then processed often using the same computer vision algorithms used to process visiblelight images. While traditional broadcast and consumer video systems operate at a rate of 30 frames per second advances in digital signal processing and consumer graphics hardware has made highspeed image acquisition processing and display possible for realtime systems on the order of hundreds to thousands of frames per second. For applications in robotics fast realtime video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a highspeed projector fast image acquisition allows 3D measurement and feature tracking to be realized.  49  Egocentric vision systems are composed of a wearable camera that automatically take pictures from a firstperson perspective. As of 2016 vision processing units are emerging as a new class of processors to complement CPUs and graphics processing units GPUs in this role.  50  See also  edit  Chessboard detection Computational imaging Computational photography Computer audition Egocentric vision Machine vision glossary Space mapping TeknomoFernandez algorithm Vision science Visual agnosia Visual perception Visual system Lists  edit  Outline of computer vision List of emerging technologies Outline of artificial intelligence References  edit   a b Reinhard Klette 2014. Concise Computer Vision . Springer. ISBN 9781447163206 .  a b Linda G. Shapiro  George C. Stockman 2001. Computer Vision . Prentice Hall. ISBN 9780130307965 .  a b Tim Morris 2004. Computer Vision and Image Processing . Palgrave Macmillan. ISBN 9780333994511 .  a b Bernd Jähne Horst Haußecker 2000. Computer Vision and Applications A Guide for Students and Practitioners . Academic Press. ISBN 9780130851987 .  Dana H. Ballard Christopher M. Brown 1982. Computer Vision . Prentice Hall. ISBN 9780131653160 .  Huang T. 19961119. Vandoni Carlo E ed.. Computer Vision\\xa0 Evolution And Promise PDF . 19th CERN School of Computing . Geneva CERN. pp. 21 25. doi  10.5170CERN1996008.21 . ISBN 9789290830955 . Archived PDF from the original on 20180207.  Milan Sonka Vaclav Hlavac Roger Boyle 2008. Image Processing Analysis and Machine Vision . Thomson. ISBN 9780495082521 .  httpwww.bmva.orgvisionoverview Archived 20170216 at the Wayback Machine The British Machine Vision Association and Society for Pattern Recognition Retrieved February 20 2017  Murphy Mike 13 April 2017. Star Treks tricorder medical scanner just got closer to becoming a reality . Archived from the original on 2 July 2017 . Retrieved 18 July 2017 .  Computer Vision Principles algorithms Applications Learning   5th Edition by E.R. Davies Academic Press Elsevier 2018 ISBN 9780128092842  a b c d Richard Szeliski 30 September 2010. Computer Vision Algorithms and Applications . Springer Science  Business Media. pp. 10 16. ISBN 9781848829350 .  Sejnowski Terrence J. 2018. The deep learning revolution . Cambridge Massachusetts London England The MIT Press. p.\\xa028. ISBN 9780262038034 .  Papert Seymour 19660701. The Summer Vision Project. MIT AI Memos 1959  2004 . hdl  1721.16125 .  Margaret Ann Boden 2006. Mind as Machine A History of Cognitive Science . Clarendon Press. p.\\xa0781. ISBN 9780199543168 .  Takeo Kanade 6 December 2012. ThreeDimensional Machine Vision . Springer Science  Business Media. ISBN 9781461319818 .  Nicu Sebe Ira Cohen Ashutosh Garg Thomas S. Huang 3 June 2005. Machine Learning in Computer Vision . Springer Science  Business Media. ISBN 9781402032745 .  William Freeman Pietro Perona Bernhard Scholkopf 2008. Guest Editorial Machine Learning for Computer Vision . International Journal of Computer Vision . 77 1 1. doi  10.1007s1126300801277 . hdl  21.111160000000330FBC . ISSN 15731405 .  LeCun Yann Bengio Yoshua Hinton Geoffrey 2015. Deep Learning PDF . Nature . 521 7553 436 444. Bibcode  2015Natur.521..436L . doi  10.1038nature14539 . PMID 26017442 . S2CID 3074096 .  Jiao Licheng Zhang Fan Liu Fang Yang Shuyuan Li Lingling Feng Zhixi Qu Rong 2019. A Survey of Deep LearningBased Object Detection. IEEE Access . 7  128837 128868. arXiv  1907.09408 . Bibcode  2019IEEEA...7l8837J . doi  10.1109ACCESS.2019.2939201 . S2CID 198147317 .  Ferrie C. Kaiser S. 2019. Neural Networks for Babies . Sourcebooks. ISBN 9781492671206 .  a b Steger Carsten Markus Ulrich Christian Wiedemann 2018. Machine Vision Algorithms and Applications 2nd\\xa0ed.. Weinheim WileyVCH . p.\\xa01. ISBN 9783527413652 . Archived from the original on 20230315 . Retrieved 20180130 .  Murray Don and Cullen Jennings.  Stereo visionbased mapping and navigation for mobile robots Archived 20201031 at the Wayback Machine . Proceedings of International Conference on Robotics and Automation. Vol. 2. IEEE 1997.  Andrade Norberto Almeida. Computational Vision and Business Intelligence in the Beauty Segment  An Analysis through Instagram PDF . Journal of Marketing Management . American Research Institute for Policy Development . Retrieved 11 March 2024 .  a b c Soltani A. A. Huang H. Wu J. Kulkarni T. D. Tenenbaum J. B. 2017. Synthesizing 3D Shapes via Modeling Multiview Depth Maps and Silhouettes with Deep Generative Networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition CVPR . pp. 1511 1519. doi  10.1109CVPR.2017.269 . hdl  1721.1126644 . ISBN 9781538604571 . S2CID 31373273 .  Turek Fred June 2011. Machine Vision Fundamentals How to Make Robots See. NASA Tech Briefs Magazine . 35 6. pages 6062  The Future of Automated Random Bin Picking . Archived from the original on 20180111 . Retrieved 20180110 .  Esteva Andre Chou Katherine Yeung Serena Naik Nikhil Madani Ali Mottaghi Ali Liu Yun Topol Eric Dean Jeff Socher Richard 20210108. Deep learningenabled medical computer vision . npj Digital Medicine . 4 1 5. doi  10.1038s41746020003762 . ISSN 23986352 . PMC 7794558 . PMID 33420381 .  Chervyakov N. I. Lyakhov P. A. Deryabin M. A. Nagornov N. N. Valueva M. V. Valuev G. V. 2020. Residue Number SystemBased Solution for Reducing the Hardware Cost of a Convolutional Neural Network. Neurocomputing . 407  439 453. doi  10.1016j.neucom.2020.04.018 . S2CID 219470398 . Convolutional neural networks CNNs represent deep learning architectures that are currently used in a wide range of applications including computer vision speech recognition identification of albuminous sequences in bioinformatics production control time series analysis in finance and many others.  Wäldchen Jana Mäder Patrick 20170107. Plant Species Identification Using Computer Vision Techniques A Systematic Literature Review . Archives of Computational Methods in Engineering . 25 2 507 543. doi  10.1007s118310169206z . ISSN 11343060 . PMC 6003396 . PMID 29962832 .  Aghamohammadesmaeilketabforoosh Kimia Nikan Soodeh Antonini Giorgio Pearce Joshua M. January 2024. Optimizing Strawberry Disease and Quality Detection with Vision Transformers and AttentionBased Convolutional Neural Networks . Foods . 13 12 1869. doi  10.3390foods13121869 . ISSN 23048158 . PMC 11202458 . PMID 38928810 .  New AI model developed at Western detects strawberry diseases takes aim at waste . London . 20240913 . Retrieved 20240919 .  a b c d e f E. Roy Davies 2005. Machine Vision Theory Algorithms Practicalities . Morgan Kaufmann. ISBN 9780122060939 .  Ando Mitsuhito Takei Toshinobu Mochiyama Hiromi 20200303. Rubber artificial skin layer with flexible structure for shape estimation of microundulation surfaces . ROBOMECH Journal . 7 1 11. doi  10.1186s40648020001590 . ISSN 21974225 .  Choi Seunghyun Tahara Kenji 20200312. Dexterous object manipulation by a multifingered robotic hand with visualtactile fingertip sensors . ROBOMECH Journal . 7 1 14. doi  10.1186s40648020001625 . ISSN 21974225 .  Garg Hitendra 20200229. Drowsiness Detection of a Driver using Conventional Computer Vision Application . 2020 International Conference on Power Electronics  IoT Applications in Renewable Energy and its Control PARC . pp. 50 53. doi  10.1109PARC49193.2020.236556 . ISBN 9781728165752 . S2CID 218564267 . Archived from the original on 20220627 . Retrieved 20221106 .  Hasan Fudail Kashevnik Alexey 20210514. StateoftheArt Analysis of Modern Drowsiness Detection Algorithms Based on Computer Vision . 2021 29th Conference of Open Innovations Association FRUCT . pp. 141 149. doi  10.23919FRUCT52173.2021.9435480 . ISBN 9789526924458 . S2CID 235207036 . Archived from the original on 20220627 . Retrieved 20221106 .  Balasundaram A Ashokkumar S Kothandaraman D kora SeenaNaik Sudarshan E Harshaverdhan A 20201201. Computer vision based fatigue detection using facial parameters . IOP Conference Series Materials Science and Engineering . 981 2 022005. Bibcode  2020MSE..981b2005B . doi  10.10881757899x9812022005 . ISSN 1757899X . S2CID 230639179 .  a b Bruijning Marjolein Visser Marco D. Hallmann Caspar A. Jongejans Eelke Golding Nick 2018. trackdem Automated particle tracking to obtain population counts and size distributions from videos in r . Methods in Ecology and Evolution . 9 4 965 973. Bibcode  2018MEcEv...9..965B . doi  10.11112041210X.12975 . hdl  2066184075 . ISSN 2041210X .  David A. Forsyth Jean Ponce 2003. Computer Vision A Modern Approach . Prentice Hall. ISBN 9780130851987 .  Forsyth David Ponce Jean 2012. Computer vision a modern approach . Pearson.  a b Russakovsky Olga Deng Jia Su Hao Krause Jonathan Satheesh Sanjeev Ma Sean Huang Zhiheng Karpathy Andrej Khosla Aditya Bernstein Michael Berg Alexander C. December 2015. ImageNet Large Scale Visual Recognition Challenge . International Journal of Computer Vision . 115 3 211 252. arXiv  1409.0575 . doi  10.1007s112630150816y . hdl  1721.1104944 . ISSN 09205691 . S2CID 2930547 . Archived from the original on 20230315 . Retrieved 20201120 .  Quinn Arthur 20221009. AI Image Recognition Inevitable Trending of Modern Lifestyle . TopTen.ai . Archived from the original on 20221202 . Retrieved 20221223 .  Barrett Lisa Feldman Adolphs Ralph Marsella Stacy Martinez Aleix M. Pollak Seth D. July 2019. Emotional Expressions Reconsidered Challenges to Inferring Emotion From Human Facial Movements . Psychological Science in the Public Interest . 20 1 1 68. doi  10.11771529100619832930 . ISSN 15291006 . PMC 6640856 . PMID 31313636 .  A. Maity 2015. Improvised Salient Object Detection and Manipulation. arXiv  1511.02999  cs.CV .  Barghout Lauren.  Visual Taxometric Approach to Image Segmentation Using FuzzySpatial Taxon Cut Yields Contextually Relevant Regions Archived 20181114 at the Wayback Machine . Information Processing and Management of Uncertainty in KnowledgeBased Systems. Springer International Publishing 2014.  Liu Ziyi Wang Le Hua Gang Zhang Qilin Niu Zhenxing Wu Ying Zheng Nanning 2018. Joint Video Object Discovery and Segmentation by Coupled Dynamic Markov Networks PDF . IEEE Transactions on Image Processing . 27 12 5840 5853. Bibcode  2018ITIP...27.5840L . doi  10.1109tip.2018.2859622 . ISSN 10577149 . PMID 30059300 . S2CID 51867241 . Archived from the original PDF on 20180907 . Retrieved 20180914 .  Wang Le Duan Xuhuan Zhang Qilin Niu Zhenxing Hua Gang Zheng Nanning 20180522. SegmentTube SpatioTemporal Action Localization in Untrimmed Videos with PerFrame Segmentation PDF . Sensors . 18 5 1657. Bibcode  2018Senso..18.1657W . doi  10.3390s18051657 . ISSN 14248220 . PMC 5982167 . PMID 29789447 . Archived PDF from the original on 20180907.  Shapiro Stuart C. 1992. Encyclopedia of Artificial Intelligence Volume 1 . New York John Wiley  Sons Inc. pp. 643 646. ISBN 9780471503064 .  Kagami Shingo 2010. Highspeed vision systems and projectors for realtime perception of the world. 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition  Workshops . Vol.\\xa02010. pp. 100 107. doi  10.1109CVPRW.2010.5543776 . ISBN 9781424470297 . S2CID 14111100 .  Seth Colaner January 3 2016. A Third Type Of Processor For VRAR Movidius Myriad 2 VPU . www.tomshardware.com . Archived from the original on March 15 2023 . Retrieved May 3 2016 . Further reading  edit  James E. Dobson 2023. The Birth of Computer Vision . University of Minnesota Press. ISBN 9781517914219 . David Marr 1982. Vision . W. H. Freeman and Company. ISBN 9780716712848 . Azriel Rosenfeld Avinash Kak 1982. Digital Picture Processing . Academic Press. ISBN 9780125973014 . Barghout Lauren Lawrence W. Lee 2003. Perceptual information processing system . U.S. Patent Application 10618543. ISBN 9780262081597 . Berthold K.P. Horn 1986. Robot Vision . MIT Press. ISBN 9780262081597 . Michael C. Fairhurst 1988. Computer Vision for robotic systems . Prentice Hall. ISBN 9780131669192 . Olivier Faugeras 1993. ThreeDimensional Computer Vision A Geometric Viewpoint . MIT Press. ISBN 9780262061582 . Tony Lindeberg 1994. ScaleSpace Theory in Computer Vision . Springer. ISBN 9780792394181 . James L. Crowley Henrik I. Christensen eds. 1995. Vision as Process . SpringerVerlag. ISBN 9783540581437 . Gösta H. Granlund Hans Knutsson 1995. Signal Processing for Computer Vision . Kluwer Academic Publisher. ISBN 9780792395300 . Reinhard Klette Karsten Schluens Andreas Koschan 1998. Computer Vision  ThreeDimensional Data from Images . Springer Singapore. ISBN 9789813083714 . Emanuele Trucco Alessandro Verri 1998. Introductory Techniques for 3D Computer Vision . Prentice Hall. ISBN 9780132611084 . Bernd Jähne 2002. Digital Image Processing . Springer. ISBN 9783540677543 . Richard Hartley and Andrew Zisserman 2003. Multiple View Geometry in Computer Vision . Cambridge University Press. ISBN 9780521540513 . Gérard Medioni Sing Bing Kang 2004. Emerging Topics in Computer Vision . Prentice Hall. ISBN 9780131013667 . R. Fisher K DawsonHowe A. Fitzgibbon C. Robertson E. Trucco 2005. Dictionary of Computer Vision and Image Processing . John Wiley. ISBN 9780470015261 . Nikos Paragios and Yunmei Chen and Olivier Faugeras 2005. Handbook of Mathematical Models in Computer Vision . Springer. ISBN 9780387263717 . Wilhelm Burger Mark J. Burge 2007. Digital Image Processing An Algorithmic Approach Using Java . Springer . ISBN 9781846283796 . Archived from the original on 20140517 . Retrieved 20070613 . Pedram Azad Tilo Gockel Rüdiger Dillmann 2008. Computer Vision  Principles and Practice . Elektor International Media BV. ISBN 9780905705712 . Richard Szeliski 2010. Computer Vision Algorithms and Applications . SpringerVerlag. ISBN 9781848829343 . J. R. Parker 2011. Algorithms for Image Processing and Computer Vision 2nd\\xa0ed.. Wiley. ISBN 9780470643853 . Richard J. Radke 2013. Computer Vision for Visual Effects . Cambridge University Press. ISBN 9780521766876 . Nixon Mark Aguado Alberto 2019. Feature Extraction and Image Processing for Computer Vision 4th\\xa0ed.. Academic Press. ISBN 9780128149768 . External links  edit  USC Iris computer vision conference list Computer vision papers on the web  a complete list of papers of the most relevant computer vision conferences. Computer Vision Online Archived 20111130 at the Wayback Machine  news source code datasets and job offers related to computer vision CVonline  Bob Fishers Compendium of Computer Vision. British Machine Vision Association  supporting computer vision research within the UK via the BMVC and MIUA conferences  Annals of the BMVA opensource journal BMVA Summer School and oneday meetings Computer Vision Container Joe Hoeller GitHub Widely adopted opensource container for GPU accelerated computer vision applications. Used by researchers universities private companies as well as the U.S. Govt. v t e Computer vision Categories Datasets Digital geometry Commercial systems Feature detection Geometry Image sensor technology Learning Morphology Motion analysis Noise reduction techniques Recognition and categorization Research infrastructure Researchers Segmentation Software Technologies Computer stereo vision Motion capture Object recognition 3D object recognition Applications 3D reconstruction 3D reconstruction from multiple images 2D to 3D conversion Gaussian splatting Neural radiance field Shape from focus Simultaneous localization and mapping Structure from motion View synthesis Visual hull 4D reconstruction Free viewpoint television Volumetric capture 3D pose estimation Activity recognition Audiovisual speech recognition Automatic image annotation Automatic numberplate recognition Automated species identification Augmented reality Bioimage informatics Blob detection Computeraided diagnosis Contentbased image retrieval Reverse image search Eye tracking Face recognition Foreground detection Gesture recognition Image denoising Image restoration Landmark detection Medical image computing Object detection Moving object detection Small object detection Optical character recognition Pose tracking Remote sensing Robotic mapping Autonomous vehicles Video content analysis Video motion analysis Video surveillance Video tracking Main category v t e Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic computing Pattern recognition Ricci calculus Computational learning theory Inductive bias Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras scikitlearn Theano JAX Flux.jl MindSpore Portals Computer programming Technology Authority control databases  National United States France BnF data Czech Republic Israel', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9e6eafd4-83c9-4ba1-ac73-e7632c52f6af', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Convolutional_neural_network.txt', 'file_name': 'Convolutional_neural_network.txt', 'file_type': 'text/plain', 'file_size': 107972, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='A type of artificial neural network Part of a series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Semisupervised learning Selfsupervised learning Reinforcement learning Metalearning Online learning Batch learning Curriculum learning Rulebased learning Neurosymbolic AI Neuromorphic engineering Quantum machine learning Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning  classification  regression  Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest k NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine RVM Support vector machine SVM Clustering BIRCH CURE Hierarchical k means Fuzzy Expectationmaximization EM DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD tSNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC k NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network UNet LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM ECRAM Reinforcement learning Qlearning SARSA Temporal difference TD Multiagent Selfplay Learning with humans Active learning Crowdsourcing Humanintheloop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Biasvariance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Topological deep learning Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machinelearning research List of datasets in computer vision and image processing Outline of machine learning v t e A convolutional neural network  CNN  is a type of feedforward neural network that learns features via filter or kernel optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text images and audio.  1  Convolutionbased networks are the defacto standard in deep learning based approaches to computer vision  2  and image processing and have only recently been replacedin some casesby newer deep learning architectures such as the transformer . Vanishing gradients and exploding gradients seen during backpropagation in earlier neural networks are prevented by the regularization that comes from using shared weights over fewer connections.  3   4  For example for each neuron in the fullyconnected layer 10000 weights would be required for processing an image sized 100  100 pixels. However applying cascaded convolution or crosscorrelation kernels  5   6  only 25 weights for each convolutional layer are required to process 5x5sized tiles.  7   8  Higherlayer features are extracted from wider context windows compared to lowerlayer features. Some applications of CNNs include image and video recognition   9  recommender systems   10  image classification  image segmentation  medical image analysis  natural language processing   11  braincomputer interfaces   12  and financial time series .  13  CNNs are also known as shift invariant or space invariant artificial neural networks  based on the sharedweight architecture of the convolution kernels or filters that slide along input features and provide translation equivariant responses known as feature maps.  14   15  Counterintuitively most convolutional neural networks are not invariant to translation  due to the downsampling operation they apply to the input.  16  Feedforward neural networks are usually fully connected networks that is each neuron in one layer is connected to all neurons in the next layer . The full connectivity of these networks makes them prone to overfitting data. Typical ways of regularization or preventing overfitting include penalizing parameters during training such as weight decay or trimming connectivity skipped connections dropout etc. Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorlypopulated set.  17  Convolutional networks were inspired by biological processes  18   19   20   21  in that the connectivity pattern between neurons resembles the organization of the animal visual cortex . Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field . The receptive fields of different neurons partially overlap such that they cover the entire visual field. CNNs use relatively little preprocessing compared to other image classification algorithms . This means that the network learns to optimize the filters or kernels through automated learning whereas in traditional algorithms these filters are handengineered . This simplifies and automates the process enhancing efficiency and scalability overcoming humanintervention bottlenecks. Architecture  edit  Comparison of the LeNet and AlexNet convolution pooling and dense layers AlexNet image size should be 2272273 instead of 2242243 so the math will come out right. The original paper said different numbers but Andrej Karpathy the head of computer vision at Tesla said it should be 2272273 he said Alex did not describe why he put 2242243. The next convolution should be 1111 with stride 4 555596 instead of 545496. It would be calculated for example as input width 227  kernel width 11  stride 4  1  227  11  4  1  55. Since the kernel output is the same length as width its area is 5555. Main article Layer deep learning A convolutional neural network consists of an input layer hidden layers and an output layer. In a convolutional neural network the hidden layers include one or more layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layers input matrix. This product is usually the Frobenius inner product  and its activation function is commonly ReLU . As the convolution kernel slides along the input matrix for the layer the convolution operation generates a feature map which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers  fully connected layers and normalization layers.\\nHere it should be noted how close a convolutional neural network is to a matched filter .  22  Convolutional layers  edit  In a CNN the input is a tensor with shape number of inputs  input height  input width  input channels  After passing through a convolutional layer the image becomes abstracted to a feature map also called an activation map with shape number of inputs  feature map height  feature map width  feature map channels . Convolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus.  23  Each convolutional neuron processes data only for its receptive field . 1D convolutional neural network feed forward example Although fully connected feedforward neural networks can be used to learn features and classify data this architecture is generally impractical for larger inputs e.g. highresolution images which would require massive numbers of neurons because each pixel is a relevant input feature. A fully connected layer for an image of size 100  100 has 10000 weights for each neuron in the second layer. Convolution reduces the number of free parameters allowing the network to be deeper.  7  For example using a 5  5 tiling region each with the same shared weights requires only 25 neurons. Using shared weights means there are many fewer parameters which helps avoid the vanishing gradients and exploding gradients problems seen during backpropagation in earlier neural networks.  3   4  To speed processing standard convolutional layers can be replaced by depthwise separable convolutional layers  24  which are based on a depthwise convolution followed by a pointwise convolution. The depthwise convolution is a spatial convolution applied independently over each channel of the input tensor while the pointwise convolution is a standard convolution restricted to the use of 1  1 displaystyle 1times 1 kernels. Pooling layers  edit  Convolutional networks may include local andor global pooling layers along with traditional convolutional layers. Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters tiling sizes such as 2  2 are commonly used. Global pooling acts on all the neurons of the feature map.  25   26  There are two common types of pooling in popular use max and average. Max pooling uses the maximum value of each local cluster of neurons in the feature map  27   28  while average pooling takes the average value. Fully connected layers  edit  Fully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional multilayer perceptron neural network MLP. The flattened matrix goes through a fully connected layer to classify the images. Receptive field  edit  In neural networks each neuron receives input from some number of locations in the previous layer. In a convolutional layer each neuron receives input from only a restricted area of the previous layer called the neurons receptive field . Typically the area is a square e.g. 5 by 5 neurons. Whereas in a fully connected layer the receptive field is the entire previous layer . Thus in each convolutional layer each neuron takes input from a larger area in the input than previous layers. This is due to applying the convolution over and over which takes the value of a pixel into account as well as its surrounding pixels. When using dilated layers the number of pixels in the receptive field remains constant but the field is more sparsely populated as its dimensions grow when combining the effect of several layers. To manipulate the receptive field size as desired there are some alternatives to the standard convolutional layer. For example atrous or dilated convolution  29   30  expands the receptive field size without increasing the number of parameters by interleaving visible and blind regions. Moreover a single dilated convolutional layer can comprise filters with multiple dilation ratios  31  thus having a variable receptive field size. Weights  edit  Each neuron in a neural network computes an output value by applying a specific function to the input values received from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias typically real numbers. Learning consists of iteratively adjusting these biases and weights. The vectors of weights and biases are called filters and represent particular features of the input e.g. a particular shape. A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces the memory footprint because a single bias and a single vector of weights are used across all receptive fields that share that filter as opposed to each receptive field having its own bias and vector weighting.  32  Deconvolutional  edit  A deconvolutional neural network is essentially the reverse of a CNN. It consists of deconvolutional layers and unpooling layers.  33  A deconvolutional layer is the transpose of a convolutional layer. Specifically a convolutional layer can be written as a multiplication with a matrix and a deconvolutional layer is multiplication with the transpose of that matrix.  34  An unpooling layer expands the layer. The maxunpooling layer is the simplest as it simply copies each entry multiple times. For example a 2by2 maxunpooling layer is  x    x x x x  displaystyle xmapsto beginbmatrixxxxxendbmatrix . Deconvolution layers are used in image generators. By default it creates periodic checkerboard artifact which can be fixed by upscalethenconvolve.  35  History  edit  CNN are often compared to the way the brain achieves vision processing in living organisms .  36  Receptive fields in the visual cortex  edit  Work by Hubel and Wiesel in the 1950s and 1960s showed that cat visual cortices contain neurons that individually respond to small regions of the visual field . Provided the eyes are not moving the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field .  37  Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space.  citation needed  The cortex in each hemisphere represents the contralateral visual field .  citation needed  Their 1968 paper identified two basic visual cell types in the brain  19  simple cells  whose output is maximized by straight edges having particular orientations within their receptive field complex cells  which have larger receptive fields  whose output is insensitive to the exact position of the edges in the field. Hubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.  38   37  Fukushimas analog threshold elements in a vision model  edit  In 1969 Kunihiko Fukushima introduced a multilayer visual feature detection network inspired by the abovementioned work of Hubel and Wiesel in which All the elements in one layer have the same set of interconnecting coefficients the arrangement of the elements and their interconnections are all homogeneous over a given layer.  This is the essential core of a convolutional network but the weights were not trained.  In the same paper Fukushima also introduced the ReLU rectified linear unit activation function .  39   40  Neocognitron origin of the trainable CNN architecture  edit  The  neocognitron   18  was introduced by Fukushima in 1980.  20   28   41  The neocognitron introduced the two basic types of layers Slayer a sharedweights receptivefield layer later known as a convolutional layer which contains units whose receptive fields cover a patch of the previous layer. A sharedweights receptivefield group a plane in neocognitron terminology is often called a filter and a layer typically has several such filters. Clayer a downsampling layer that contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes a weighted average of the activations of the units in its patch and applies inhibition divisive normalization pooled from a somewhat larger patch and across different filters in a layer and applies a saturating activation function. The patch weights are nonnegative and are not trainable in the original neocognitron. The downsampling and competitive inhibition help to classify features and objects in visual scenes even when the objects are shifted. Several supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron.  18  Today however the CNN architecture is usually trained through backpropagation . Fukushimas ReLU activation function was not used in his neocognitron since all the weights were nonnegative lateral inhibition was used instead. The rectifier has become a very popular activation function for CNNs and deep neural networks in general.  42  Convolution in time  edit  The term convolution first appears in neural networks in a paper by Toshiteru Homma Les Atlas and Robert Marks II at the first Conference on Neural Information Processing Systems in 1987. Their paper replaced multiplication with convolution in time inherently providing shift invariance motivated by and connecting more directly to the signalprocessing concept of a filter  and demonstrated it on a speech recognition task.  8  They also pointed out that as a datatrainable system convolution is essentially equivalent to correlation since reversal of the weights does not affect the final learned function For convenience we denote  as correlation instead of convolution. Note that convolving at with bt is equivalent to correlating at with bt..  8  Modern CNN implementations typically do correlation and call it convolution for convenience as they did here. Time delay neural networks  edit  The time delay neural network TDNN was introduced in 1987 by Alex Waibel et al. for phoneme recognition and was an early convolutional network exhibiting shiftinvariance.  43  A TDNN is a 1D convolutional neural net where the convolution is performed along the time axis of the data. It is the first CNN utilizing weight sharing in combination with a training by gradient descent using backpropagation .  44  Thus while also using a pyramidal structure as in the neocognitron it performed a global optimization of the weights instead of a local one.  43  TDNNs are convolutional networks that share weights along the temporal dimension.  45  They allow speech signals to be processed timeinvariantly. In 1990 Hampshire and Waibel introduced a variant that performs a twodimensional convolution.  46  Since these TDNNs operated on spectrograms the resulting phoneme recognition system was invariant to both time and frequency shifts as with images processed by a neocognitron. TDNNs improved the performance of fardistance speech recognition.  47  Image recognition with CNNs trained by gradient descent  edit  Denker et al. 1989 designed a 2D CNN system to recognize handwritten ZIP Code numbers.  48  However the lack of an efficient training method to determine the kernel coefficients of the involved convolutions meant that all the coefficients had to be laboriously handdesigned.  49  Following the advances in the training of 1D CNNs by Waibel et al. 1987 Yann LeCun et al. 1989  49  used backpropagation to learn the convolution kernel coefficients directly from images of handwritten numbers. Learning was thus fully automatic performed better than manual coefficient design and was suited to a broader range of image recognition problems and image types. \\nWei Zhang et al. 1988  14   15  used backpropagation to train the convolution kernels of a CNN for alphabets recognition. The model was called shiftinvariant pattern recognition neural network before the name CNN was coined later in the early 1990s. Wei Zhang et al. also applied the same CNN without the last fully connected layer for medical image object segmentation 1991  50  and breast cancer detection in mammograms 1994.  51  This approach became a foundation of modern computer vision . Max pooling  edit  In 1990 Yamaguchi et al. introduced the concept of max pooling a fixed filtering operation that calculates and propagates the maximum value of a given region. They did so by combining TDNNs with max pooling to realize a speakerindependent isolated word recognition system.  27  In their system they used several TDNNs per word one for each syllable . The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification. In a variant of the neocognitron called the cresceptron  instead of using Fukushimas spatial averaging with inhibition and saturation J. Weng et al. in 1993 used max pooling where a downsampling unit computes the maximum of the activations of the units in its patch  52  introducing this method into the vision field. Max pooling is often used in modern CNNs.  53  LeNet5  edit  Main article LeNet LeNet5 a pioneering 7level convolutional network by LeCun et al. in 1995  54  classifies handwritten numbers on checks  British English  cheques  digitized in 32x32 pixel images. The ability to process higherresolution images requires larger and more layers of convolutional neural networks so this technique is constrained by the availability of computing resources. It was superior than other commercial courtesy amount reading systems as of 1995. The system was integrated in NCR s check reading systems and fielded in several American banks since June 1996 reading millions of checks per day.  55  Shiftinvariant neural network  edit  A shiftinvariant neural network was proposed by Wei Zhang et al. for image character recognition in 1988.  14   15  It is a modified Neocognitron by keeping only the convolutional interconnections between the image feature layers and the last fully connected layer. The model was trained with backpropagation. The training algorithm was further improved in 1991  56  to improve its generalization ability. The model architecture was modified by removing the last fully connected layer and applied for medical image segmentation 1991  50  and automatic detection of breast cancer in mammograms 1994 .  51  A different convolutionbased design was proposed in 1988  57  for application to decomposition of onedimensional electromyography convolved signals via deconvolution. This design was modified in 1989 to other deconvolutionbased designs.  58   59  GPU implementations  edit  Although CNNs were invented in the 1980s their breakthrough in the 2000s required fast implementations on graphics processing units GPUs. In 2004 it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on CPU .  60  In 2005 another paper also emphasised the value of GPGPU for machine learning .  61  The first GPUimplementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU.  62  In the same period GPUs were also used for unsupervised training of deep belief networks .  63   64   65   66  In 2010 Dan Ciresan et al. at IDSIA trained deep feedforward networks on GPUs.  67  In 2011 they extended this to CNNs accelerating by 60 compared to training CPU.  25  In 2011 the network won an image recognition contest where they achieved superhuman performance for the first time.  68  Then they won more competitions and achieved state of the art on several benchmarks.  69   53   28  Subsequently AlexNet  a similar GPUbased CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.  70  It was an early catalytic event for the AI boom . Compared to the training of CNNs using GPUs  not much attention was given to CPU. Viebke et al 2019 parallelizes CNN by thread and SIMD level parallelism that is available on the Intel Xeon Phi .  71   72  Distinguishing features  edit  In the past traditional multilayer perceptron MLP models were used for image recognition.  example needed  However the full connectivity between nodes caused the curse of dimensionality  and was computationally intractable with higherresolution images. A 10001000pixel image with RGB color channels has 3 million weights per fullyconnected neuron which is too high to feasibly process efficiently at scale. CNN layers arranged in 3 dimensions For example in CIFAR10  images are only of size 32323 32 wide 32 high 3 color channels so a single fully connected neuron in the first hidden layer of a regular neural network would have 32323  3072 weights. A 200200 image however would lead to neurons that have 2002003  120000 weights. Also such network architecture does not take into account the spatial structure of data treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in data with a gridtopology such as images both computationally and semantically. Thus full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns. Convolutional neural networks are variants of multilayer perceptrons designed to emulate the behavior of a visual cortex . These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs CNNs have the following distinguishing features 3D volumes of neurons. The layers of a CNN have neurons arranged in 3 dimensions  width height and depth.  73  Where each neuron inside a convolutional layer is connected to only a small region of the layer before it called a receptive field. Distinct types of layers both locally and completely connected are stacked to form a CNN architecture. Local connectivity following the concept of receptive fields CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned  filters  produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global i.e. responsive to a larger region of pixel space so that the network first creates representations of small parts of the input then from them assembles representations of larger areas. Shared weights In CNNs each filter is replicated across the entire visual field. These replicated units share the same parameterization weight vector and bias and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field i.e. they grant translational equivariance given that the layer has a stride of one.  74  Pooling In a CNNs pooling layers  feature maps are divided into rectangular subregions and the features in each rectangle are independently downsampled to a single value commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps the pooling operation grants a degree of local translational invariance to the features contained therein allowing the CNN to be more robust to variations in their positions.  16  Together these properties allow CNNs to achieve better generalization on vision problems . Weight sharing dramatically reduces the number of free parameters learned thus lowering the memory requirements for running the network and allowing the training of larger more powerful networks. Building blocks  edit  A CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume e.g. holding the class scores through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below. Neurons of a convolutional layer blue connected to their receptive field red Convolutional layer  edit  A worked example of performing a convolution. The convolution has stride 1 zeropadding with kernel size 3by3. The convolution kernel is a discrete Laplacian operator . The convolutional layer is the core building block of a CNN. The layers parameters consist of a set of learnable filters or kernels  which have a small receptive field but extend through the full depth of the input volume. During the forward pass each filter is convolved across the width and height of the input volume computing the dot product between the filter entries and the input producing a 2dimensional activation map of that filter. As a result the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.  75   nb 1  Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input. Each entry in an activation map use the same set of parameters that define the filter. Selfsupervised learning has been adapted for use in convolutional layers by using sparse patches with a highmask ratio and a global response normalization layer.  citation needed  Local connectivity  edit  Typical CNN architecture When dealing with highdimensional inputs such as images it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers each neuron is connected to only a small region of the input volume. The extent of this connectivity is a hyperparameter called the receptive field of the neuron. The connections are local in space along width and height but always extend along the entire depth of the input volume. Such an architecture ensures that the learned filters produce the strongest response to a spatially local input pattern.  76  Spatial arrangement  edit  Three hyperparameters control the size of the output volume of the convolutional layer the depth stride  and padding size The depth of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example if the first convolutional layer takes the raw image as input then different neurons along the depth dimension may activate in the presence of various oriented edges or blobs of color. Stride controls how depth columns around the width and height are allocated. If the stride is 1 then we move the filters one pixel at a time. This leads to heavily overlapping receptive fields between the columns and to large output volumes. For any integer S  0  textstyle S0 a stride S means that the filter is translated S units at a time per output. In practice S  3 textstyle Sgeq 3 is rare. A greater stride means smaller overlap of receptive fields and smaller spatial dimensions of the output volume.  77  Sometimes it is convenient to pad the input with zeros or other values such as the average of the region on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volumes spatial size. In particular sometimes it is desirable to exactly preserve the spatial size of the input volume this is commonly referred to as same padding. Three example padding conditions. Replication condition means that the pixel outside is padded with the closest pixel inside. The reflection padding is where the pixel outside is padded with the pixel inside reflected across the boundary of the image. The circular padding is where the pixel outside wraps around to the other side of the image. The spatial size of the output volume is a function of the input volume size W displaystyle W  the kernel field size K displaystyle K of the convolutional layer neurons the stride S displaystyle S  and the amount of zero padding P displaystyle P on the border. The number of neurons that fit in a given volume is then W  K  2 P S  1. displaystyle frac WK2PS1. If this number is not an integer  then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a symmetric way. In general setting zero padding to be P   K  1   2 textstyle PK12 when the stride is S  1 displaystyle S1 ensures that the input volume and output volume will have the same size spatially. However it is not always completely necessary to use all of the neurons of the previous layer. For example a neural network designer may decide to use just a portion of padding. Parameter sharing  edit  A parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position then it should also be useful to compute at other positions. Denoting a single 2dimensional slice of depth as a depth slice  the neurons in each depth slice are constrained to use the same weights and bias. Since all neurons in a single depth slice share the same parameters the forward pass in each depth slice of the convolutional layer can be computed as a convolution of the neurons weights with the input volume.  nb 2  Therefore it is common to refer to the sets of weights as a filter or a kernel  which is convolved with the input. The result of this convolution is an activation map  and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the translation invariance of the CNN architecture.  16  Sometimes the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image we might expect different eyespecific or hairspecific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme and instead simply call the layer a locally connected layer. Pooling layer  edit  Main article Pooling layer Worked example of 2x2 maxpooling with stride 2. Max pooling with a 2x2 filter and stride  2 Another important concept of CNNs is pooling which is used as a form of nonlinear downsampling . Pooling provides downsampling because it reduces the spatial dimensions height and width of the input feature maps while retaining the most important information. There are several nonlinear functions to implement pooling where max pooling and average pooling are the most common. Pooling aggregates information from small regions of the input creating partitions of the input feature map typically using a fixedsize window like 2x2 and applying a stride often 2 to move the window across the input.  78  Note that without using a stride greater than 1 pooling would not perform downsampling as it would simply move the pooling window across the input one step at a time without reducing the size of the feature map. In other words the stride is what actually causes the downsampling by determining how much the pooling window moves over the input. Intuitively the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation to reduce the number of parameters memory footprint and amount of computation in the network and hence to also control overfitting . This is known as downsampling. It is common to periodically insert a pooling layer between successive convolutional layers each one typically followed by an activation function such as a ReLU layer  in a CNN architecture.  75  \\u200a460461 While pooling layers contribute to local translation invariance they do not provide global translation invariance in a CNN unless a form of global pooling is used.  16   74  The pooling layer commonly operates independently on every depth or slice of the input and resizes it spatially. A very common form of max pooling is a layer with filters of size 22 applied with a stride of 2 which subsamples every depth slice in the input by 2 along both width and height discarding 75 of the activations f X  Y  S   max a  b  0 1 S 2 X  a  2 Y  b . displaystyle f_XYSmax _ab01S_2Xa2Yb. In this case every max operation is over 4 numbers. The depth dimension remains unchanged this is true for other forms of pooling as well. In addition to max pooling pooling units can use other functions such as average pooling or ℓ 2 norm pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling which generally performs better in practice.  79  Due to the effects of fast spatial reduction of the size of the representation  which  there is a recent trend towards using smaller filters  80  or discarding pooling layers altogether.  81  RoI pooling to size 2x2. In this example region proposal an input parameter has size 7x5. Channel max pooling  edit  A channel max pooling CMP operation layer conducts the MP operation along the channel side among the corresponding positions of the consecutive feature maps for the purpose of redundant information elimination. The CMP makes the significant features gather together within fewer channels which is important for finegrained image classification that needs more discriminating features. Meanwhile another advantage of the CMP operation is to make the channel number of feature maps smaller before it connects to the first fully connected FC layer. Similar to the MP operation we denote the input feature maps and output feature maps of a CMP layer as F  RCMN and C  RcMN respectively where C and c are the channel numbers of the input and output feature maps M and N are the widths and the height of the feature maps respectively. Note that the CMP operation only changes the channel number of the feature maps. The width and the height of the feature maps are not changed which is different from the MP operation.  82  See  83   84  for reviews for pooling methods. ReLU layer  edit  ReLU is the abbreviation of rectified linear unit . It was proposed by Alston Householder in 1941  85  and used in CNN by Kunihiko Fukushima in 1969.  39  ReLU applies the nonsaturating activation function f  x   max  0  x  textstyle fxmax0x .  70  It effectively removes negative values from an activation map by setting them to zero.  86  It introduces nonlinearity to the decision function and in the overall network without affecting the receptive fields of the convolution layers.\\nIn 2011 Xavier Glorot Antoine Bordes and Yoshua Bengio found that ReLU enables better training of deeper networks  87  compared to widely used activation functions prior to 2011. Other functions can also be used to increase nonlinearity for example the saturating hyperbolic tangent f  x   tanh   x  displaystyle fxtanhx  f  x    tanh   x   displaystyle fxtanhx  and the sigmoid function σ  x    1  e  x   1 textstyle sigma x1ex1 . ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.  88  Fully connected layer  edit  After several convolutional and max pooling layers the final classification is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer as seen in regular nonconvolutional artificial neural networks . Their activations can thus be computed as an affine transformation  with matrix multiplication followed by a bias offset  vector addition of a learned or fixed bias term. Loss layer  edit  Main articles Loss function and Loss functions for classification The loss layer or  loss function  specifies how training penalizes the deviation between the predicted output of the network and the true data labels during supervised learning. Various loss functions can be used depending on the specific task. The Softmax loss function is used for predicting a single class of K mutually exclusive classes.  nb 3  Sigmoid crossentropy loss is used for predicting K independent probability values in  0  1  displaystyle 01 . Euclidean loss is used for regressing to realvalued labels       displaystyle infty infty  . Hyperparameters  edit  This section needs additional citations for verification . Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  June 2017   Learn how and when to remove this message  Hyperparameters are various settings that are used to control the learning process. CNNs use more hyperparameters than a standard multilayer perceptron MLP. Kernel size  edit  The kernel is the number of pixels processed together. It is typically expressed as the kernels dimensions e.g. 2x2 or 3x3. Padding  edit  Padding is the addition of typically 0valued pixels on the borders of an image. This is done so that the border pixels are not undervalued lost from the output because they would ordinarily participate in only a single receptive field instance. The padding applied is typically one less than the corresponding kernel dimension. For example a convolutional layer using 3x3 kernels would receive a 2pixel pad that is 1 pixel on each side of the image.  citation needed  Stride  edit  The stride is the number of pixels that the analysis window moves on each iteration. A stride of 2 means that each kernel is offset by 2 pixels from its predecessor. Number of filters  edit  Since feature map size decreases with depth layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer the product of feature values v a with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations number of feature maps times number of pixel positions nondecreasing from one layer to the next. The number of feature maps directly controls the capacity and depends on the number of available examples and task complexity. Filter size  edit  Common filter sizes found in the literature vary greatly and are usually chosen based on the data set. Typical filter sizes range from 1x1 to 7x7. As two famous examples AlexNet used 3x3 5x5 and 11x11. Inceptionv3 used 1x1 3x3 and 5x5. The challenge is to find the right level of granularity so as to create abstractions at the proper scale given a particular data set and without overfitting . Pooling type and size  edit  Max pooling is typically used often with a 2x2 dimension. This implies that the input is drastically downsampled  reducing processing cost. Greater pooling reduces the dimension of the signal and may result in unacceptable information loss . Often nonoverlapping pooling windows perform best.  79  Dilation  edit  Dilation involves ignoring pixels within a kernel. This reduces processing memory potentially without significant signal loss. A dilation of 2 on a 3x3 kernel expands the kernel to 5x5 while still processing 9 evenly spaced pixels. Specifically the processed pixels after the dilation are the cells 11 13 15 31 33 35 51 53 55 where ij denotes the cell of the ith row and jth column in the expanded 5x5 kernel. Accordingly dilation of 4 expands the kernel to 7x7.  citation needed  Translation equivariance and aliasing  edit  It is commonly assumed that CNNs are invariant to shifts of the input. Convolution or pooling layers within a CNN that do not have a stride greater than one are indeed equivariant to translations of the input.  74  However layers with a stride greater than one ignore the NyquistShannon sampling theorem and might lead to aliasing of the input signal  74  While in principle CNNs are capable of implementing antialiasing filters it has been observed that this does not happen in practice  89  and therefore yield models that are not equivariant to translations. Furthermore if a CNN makes use of fully connected layers translation equivariance does not imply translation invariance as the fully connected layers are not invariant to shifts of the input.  90   16  One solution for complete translation invariance is avoiding any downsampling throughout the network and applying global average pooling at the last layer.  74  Additionally several other partial solutions have been proposed such as antialiasing before downsampling operations  91  spatial transformer networks  92  data augmentation  subsampling combined with pooling  16  and capsule neural networks .  93  Evaluation  edit  The accuracy of the final model is typically estimated on a subpart of the dataset set apart at the start often called a test set. Alternatively methods such as k fold crossvalidation are applied. Other strategies include using conformal prediction .  94   95  Regularization methods  edit  Main article Regularization mathematics This section needs additional citations for verification . Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.  June 2017   Learn how and when to remove this message  Regularization is a process of introducing additional information to solve an illposed problem or to prevent overfitting . CNNs use various types of regularization. Empirical  edit  Dropout  edit  Because networks have so many parameters they are prone to overfitting. One method to reduce overfitting is dropout  introduced in 2014.  96  At each training stage individual nodes are either dropped out of the net ignored with probability 1  p displaystyle 1p or kept with probability p displaystyle p  so that a reduced network is left incoming and outgoing edges to a droppedout node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights. In the training stages p displaystyle p is usually 0.5 for input nodes it is typically much higher because information is directly lost when input nodes are ignored. At testing time after training has finished we would ideally like to find a sample average of all possible 2 n displaystyle 2n droppedout networks unfortunately this is unfeasible for large values of n displaystyle n . However we can find an approximation by using the full network with each nodes output weighted by a factor of p displaystyle p  so the expected value of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method although it effectively generates 2 n displaystyle 2n neural nets and as such allows for model combination at test time only a single network needs to be tested. By avoiding training all nodes on all training data dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical even for deep neural networks . The technique seems to reduce node interactions leading them to learn more robust features  clarification needed  that better generalize to new data. DropConnect  edit  DropConnect is the generalization of dropout in which each connection rather than each output unit can be dropped with probability 1  p displaystyle 1p . Each unit thus receives input from a random subset of units in the previous layer.  97  DropConnect is similar to dropout as it introduces dynamic sparsity within the model but differs in that the sparsity is on the weights rather than the output vectors of a layer. In other words the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage. Stochastic pooling  edit  A major drawback to dropout is that it does not have the same benefits for convolutional layers where the neurons are not fully connected. Even before dropout in 2013 a technique called stochastic pooling  98  the conventional deterministic pooling operations were replaced with a stochastic procedure where the activation within each pooling region is picked randomly according to a multinomial distribution  given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches such as dropout and data augmentation . An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image each having small local deformations . This is similar to explicit elastic deformations of the input images  99  which delivers excellent performance on the MNIST data set .  99  Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below. Artificial data  edit  Main article Data augmentation Because the degree of model overfitting is determined by both its power and the amount of training it receives providing a convolutional network with more training examples can reduce overfitting. Because there is often not enough available data to train especially considering that some part should be spared for later testing two approaches are to either generate new data from scratch if possible or perturb existing data to create new ones. The latter one is used since mid1990s.  54  For example input images can be cropped rotated or rescaled to create new examples with the same labels as the original training set.  100  Explicit  edit  Early stopping  edit  Main article Early stopping One of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted. Number of parameters  edit  Another simple way to prevent overfitting is to limit the number of parameters typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly reducing the complexity of the function that it can perform on the data and thus limits the amount of overfitting. This is equivalent to a  zero norm . Weight decay  edit  A simple form of added regularizer is weight decay which simply adds an additional error proportional to the sum of weights  L1 norm  or squared magnitude  L2 norm  of the weight vector to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constantalpha hyperparameter thus increasing the penalty for large weight vectors. L2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot. L1 regularization is also common. It makes the weight vectors sparse during optimization. In other words neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularization can be combined this is called elastic net regularization . Max norm constraints  edit  Another form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use projected gradient descent to enforce the constraint. In practice this corresponds to performing the parameter update as normal and then enforcing the constraint by clamping the weight vector w  displaystyle vec w of every neuron to satisfy  w   2  c displaystyle vec w_2c . Typical values of c displaystyle c are order of 34. Some papers report improvements  101  when using this form of regularization. Hierarchical coordinate frames  edit  Pooling loses the precise spatial relationships between highlevel parts such as nose and mouth in a face image. These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint such as a different orientation or scale. On the other hand people are very good at extrapolating after seeing a new shape once they can recognize it from a different viewpoint.  102  An earlier common way to deal with this problem is to train the network on transformed data in different orientations scales lighting etc. so that the network can cope with these variations. This is computationally intensive for large datasets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the retina . The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features coordinate frame.  103  Thus one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts e.g. nose and mouth poses make a consistent prediction of the pose of the whole face. This approach ensures that the higherlevel entity e.g. face is present when the lowerlevel e.g. nose and mouth agree on its prediction of the pose. The vectors of neuronal activity that represent pose pose vectors allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human visual system imposes coordinate frames in order to represent shapes.  104  Applications  edit  Image recognition  edit  CNNs are often used in image recognition systems. In 2012 an error rate of 0.23 on the MNIST database was reported.  28  Another paper on using CNN for image classification reported that the learning process was surprisingly fast in the same paper the best published results as of 2011 were achieved in the MNIST database and the NORB database.  25  Subsequently a similar CNN called AlexNet  105  won the ImageNet Large Scale Visual Recognition Challenge 2012. When applied to facial recognition  CNNs achieved a large decrease in error rate.  106  Another paper reported a 97.6 recognition rate on 5600 still images of more than 10 subjects.  21  CNNs were used to assess video quality in an objective way after manual training the resulting system had a very low root mean square error .  107  The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection with millions of images and hundreds of object classes. In the ILSVRC 2014  108  a largescale visual recognition challenge almost every highly ranked team used CNN as their basic framework. The winner GoogLeNet  109  the foundation of DeepDream  increased the mean average precision of object detection to 0.439329 and reduced classification error to 0.06656 the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans.  110  The best algorithms still struggle with objects that are small or thin such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters an increasingly common phenomenon with modern digital cameras. By contrast those kinds of images rarely trouble humans. Humans however tend to have trouble with other issues. For example they are not good at classifying objects into finegrained categories such as the particular breed of dog or species of bird whereas convolutional neural networks handle this.  citation needed  In 2015 a manylayered CNN demonstrated the ability to spot faces from a wide range of angles including upside down even when partially occluded with competitive performance. The network was trained on a database of 200000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50000 iterations.  111  Video analysis  edit  Compared to image data domains there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another temporal dimension. However some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space.  112   113  Another way is to fuse the features of two convolutional neural networks one for the spatial and one for the temporal stream.  114   115   116  Long shortterm memory LSTM recurrent units are typically incorporated after the CNN to account for interframe or interclip dependencies.  117   118  Unsupervised learning schemes for training spatiotemporal features have been introduced based on Convolutional Gated Restricted Boltzmann Machines  119  and Independent Subspace Analysis.  120  Its application can be seen in texttovideo model .  citation needed  Natural language processing  edit  CNNs have also been explored for natural language processing . CNN models are effective for various NLP problems and achieved excellent results in semantic parsing   121  search query retrieval  122  sentence modeling  123  classification  124  prediction  125  and other traditional NLP tasks.  126  Compared to traditional language processing methods such as recurrent neural networks  CNNs can represent different contextual realities of language that do not rely on a seriessequence assumption while RNNs are better suitable when classical time series modeling is required.  127   128   129   130  Anomaly detection  edit  A CNN with 1D convolutions was used on time series in the frequency domain spectral residual by an unsupervised model to detect anomalies in the time domain.  131  Drug discovery  edit  CNNs have been used in drug discovery . Predicting the interaction between molecules and biological proteins can identify potential treatments. In 2015 Atomwise introduced AtomNet the first deep learning neural network for structurebased drug design .  132  The system trains directly on 3dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller spatially proximate features into larger complex structures  133  AtomNet discovers chemical features such as aromaticity  sp 3 carbons  and hydrogen bonding . Subsequently AtomNet was used to predict novel candidate biomolecules for multiple disease targets most notably treatments for the Ebola virus  134  and multiple sclerosis .  135  Checkers game  edit  CNNs have been used in the game of checkers . From 1999 to 2001 Fogel and Chellapilla published papers showing how a convolutional neural network could learn to play checkers using coevolution. The learning process did not use prior human professional games but rather focused on a minimal set of information contained in the checkerboard the location and type of pieces and the difference in number of pieces between the two sides. Ultimately the program  Blondie24  was tested on 165 games against players and ranked in the highest 0.4.  136   137  It also earned a win against the program Chinook at its expert level of play.  138  Go  edit  CNNs have been used in computer Go . In December 2014 Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform GNU Go and win some games against Monte Carlo tree search Fuego 1.1 in a fraction of the time it took Fuego to play.  139  Later it was announced that a large 12layer convolutional neural network had correctly predicted the professional move in 55 of positions equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go without any search it beat the traditional search program GNU Go in 97 of games and matched the performance of the Monte Carlo tree search program Fuego simulating ten thousand playouts about a million positions per move.  140  A couple of CNNs for choosing moves to try policy network and evaluating positions value network driving MCTS were used by AlphaGo  the first to beat the best human player at the time.  141  Time series forecasting  edit  Recurrent neural networks are generally considered the best neural network architectures for time series forecasting and sequence modeling in general but recent studies show that convolutional networks can perform comparably or even better.  142   13  Dilated convolutions  143  might enable onedimensional convolutional neural networks to effectively learn time series dependences.  144  Convolutions can be implemented more efficiently than RNNbased solutions and they do not suffer from vanishing or exploding gradients.  145  Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from.  146  CNNs can also be applied to further tasks in time series analysis e.g. time series classification  147  or quantile forecasting  148  . Cultural heritage and 3Ddatasets  edit  As archaeological findings such as clay tablets with cuneiform writing are increasingly acquired using 3D scanners  benchmark datasets are becoming available including HeiCuBeDa  149  providing almost 2000 normalized 2D and 3D datasets prepared with the GigaMesh Software Framework .  150  So curvature based measures are used in conjunction with geometric neural networks GNNs e.g. for period classification of those clay tablets being among the oldest documents of human history.  151   152  Finetuning  edit  For many applications training data is not very available. Convolutional neural networks usually require a large amount of training data in order to avoid overfitting . A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the indomain data to finetune the network weights this is known as transfer learning . Furthermore this technique allows convolutional network architectures to successfully be applied to problems with tiny training sets.  153  Human interpretable explanations  edit  Endtoend training and prediction are common practice in computer vision . However human interpretable explanations are required for critical systems such as a selfdriving cars .  154  With recent advances in visual salience  spatial attention  and temporal attention  the most critical spatial regionstemporal instants could be visualized to justify the CNN predictions.  155   156  Related architectures  edit  Deep Qnetworks  edit  A deep Qnetwork DQN is a type of deep learning model that combines a deep neural network with Qlearning  a form of reinforcement learning . Unlike earlier reinforcement learning agents DQNs that utilize CNNs can learn directly from highdimensional sensory inputs via reinforcement learning.  157  Preliminary results were presented in 2014 with an accompanying paper in February 2015.  158  The research described an application to Atari 2600 gaming. Other deep reinforcement learning models preceded it.  159  Deep belief networks  edit  Main article Deep belief network Convolutional deep belief networks CDBN have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore they exploit the 2D structure of images like CNNs do and make use of pretraining like deep belief networks . They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR  160  have been obtained using CDBNs.  161  Neural abstraction pyramid Neural abstraction pyramid  edit  The feedforward architecture of convolutional neural networks was extended in the neural abstraction pyramid  162  by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models imagelike outputs at the highest resolution were generated e.g. for semantic segmentation image reconstruction and object localization tasks. Notable libraries  edit  Caffe  A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center BVLC. It supports both CPU and GPU. Developed in C  and has Python and MATLAB wrappers. Deeplearning4j  Deep learning in Java and Scala on multiGPUenabled Spark . A generalpurpose deep learning library for the JVM production stack running on a C scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka. Dlib  A toolkit for making real world machine learning and data analysis applications in C. Microsoft Cognitive Toolkit  A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports fullfledged interfaces for training in C and Python and with additional support for model inference in C and Java. TensorFlow  Apache 2.0 licensed Theanolike library with support for CPU GPU Googles proprietary tensor processing unit TPU  163  and mobile devices. Theano  The reference deeplearning library for Python with an API largely compatible with the popular NumPy library. Allows user to write symbolic mathematical expressions then automatically generates their derivatives saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast ontheGPU implementation. Torch  A scientific computing framework with wide support for machine learning algorithms written in C and Lua . See also  edit  Attention machine learning Convolution Deep learning Naturallanguage processing Neocognitron Scaleinvariant feature transform Time delay neural network Vision processing unit Notes  edit   When applied to other types of data than image data such as sound data spatial position may variously correspond to different points in the time domain  frequency domain  or other mathematical spaces .  hence the name convolutional layer  Socalled categorical data . References  edit   LeCun Yann Bengio Yoshua Hinton Geoffrey 20150528. Deep learning . Nature . 521 7553 436 444. Bibcode  2015Natur.521..436L . doi  10.1038nature14539 . ISSN 14764687 . PMID 26017442 .  LeCun Y. Boser B. Denker J. S. Henderson D. Howard R. E. Hubbard W. Jackel L. D. December 1989. Backpropagation Applied to Handwritten Zip Code Recognition . Neural Computation . 1 4 541 551. doi  10.1162neco.1989.1.4.541 . ISSN 08997667 .  a b Venkatesan Ragav Li Baoxin 20171023. Convolutional Neural Networks in Visual Computing A Concise Guide . CRC Press. ISBN 9781351650328 . Archived from the original on 20231016 . Retrieved 20201213 .  a b Balas Valentina E. Kumar Raghvendra Srivastava Rajshree 20191119. Recent Trends and Advances in Artificial Intelligence and Internet of Things . Springer Nature. ISBN 9783030326449 . Archived from the original on 20231016 . Retrieved 20201213 .  Zhang Yingjie Soon Hong Geok Ye Dongsen Fuh Jerry Ying Hsi Zhu Kunpeng September 2020. PowderBed Fusion Process Monitoring by Machine Vision With Hybrid Convolutional Neural Networks . IEEE Transactions on Industrial Informatics . 16 9 5769 5779. doi  10.1109TII.2019.2956078 . ISSN 19410050 . S2CID 213010088 . Archived from the original on 20230731 . Retrieved 20230812 .  Chervyakov N.I. Lyakhov P.A. Deryabin M.A. Nagornov N.N. Valueva M.V. Valuev G.V. September 2020. Residue Number SystemBased Solution for Reducing the Hardware Cost of a Convolutional Neural Network . Neurocomputing . 407  439 453. doi  10.1016j.neucom.2020.04.018 . S2CID 219470398 . Archived from the original on 20230629 . Retrieved 20230812 . Convolutional neural networks represent deep learning architectures that are currently used in a wide range of applications including computer vision speech recognition malware dedection time series analysis in finance and many others.  a b Habibi Aghdam Hamed 20170530. Guide to convolutional neural networks\\xa0 a practical application to trafficsign detection and classification . Heravi Elnaz Jahani. Cham Switzerland. ISBN 9783319575490 . OCLC 987790957 .  cite book    CS1 maint location missing publisher  link  CS1 maint multiple names authors list  link   a b c Homma Toshiteru Les Atlas Robert Marks II 1987. An Artificial Neural Network for SpatioTemporal Bipolar Patterns Application to Phoneme Classification PDF . Advances in Neural Information Processing Systems . 1  31 40. Archived PDF from the original on 20220331 . Retrieved 20220331 . The notion of convolution or correlation used in the models presented is popular in engineering disciplines and has been applied extensively to designing filters control systems etc.  Valueva M.V. Nagornov N.N. Lyakhov P.A. Valuev G.V. Chervyakov N.I. 2020. Application of the residue number system to reduce hardware costs of the convolutional neural network implementation. Mathematics and Computers in Simulation . 177 . Elsevier BV 232 243. doi  10.1016j.matcom.2020.04.031 . ISSN 03784754 . S2CID 218955622 . Convolutional neural networks are a promising tool for solving the problem of pattern recognition.  van den Oord Aaron Dieleman Sander Schrauwen Benjamin 20130101. Burges C. J. C. Bottou L. Welling M. Ghahramani Z. Weinberger K. Q. eds.. Deep contentbased music recommendation PDF . Curran Associates Inc. pp. 2643 2651. Archived PDF from the original on 20220307 . Retrieved 20220331 .  Collobert Ronan Weston Jason 20080101. A unified architecture for natural language processing. Proceedings of the 25th international conference on Machine learning  ICML 08 . New York NY US ACM. pp. 160 167. doi  10.11451390156.1390177 . ISBN 9781605582054 . S2CID 2617020 .  Avilov Oleksii Rimbert Sebastien Popov Anton Bougrain Laurent July 2020. Deep Learning Techniques to Improve Intraoperative Awareness Detection from Electroencephalographic Signals . 2020 42nd Annual International Conference of the IEEE Engineering in Medicine  Biology Society EMBC PDF . Vol.\\xa02020. Montreal QC Canada IEEE. pp. 142 145. doi  10.1109EMBC44109.2020.9176228 . ISBN 9781728119908 . PMID 33017950 . S2CID 221386616 . Archived PDF from the original on 20220519 . Retrieved 20230721 .  a b Tsantekidis Avraam Passalis Nikolaos Tefas Anastasios Kanniainen Juho Gabbouj Moncef Iosifidis Alexandros July 2017. Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks. 2017 IEEE 19th Conference on Business Informatics CBI . Thessaloniki Greece IEEE. pp. 7 12. doi  10.1109CBI.2017.23 . ISBN 9781538630358 . S2CID 4950757 .  a b c Zhang Wei 1988. Shiftinvariant pattern recognition neural network and its optical architecture . Proceedings of Annual Conference of the Japan Society of Applied Physics . Archived from the original on 20200623 . Retrieved 20200622 .  a b c Zhang Wei 1990. Parallel distributed processing model with local spaceinvariant interconnections and its optical architecture . Applied Optics . 29 32 4790 7. Bibcode  1990ApOpt..29.4790Z . doi  10.1364AO.29.004790 . PMID 20577468 . Archived from the original on 20170206 . Retrieved 20160922 .  a b c d e f Mouton Coenraad Myburgh Johannes C. Davel Marelie H. 2020. Stride and Translation Invariance in CNNs . In Gerber Aurona ed.. Artificial Intelligence Research . Communications in Computer and Information Science. Vol.\\xa01342. Cham Springer International Publishing. pp. 267 281. arXiv  2103.10097 . doi  10.10079783030661519_17 . ISBN 9783030661519 . S2CID 232269854 . Archived from the original on 20210627 . Retrieved 20210326 .  Kurtzman Thomas August 20 2019. Hidden bias in the DUDE dataset leads to misleading performance of deep learning in structurebased virtual screening . PLOS ONE . 14 8 e0220113. Bibcode  2019PLoSO..1420113C . doi  10.1371journal.pone.0220113 . PMC 6701836 . PMID 31430292 .  a b c Fukushima K. 2007. Neocognitron . Scholarpedia . 2 1 1717. Bibcode  2007SchpJ...2.1717F . doi  10.4249scholarpedia.1717 .  a b Hubel D. H. Wiesel T. N. 19680301. Receptive fields and functional architecture of monkey striate cortex . The Journal of Physiology . 195 1 215 243. doi  10.1113jphysiol.1968.sp008455 . ISSN 00223751 . PMC 1557912 . PMID 4966457 .  a b Fukushima Kunihiko 1980. Neocognitron A Selforganizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position PDF . Biological Cybernetics . 36 4 193 202. doi  10.1007BF00344251 . PMID 7370364 . S2CID 206775608 . Archived PDF from the original on 3 June 2014 . Retrieved 16 November 2013 .  a b Matusugu Masakazu Katsuhiko Mori Yusuke Mitari Yuji Kaneda 2003. Subject independent facial expression recognition with robust face detection using a convolutional neural network PDF . Neural Networks . 16 5 555 559. doi  10.1016S0893608003001151 . PMID 12850007 . Archived PDF from the original on 13 December 2013 . Retrieved 17 November 2013 .  Convolutional Neural Networks Demystified A Matched Filtering Perspective Based Tutorial httpsarxiv.orgabs2108.11663v3  Convolutional Neural Networks LeNet  DeepLearning 0.1 documentation . DeepLearning 0.1 . LISA Lab. Archived from the original on 28 December 2017 . Retrieved 31 August 2013 .  Chollet François 20170404. Xception Deep Learning with Depthwise Separable Convolutions. arXiv  1610.02357  cs.CV .  a b c Ciresan Dan Ueli Meier Jonathan Masci Luca M. Gambardella Jurgen Schmidhuber 2011. Flexible High Performance Convolutional Neural Networks for Image Classification PDF . Proceedings of the TwentySecond International Joint Conference on Artificial IntelligenceVolume Volume Two . 2  1237 1242. Archived PDF from the original on 5 April 2022 . Retrieved 17 November 2013 .  Krizhevsky  Alex. ImageNet Classification with Deep Convolutional Neural Networks PDF . Archived PDF from the original on 25 April 2021 . Retrieved 17 November 2013 .  a b Yamaguchi Kouichi Sakamoto Kenji Akabane Toshio Fujimoto Yoshiji November 1990. A Neural Network for SpeakerIndependent Isolated Word Recognition . First International Conference on Spoken Language Processing ICSLP 90. Kobe Japan. Archived from the original on 20210307 . Retrieved 20190904 .  a b c d Ciresan Dan Meier Ueli Schmidhuber Jürgen June 2012. Multicolumn deep neural networks for image classification. 2012 IEEE Conference on Computer Vision and Pattern Recognition . New York NY Institute of Electrical and Electronics Engineers IEEE. pp. 3642 3649. arXiv  1202.2745 . CiteSeerX 10.1.1.300.3283 . doi  10.1109CVPR.2012.6248110 . ISBN 9781467312264 . OCLC 812295155 . S2CID 2161592 .  Yu Fisher Koltun Vladlen 20160430. MultiScale Context Aggregation by Dilated Convolutions. arXiv  1511.07122  cs.CV .  Chen LiangChieh Papandreou George Schroff Florian Adam Hartwig 20171205. Rethinking Atrous Convolution for Semantic Image Segmentation. arXiv  1706.05587  cs.CV .  Duta Ionut Cosmin Georgescu Mariana Iuliana Ionescu Radu Tudor 20210816. Contextual Convolutional Neural Networks. arXiv  2108.07387  cs.CV .  LeCun Yann. LeNet5 convolutional neural networks . Archived from the original on 24 February 2021 . Retrieved 16 November 2013 .  Zeiler Matthew D. Taylor Graham W. Fergus Rob November 2011. Adaptive deconvolutional networks for mid and high level feature learning . 2011 International Conference on Computer Vision . IEEE. pp. 2018 2025. doi  10.1109iccv.2011.6126474 . ISBN 9781457711022 .  Dumoulin Vincent Visin Francesco 20180111 A guide to convolution arithmetic for deep learning  arXiv  1603.07285  Odena Augustus Dumoulin Vincent Olah Chris 20161017. Deconvolution and Checkerboard Artifacts . Distill . 1 10 e3. doi  10.23915distill.00003 . ISSN 24760757 .  van Dyck Leonard Elia Kwitt Roland Denzler Sebastian Jochen Gruber Walter Roland 2021. Comparing Object Recognition in Humans and Deep Convolutional Neural NetworksAn Eye Tracking Study . Frontiers in Neuroscience . 15  750639. doi  10.3389fnins.2021.750639 . ISSN 1662453X . PMC 8526843 . PMID 34690686 .  a b Hubel DH Wiesel TN October 1959. Receptive fields of single neurones in the cats striate cortex . J. Physiol . 148 3 574 91. doi  10.1113jphysiol.1959.sp006308 . PMC 1363130 . PMID 14403679 .  David H. Hubel and Torsten N. Wiesel 2005. Brain and visual perception the story of a 25year collaboration . Oxford University Press US. p.\\xa0106. ISBN 9780195176186 . Archived from the original on 20231016 . Retrieved 20190118 .  a b Fukushima K. 1969. Visual feature extraction by a multilayered network of analog threshold elements. IEEE Transactions on Systems Science and Cybernetics . 5 4 322 333. doi  10.1109TSSC.1969.300225 .  Schmidhuber Juergen 2022. Annotated History of Modern AI and Deep Learning. arXiv  2212.11279  cs.NE .  LeCun Yann Bengio Yoshua Hinton Geoffrey 2015. Deep learning PDF . Nature . 521 7553 436 444. Bibcode  2015Natur.521..436L . doi  10.1038nature14539 . PMID 26017442 . S2CID 3074096 .  Ramachandran Prajit Barret Zoph Quoc V. Le October 16 2017. Searching for Activation Functions. arXiv  1710.05941  cs.NE .  a b Waibel Alex December 1987. Phoneme Recognition Using TimeDelay Neural Networks PDF . Meeting of the Institute of Electrical Information and Communication Engineers IEICE. Tokyo Japan.  Alexander Waibel et al. Phoneme Recognition Using TimeDelay Neural Networks Archived 20210225 at the Wayback Machine IEEE Transactions on Acoustics Speech and Signal Processing Volume 37 No. 3 pp. 328.  339 March 1989.  LeCun Yann Bengio Yoshua 1995. Convolutional networks for images speech and time series . In Arbib Michael A. ed.. The handbook of brain theory and neural networks Second\\xa0ed.. The MIT press. pp. 276 278. Archived from the original on 20200728 . Retrieved 20191203 .  John B. Hampshire and Alexander Waibel Connectionist Architectures for MultiSpeaker Phoneme Recognition Archived 20220331 at the Wayback Machine   Advances in Neural Information Processing Systems 1990 Morgan Kaufmann.  Ko Tom Peddinti Vijayaditya Povey Daniel Seltzer Michael L. Khudanpur Sanjeev March 2018. A Study on Data Augmentation of Reverberant Speech for Robust Speech Recognition PDF . The 42nd IEEE International Conference on Acoustics Speech and Signal Processing ICASSP 2017. New Orleans LA US. Archived PDF from the original on 20180708 . Retrieved 20190904 .  Denker J S Gardner W R Graf H. P Henderson D Howard R E Hubbard W Jackel L D BaIrd H S and Guyon 1989 Neural network recognizer for handwritten zip code digits Archived 20180804 at the Wayback Machine  ATT Bell Laboratories  a b Y. LeCun B. Boser J. S. Denker D. Henderson R. E. Howard W. Hubbard L. D. Jackel Backpropagation Applied to Handwritten Zip Code Recognition Archived 20200110 at the Wayback Machine  ATT Bell Laboratories  a b Zhang Wei 1991. Image processing of human corneal endothelium based on a learning network . Applied Optics . 30 29 4211 7. Bibcode  1991ApOpt..30.4211Z . doi  10.1364AO.30.004211 . PMID 20706526 . Archived from the original on 20170206 . Retrieved 20160922 .  a b Zhang Wei 1994. Computerized detection of clustered microcalcifications in digital mammograms using a shiftinvariant artificial neural network . Medical Physics . 21 4 517 24. Bibcode  1994MedPh..21..517Z . doi  10.11181.597177 . PMID 8058017 . Archived from the original on 20170206 . Retrieved 20160922 .  Weng J Ahuja N Huang TS 1993. Learning recognition and segmentation of 3D objects from 2D images . 1993 4th International Conference on Computer Vision . IEEE. pp. 121 128. doi  10.1109ICCV.1993.378228 . ISBN 0818638702 . S2CID 8619176 .  a b Schmidhuber Jürgen 2015. Deep Learning . Scholarpedia . 10 11 1527 54. CiteSeerX 10.1.1.76.1541 . doi  10.1162neco.2006.18.7.1527 . PMID 16764513 . S2CID 2309950 . Archived from the original on 20160419 . Retrieved 20190120 .  a b Lecun Y. Jackel L. D. Bottou L. Cortes C. Denker J. S. Drucker H. Guyon I. Muller U. A. Sackinger E. Simard P. Vapnik V. August 1995. Learning algorithms for classification A comparison on handwritten digit recognition PDF . World Scientific. pp. 261 276. doi  10.11422808 . ISBN 9789810223243 . Archived PDF from the original on 2 May 2023.  Lecun Y. Bottou L. Bengio Y. Haffner P. November 1998. Gradientbased learning applied to document recognition . Proceedings of the IEEE . 86 11 2278 2324. doi  10.11095.726791 .  Zhang Wei 1991. Error Back Propagation with MinimumEntropy Weights A Technique for Better Generalization of 2D ShiftInvariant NNs . Proceedings of the International Joint Conference on Neural Networks . Archived from the original on 20170206 . Retrieved 20160922 .  Daniel Graupe Ruey Wen Liu George S Moschytz. Applications of neural networks to medical signal processing Archived 20200728 at the Wayback Machine . In Proc. 27th IEEE Decision and Control Conf.  pp. 343347 1988.  Daniel Graupe Boris Vern G. Gruener Aaron Field and Qiu Huang.  Decomposition of surface EMG signals into single fiber action potentials by means of neural network Archived 20190904 at the Wayback Machine . Proc. IEEE International Symp. on Circuits and Systems pp. 10081011 1989.  Qiu Huang Daniel Graupe Yi Fang Huang Ruey Wen Liu. Identification of firing patterns of neuronal signals  dead link   . In Proc. 28th IEEE Decision and Control Conf. pp. 266271 1989. httpsieeexplore.ieee.orgdocument70115 Archived 20220331 at the Wayback Machine  Oh KS Jung K 2004. GPU implementation of neural networks. Pattern Recognition . 37 6 1311 1314. Bibcode  2004PatRe..37.1311O . doi  10.1016j.patcog.2004.01.013 .  Dave Steinkraus Patrice Simard Ian Buck 2005. Using GPUs for Machine Learning Algorithms . 12th International Conference on Document Analysis and Recognition ICDAR 2005 . pp. 1115 1119. doi  10.1109ICDAR.2005.251 . Archived from the original on 20220331 . Retrieved 20220331 .  Kumar Chellapilla Sid Puri Patrice Simard 2006. High Performance Convolutional Neural Networks for Document Processing . In Lorette Guy ed.. Tenth International Workshop on Frontiers in Handwriting Recognition . Suvisoft. Archived from the original on 20200518 . Retrieved 20160314 .  Hinton GE Osindero S Teh YW Jul 2006. A fast learning algorithm for deep belief nets. Neural Computation . 18 7 1527 54. CiteSeerX 10.1.1.76.1541 . doi  10.1162neco.2006.18.7.1527 . PMID 16764513 . S2CID 2309950 .  Bengio Yoshua Lamblin Pascal Popovici Dan Larochelle Hugo 2007. Greedy LayerWise Training of Deep Networks PDF . Advances in Neural Information Processing Systems  153 160. Archived PDF from the original on 20220602 . Retrieved 20220331 .  Ranzato MarcAurelio Poultney Christopher Chopra Sumit LeCun Yann 2007. Efficient Learning of Sparse Representations with an EnergyBased Model PDF . Advances in Neural Information Processing Systems . Archived PDF from the original on 20160322 . Retrieved 20140626 .  Raina R Madhavan A Ng Andrew 14 June 2009. Largescale deep unsupervised learning using graphics processors PDF . Proceedings of the 26th Annual International Conference on Machine Learning . ICML 09 Proceedings of the 26th Annual International Conference on Machine Learning. pp. 873 880. doi  10.11451553374.1553486 . ISBN 9781605585161 . S2CID 392458 . Archived PDF from the original on 8 December 2020 . Retrieved 22 December 2023 .  Ciresan Dan Meier Ueli Gambardella Luca Schmidhuber Jürgen 2010. Deep big simple neural nets for handwritten digit recognition. Neural Computation . 22 12 3207 3220. arXiv  1003.0358 . doi  10.1162NECO_a_00052 . PMID 20858131 . S2CID 1918673 .  IJCNN 2011 Competition result table . OFFICIAL IJCNN2011 COMPETITION . 2010. Archived from the original on 20210117 . Retrieved 20190114 .  Schmidhuber Jürgen 17 March 2017. History of computer vision contests won by deep CNNs on GPU . Archived from the original on 19 December 2018 . Retrieved 14 January 2019 .  a b Krizhevsky Alex Sutskever Ilya Hinton Geoffrey E. 20170524. ImageNet classification with deep convolutional neural networks PDF . Communications of the ACM . 60 6 84 90. doi  10.11453065386 . ISSN 00010782 . S2CID 195908774 . Archived PDF from the original on 20170516 . Retrieved 20181204 .  Viebke Andre Memeti Suejb Pllana Sabri Abraham Ajith 2019. CHAOS a parallelization scheme for training convolutional neural networks on Intel Xeon Phi. The Journal of Supercomputing . 75 1 197 227. arXiv  1702.07908 . doi  10.1007s112270171994x . S2CID 14135321 .  Viebke Andre Pllana Sabri 2015. The Potential of the Intel R Xeon Phi for Supervised Deep Learning . 2015 IEEE 17th International Conference on High Performance Computing and Communications 2015 IEEE 7th International Symposium on Cyberspace Safety and Security and 2015 IEEE 12th International Conference on Embedded Software and Systems . IEEE Xplore . IEEE 2015. pp. 758 765. doi  10.1109HPCCCSSICESS.2015.45 . ISBN 9781479989379 . S2CID 15411954 . Archived from the original on 20230306 . Retrieved 20220331 .  Hinton Geoffrey 2012. ImageNet Classification with Deep Convolutional Neural Networks . NIPS12 Proceedings of the 25th International Conference on Neural Information Processing Systems  Volume 1 . 1  1097 1105. Archived from the original on 20191220 . Retrieved 20210326  via ACM.  a b c d e Azulay Aharon Weiss Yair 2019. Why do deep convolutional networks generalize so poorly to small image transformations . Journal of Machine Learning Research . 20 184 1 25. ISSN 15337928 . Archived from the original on 20220331 . Retrieved 20220331 .  a b Géron Aurélien 2019. Handson Machine Learning with ScikitLearn Keras and TensorFlow . Sebastopol CA OReilly Media. ISBN 9781492032649 .  pp. 448  Li Zewen Liu Fan Yang Wenjie Peng Shouheng Zhou Jun December 2022. A Survey of Convolutional Neural Networks Analysis Applications and Prospects . IEEE Transactions on Neural Networks and Learning Systems . 33 12 6999 7019. arXiv  2004.02806 . doi  10.1109TNNLS.2021.3084827 . Retrieved 5 March 2025 .  CS231n Convolutional Neural Networks for Visual Recognition . cs231n.github.io . Archived from the original on 20191023 . Retrieved 20170425 .  Nirthika Rajendran Manivannan Siyamalan Ramanan Amirthalingam Wang Ruixuan 20220401. Pooling in convolutional neural networks for medical image analysis a survey and an empirical study . Neural Computing and Applications . 34 7 5321 5347. doi  10.1007s00521022069538 . ISSN 14333058 . PMC 8804673 . PMID 35125669 .  a b Scherer Dominik Müller Andreas C. Behnke Sven 2010. Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition PDF . Artificial Neural Networks ICANN 20th International Conference on . Thessaloniki Greece Springer. pp. 92 101. Archived PDF from the original on 20180403 . Retrieved 20161228 .  Graham Benjamin 20141218. Fractional MaxPooling. arXiv  1412.6071  cs.CV .  Springenberg Jost Tobias Dosovitskiy Alexey Brox Thomas Riedmiller Martin 20141221. Striving for Simplicity The All Convolutional Net. arXiv  1412.6806  cs.LG .  Ma Zhanyu Chang Dongliang Xie Jiyang Ding Yifeng Wen Shaoguo Li Xiaoxu Si Zhongwei Guo Jun 2019. FineGrained Vehicle Classification With Channel Max Pooling Modified CNNs. IEEE Transactions on Vehicular Technology . 68 4. Institute of Electrical and Electronics Engineers IEEE 3224 3233. doi  10.1109tvt.2019.2899972 . ISSN 00189545 . S2CID 86674074 .  Zafar Afia Aamir Muhammad Mohd Nawi Nazri Arshad Ali Riaz Saman Alruban Abdulrahman Dutta Ashit Kumar Almotairi Sultan 20220829. A Comparison of Pooling Methods for Convolutional Neural Networks . Applied Sciences . 12 17 8643. doi  10.3390app12178643 . ISSN 20763417 .  Gholamalinezhad Hossein Khosravi Hossein 20200916 Pooling Methods in Deep Neural Networks a Review  arXiv  2009.07485  Householder Alston S. June 1941. A theory of steadystate activity in nervefiber networks I. Definitions and preliminary lemmas . The Bulletin of Mathematical Biophysics . 3 2 63 69. doi  10.1007BF02478220 . ISSN 00074985 .  Romanuke Vadim 2017. Appropriate number and allocation of ReLUs in convolutional neural networks . Research Bulletin of NTUU Kyiv Polytechnic Institute . 1 1 69 78. doi  10.2053518100546.2017.1.88156 .  Xavier Glorot Antoine Bordes Yoshua Bengio 2011. Deep sparse rectifier neural networks PDF . AISTATS. Archived from the original PDF on 20161213 . Retrieved 20230410 . Rectifier and softplus activation functions. The second one is a smooth version of the first.  Krizhevsky A. Sutskever I. Hinton G. E. 2012. Imagenet classification with deep convolutional neural networks PDF . Advances in Neural Information Processing Systems . 1  1097 1105. Archived PDF from the original on 20220331 . Retrieved 20220331 .  Ribeiro Antonio H. Schön Thomas B. 2021. How Convolutional Neural Networks Deal with Aliasing. ICASSP 2021  2021 IEEE International Conference on Acoustics Speech and Signal Processing ICASSP . pp. 2755 2759. arXiv  2102.07757 . doi  10.1109ICASSP39728.2021.9414627 . ISBN 9781728176055 . S2CID 231925012 .  Myburgh Johannes C. Mouton Coenraad Davel Marelie H. 2020. Tracking Translation Invariance in CNNS . In Gerber Aurona ed.. Artificial Intelligence Research . Communications in Computer and Information Science. Vol.\\xa01342. Cham Springer International Publishing. pp. 282 295. arXiv  2104.05997 . doi  10.10079783030661519_18 . ISBN 9783030661519 . S2CID 233219976 . Archived from the original on 20220122 . Retrieved 20210326 .  Richard Zhang 20190425. Making Convolutional Networks ShiftInvariant Again . OCLC 1106340711 .  Jadeberg Simonyan Zisserman Kavukcuoglu Max Karen Andrew Koray 2015. Spatial Transformer Networks PDF . Advances in Neural Information Processing Systems . 28 . Archived PDF from the original on 20210725 . Retrieved 20210326  via NIPS.  cite journal    CS1 maint multiple names authors list  link   E Sabour Sara Frosst Nicholas Hinton Geoffrey 20171026. Dynamic Routing Between Capsules . OCLC 1106278545 .  cite book    CS1 maint multiple names authors list  link   Matiz Sergio Barner Kenneth E. 20190601. Inductive conformal predictor for convolutional neural networks Applications to active learning for image classification . Pattern Recognition . 90  172 182. Bibcode  2019PatRe..90..172M . doi  10.1016j.patcog.2019.01.035 . ISSN 00313203 . S2CID 127253432 . Archived from the original on 20210929 . Retrieved 20210929 .  Wieslander Håkan Harrison Philip J. Skogberg Gabriel Jackson Sonya Fridén Markus Karlsson Johan Spjuth Ola Wählby Carolina February 2021. Deep Learning With Conformal Prediction for Hierarchical Analysis of LargeScale WholeSlide Tissue Images . IEEE Journal of Biomedical and Health Informatics . 25 2 371 380. doi  10.1109JBHI.2020.2996300 . ISSN 21682208 . PMID 32750907 . S2CID 219885788 .  Srivastava Nitish C. Geoffrey Hinton Alex Krizhevsky Ilya Sutskever Ruslan Salakhutdinov 2014. Dropout A Simple Way to Prevent Neural Networks from overfitting PDF . Journal of Machine Learning Research . 15 1 1929 1958. Archived PDF from the original on 20160119 . Retrieved 20150103 .  Regularization of Neural Networks using DropConnect  ICML 2013  JMLR WCP . jmlr.org  1058 1066. 20130213. Archived from the original on 20170812 . Retrieved 20151217 .  Zeiler Matthew D. Fergus Rob 20130115. Stochastic Pooling for Regularization of Deep Convolutional Neural Networks. arXiv  1301.3557  cs.LG .  a b Platt John Steinkraus Dave Simard Patrice Y. August 2003. Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis  Microsoft Research . Microsoft Research . Archived from the original on 20171107 . Retrieved 20151217 .  Hinton Geoffrey E. Srivastava Nitish Krizhevsky Alex Sutskever Ilya Salakhutdinov Ruslan R. 2012. Improving neural networks by preventing coadaptation of feature detectors. arXiv  1207.0580  cs.NE .  Dropout A Simple Way to Prevent Neural Networks from Overfitting . jmlr.org . Archived from the original on 20160305 . Retrieved 20151217 .  Hinton Geoffrey 1979. Some demonstrations of the effects of structural descriptions in mental imagery. Cognitive Science . 3 3 231 250. doi  10.1016s0364021379800087 .  Rock Irvin. The frame of reference. The legacy of Solomon Asch Essays in cognition and social psychology 1990 243268.  J. Hinton Coursera lectures on Neural Networks 2012 Url httpswww.coursera.orglearnneuralnetworks Archived 20161231 at the Wayback Machine  Dave Gershgorn 18 June 2018. The inside story of how AI got good enough to dominate Silicon Valley . Quartz . Archived from the original on 12 December 2019 . Retrieved 5 October 2018 .  Lawrence Steve C. Lee Giles Ah Chung Tsoi Andrew D. Back 1997. Face Recognition A Convolutional Neural Network Approach. IEEE Transactions on Neural Networks . 8 1 98 113. CiteSeerX 10.1.1.92.5813 . doi  10.110972.554195 . PMID 18255614 . S2CID 2883848 .  Le Callet Patrick Christian ViardGaudin Dominique Barba 2006. A Convolutional Neural Network Approach for Objective Video Quality Assessment PDF . IEEE Transactions on Neural Networks . 17 5 1316 1327. doi  10.1109TNN.2006.879766 . PMID 17001990 . S2CID 221185563 . Archived PDF from the original on 24 February 2021 . Retrieved 17 November 2013 .  ImageNet Large Scale Visual Recognition Competition 2014 ILSVRC2014 . Archived from the original on 5 February 2016 . Retrieved 30 January 2016 .  Szegedy Christian Liu Wei Jia Yangqing Sermanet Pierre Reed Scott E. Anguelov Dragomir Erhan Dumitru Vanhoucke Vincent Rabinovich Andrew 2015. Going deeper with convolutions. IEEE Conference on Computer Vision and Pattern Recognition CVPR 2015 Boston MA USA June 712 2015 . IEEE Computer Society. pp. 1 9. arXiv  1409.4842 . doi  10.1109CVPR.2015.7298594 . ISBN 9781467369640 .  Russakovsky Olga  Deng Jia Su Hao Krause Jonathan Satheesh Sanjeev Ma Sean Huang Zhiheng Karpathy Andrej  Khosla Aditya Bernstein Michael Berg Alexander C. FeiFei Li 2014. Image Net Large Scale Visual Recognition Challenge. arXiv  1409.0575  cs.CV .  The Face Detection Algorithm Set To Revolutionize Image Search . Technology Review . February 16 2015. Archived from the original on 20 September 2020 . Retrieved 27 October 2017 .  Baccouche Moez Mamalet Franck Wolf Christian Garcia Christophe Baskurt Atilla 20111116. Sequential Deep Learning for Human Action Recognition. In Salah Albert Ali Lepri Bruno eds.. Human Behavior Unterstanding . Lecture Notes in Computer Science. Vol.\\xa07065. Springer Berlin Heidelberg. pp. 29 39. CiteSeerX 10.1.1.385.4740 . doi  10.10079783642254468_4 . ISBN 9783642254451 .  Ji Shuiwang Xu Wei Yang Ming Yu Kai 20130101. 3D Convolutional Neural Networks for Human Action Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence . 35 1 221 231. CiteSeerX 10.1.1.169.4046 . doi  10.1109TPAMI.2012.59 . ISSN 01628828 . PMID 22392705 . S2CID 1923924 .  Huang Jie Zhou Wengang Zhang Qilin Li Houqiang Li Weiping 2018. Videobased Sign Language Recognition without Temporal Segmentation. arXiv  1801.10111  cs.CV .  Karpathy Andrej et al.  Largescale video classification with convolutional neural networks Archived 20190806 at the Wayback Machine . IEEE Conference on Computer Vision and Pattern Recognition CVPR. 2014.  Simonyan Karen Zisserman Andrew 2014. TwoStream Convolutional Networks for Action Recognition in Videos. arXiv  1406.2199  cs.CV . 2014.  Wang Le Duan Xuhuan Zhang Qilin Niu Zhenxing Hua Gang Zheng Nanning 20180522. SegmentTube SpatioTemporal Action Localization in Untrimmed Videos with PerFrame Segmentation PDF . Sensors . 18 5 1657. Bibcode  2018Senso..18.1657W . doi  10.3390s18051657 . ISSN 14248220 . PMC 5982167 . PMID 29789447 . Archived PDF from the original on 20210301 . Retrieved 20180914 .  Duan Xuhuan Wang Le Zhai Changbo Zheng Nanning Zhang Qilin Niu Zhenxing Hua Gang 2018. Joint SpatioTemporal Action Localization in Untrimmed Videos with PerFrame Segmentation. 2018 25th IEEE International Conference on Image Processing ICIP . 25th IEEE International Conference on Image Processing ICIP. pp. 918 922. doi  10.1109icip.2018.8451692 . ISBN 9781479970612 .  Taylor Graham W. Fergus Rob LeCun Yann Bregler Christoph 20100101. Convolutional Learning of Spatiotemporal Features . Proceedings of the 11th European Conference on Computer Vision Part VI. ECCV10. Berlin Heidelberg SpringerVerlag. pp. 140 153. ISBN 9783642155666 . Archived from the original on 20220331 . Retrieved 20220331 .  Le Q. V. Zou W. Y. Yeung S. Y. Ng A. Y. 20110101. Learning hierarchical invariant spatiotemporal features for action recognition with independent subspace analysis. CVPR 2011 . CVPR 11. Washington DC US IEEE Computer Society. pp. 3361 3368. CiteSeerX 10.1.1.294.5948 . doi  10.1109CVPR.2011.5995496 . ISBN 9781457703942 . S2CID 6006618 .  Grefenstette Edward Blunsom Phil de Freitas Nando Hermann Karl Moritz 20140429. A Deep Architecture for Semantic Parsing. arXiv  1404.7296  cs.CL .  Mesnil Gregoire Deng Li Gao Jianfeng He Xiaodong Shen Yelong April 2014. Learning Semantic Representations Using Convolutional Neural Networks for Web Search  Microsoft Research . Microsoft Research . Archived from the original on 20170915 . Retrieved 20151217 .  Kalchbrenner Nal Grefenstette Edward Blunsom Phil 20140408. A Convolutional Neural Network for Modelling Sentences. arXiv  1404.2188  cs.CL .  Kim Yoon 20140825. Convolutional Neural Networks for Sentence Classification. arXiv  1408.5882  cs.CL .  Collobert Ronan and Jason Weston.  A unified architecture for natural language processing Deep neural networks with multitask learning Archived 20190904 at the Wayback Machine .Proceedings of the 25th international conference on Machine learning. ACM 2008.  Collobert Ronan Weston Jason Bottou Leon Karlen Michael Kavukcuoglu Koray Kuksa Pavel 20110302. Natural Language Processing almost from Scratch. arXiv  1103.0398  cs.LG .  Yin W Kann K Yu M Schütze H 20170302. Comparative study of CNN and RNN for natural language processing. arXiv  1702.01923  cs.LG .  Bai S. Kolter J.S. Koltun V. 2018. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv  1803.01271  cs.LG .  Gruber N. 2021. Detecting dynamics of action in text with a recurrent neural network. Neural Computing and Applications . 33 12 15709 15718. doi  10.1007S00521021061905 . S2CID 236307579 .  Haotian J. Zhong Li Qianxiao Li 2021. Approximation Theory of Convolutional Architectures for Time Series Modelling. International Conference on Machine Learning . arXiv  2107.09355 .  Ren Hansheng Xu Bixiong Wang Yujing Yi Chao Huang Congrui Kou Xiaoyu Xing Tony Yang Mao Tong Jie Zhang Qi 2019. TimeSeries Anomaly Detection Service at Microsoft  Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery  Data Mining . arXiv  1906.03821 . doi  10.11453292500.3330680 . S2CID 182952311 .  Wallach Izhar Dzamba Michael Heifets Abraham 20151009. AtomNet A Deep Convolutional Neural Network for Bioactivity Prediction in Structurebased Drug Discovery. arXiv  1510.02855  cs.LG .  Yosinski Jason Clune Jeff Nguyen Anh Fuchs Thomas Lipson Hod 20150622. Understanding Neural Networks Through Deep Visualization. arXiv  1506.06579  cs.CV .  Toronto startup has a faster way to discover effective medicines . The Globe and Mail . Archived from the original on 20151020 . Retrieved 20151109 .  Startup Harnesses Supercomputers to Seek Cures . KQED Future of You . 20150527. Archived from the original on 20181206 . Retrieved 20151109 .  Chellapilla K Fogel DB 1999. Evolving neural networks to play checkers without relying on expert knowledge. IEEE Trans Neural Netw . 10 6 1382 91. doi  10.110972.809083 . PMID 18252639 .  Chellapilla K. Fogel D.B. 2001. Evolving an expert checkers playing program without using human expertise. IEEE Transactions on Evolutionary Computation . 5 4 422 428. doi  10.11094235.942536 .  Fogel David 2001. Blondie24 Playing at the Edge of AI . San Francisco CA Morgan Kaufmann. ISBN 9781558607835 .  Clark Christopher Storkey Amos 2014. Teaching Deep Convolutional Neural Networks to Play Go. arXiv  1412.3409  cs.AI .  Maddison Chris J. Huang Aja Sutskever Ilya Silver David 2014. Move Evaluation in Go Using Deep Convolutional Neural Networks. arXiv  1412.6564  cs.LG .  AlphaGo  Google DeepMind . Archived from the original on 30 January 2016 . Retrieved 30 January 2016 .  Bai Shaojie Kolter J. Zico Koltun Vladlen 20180419. An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. arXiv  1803.01271  cs.LG .  Yu Fisher Koltun Vladlen 20160430. MultiScale Context Aggregation by Dilated Convolutions. arXiv  1511.07122  cs.CV .  Borovykh Anastasia Bohte Sander Oosterlee Cornelis W. 20180917. Conditional Time Series Forecasting with Convolutional Neural Networks. arXiv  1703.04691  stat.ML .  Mittelman Roni 20150803. Timeseries modeling with undecimated fully convolutional neural networks. arXiv  1508.00317  stat.ML .  Chen Yitian Kang Yanfei Chen Yixiong Wang Zizhuo 20190611. Probabilistic Forecasting with Temporal Convolutional Neural Network. arXiv  1906.04397  stat.ML .  Zhao Bendong Lu Huanzhang Chen Shangfeng Liu Junliang Wu Dongya 20170201. Convolutional neural networks for time series classi. Journal of Systems Engineering and Electronics . 28 1 162 169. doi  10.21629JSEE.2017.01.18 .  Petneházi Gábor 20190821. QCNN Quantile Convolutional Neural Network. arXiv  1908.07978  cs.LG .  Hubert Mara 20190607 HeiCuBeDa Hilprecht  Heidelberg Cuneiform Benchmark Dataset for the Hilprecht Collection in German heiDATA  institutional repository for research data of Heidelberg University doi  10.11588dataIE8CCN  Hubert Mara and Bartosz Bogacz 2019 Breaking the Code on Broken Tablets The Learning Challenge for Annotated Cuneiform Script in Normalized 2D and 3D Datasets Proceedings of the 15th International Conference on Document Analysis and Recognition ICDAR in German Sydney Australien pp. 148 153 doi  10.1109ICDAR.2019.00032  ISBN 9781728130149  S2CID 211026941  Bogacz Bartosz Mara Hubert 2020 Period Classification of 3D Cuneiform Tablets with Geometric Neural Networks Proceedings of the 17th International Conference on Frontiers of Handwriting Recognition ICFHR  Dortmund Germany  Presentation of the ICFHR paper on Period Classification of 3D Cuneiform Tablets with Geometric Neural Networks on YouTube  Durjoy Sen Maitra Ujjwal Bhattacharya S.K. Parui CNN based common approach to handwritten character recognition of multiple scripts Archived 20231016 at the Wayback Machine  in Document Analysis and Recognition ICDAR 2015 13th International Conference on vol. no. pp.10211025 2326 Aug. 2015  NIPS 2017 . Interpretable ML Symposium . 20171020. Archived from the original on 20190907 . Retrieved 20180912 .  Zang Jinliang Wang Le Liu Ziyi Zhang Qilin Hua Gang Zheng Nanning 2018. AttentionBased Temporal Weighted Convolutional Neural Network for Action Recognition. Artificial Intelligence Applications and Innovations . IFIP Advances in Information and Communication Technology. Vol.\\xa0519. Cham Springer International Publishing. pp. 97 108. arXiv  1803.07179 . doi  10.10079783319920078_9 . ISBN 9783319920061 . ISSN 18684238 . S2CID 4058889 .  Wang Le Zang Jinliang Zhang Qilin Niu Zhenxing Hua Gang Zheng Nanning 20180621. Action Recognition by an AttentionAware Temporal Weighted Convolutional Neural Network PDF . Sensors . 18 7 1979. Bibcode  2018Senso..18.1979W . doi  10.3390s18071979 . ISSN 14248220 . PMC 6069475 . PMID 29933555 . Archived PDF from the original on 20180913 . Retrieved 20180914 .  Ong Hao Yi Chavez Kevin Hong Augustus 20150818. Distributed Deep QLearning. arXiv  1508.04186v2  cs.LG .  Mnih Volodymyr et\\xa0al. 2015. Humanlevel control through deep reinforcement learning. Nature . 518 7540 529 533. Bibcode  2015Natur.518..529M . doi  10.1038nature14236 . PMID 25719670 . S2CID 205242740 .  Sun R. Sessions C. June 2000. Selfsegmentation of sequences automatic formation of hierarchies of sequential behaviors. IEEE Transactions on Systems Man and Cybernetics  Part B Cybernetics . 30 3 403 418. CiteSeerX 10.1.1.11.226 . doi  10.11093477.846230 . ISSN 10834419 . PMID 18252373 .  Convolutional Deep Belief Networks on CIFAR10 PDF . Archived PDF from the original on 20170830 . Retrieved 20170818 .  Lee Honglak Grosse Roger Ranganath Rajesh Ng Andrew Y. 1 January 2009. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. Proceedings of the 26th Annual International Conference on Machine Learning . ACM. pp. 609 616. CiteSeerX 10.1.1.149.6800 . doi  10.11451553374.1553453 . ISBN 9781605585161 . S2CID 12008458 .  Behnke Sven 2003. Hierarchical Neural Networks for Image Interpretation PDF . Lecture Notes in Computer Science. Vol.\\xa02766. Springer. doi  10.1007b11963 . ISBN 9783540407225 . S2CID 1304548 . Archived PDF from the original on 20170810 . Retrieved 20161228 .  Cade Metz May 18 2016. Google Built Its Very Own Chips to Power Its AI Bots . Wired . Archived from the original on January 13 2018 . Retrieved March 6 2017 . External links  edit  CS231n Convolutional Neural Networks for Visual Recognition  Andrej Karpathy s Stanford computer science course on CNNs in computer vision vdumoulinconv_arithmetic A technical report on convolution arithmetic in the context of deep learning . Animations of convolutions. v t e Artificial intelligence AI History  timeline  Concepts Parameter Hyperparameter Loss functions Regression Biasvariance tradeoff Double descent Overfitting Clustering Gradient descent SGD QuasiNewton method Conjugate gradient method Backpropagation Attention Convolution Normalization Batchnorm Activation Softmax Sigmoid Rectifier Gating Weight initialization Regularization Datasets Augmentation Prompt engineering Reinforcement learning Qlearning SARSA Imitation Policy gradient Diffusion Latent diffusion model Autoregression Adversary RAG Uncanny valley RLHF Selfsupervised learning Recursive selfimprovement Word embedding Hallucination Applications Machine learning Incontext learning Artificial neural network Deep learning Language model Large language model NMT Artificial general intelligence Implementations Audiovisual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis 15.ai ElevenLabs Speech recognition Whisper Facial recognition AlphaFold Texttoimage models Aurora DALLE Firefly Flux Ideogram Imagen Midjourney Stable Diffusion Texttovideo models Dream Machine Gen4 Hailuo AI Kling Sora Veo Music generation Suno AI Udio Text Word2vec Seq2seq GloVe BERT T5 Llama Chinchilla AI PaLM GPT 1 2 3 J ChatGPT 4 4o o1 o3 4.5 Claude Gemini chatbot Grok LaMDA BLOOM Project Debater IBM Watson IBM Watsonx Granite PanGuΣ DeepSeek Qwen Decisional AlphaGo AlphaZero OpenAI Five Selfdriving car MuZero Action selection AutoGPT Robot control People Alan Turing Warren Sturgis McCulloch Walter Pitts John von Neumann Claude Shannon Marvin Minsky John McCarthy Nathaniel Rochester Allen Newell Cliff Shaw Herbert A. Simon Oliver Selfridge Frank Rosenblatt Bernard Widrow Joseph Weizenbaum Seymour Papert Seppo Linnainmaa Paul Werbos Jürgen Schmidhuber Yann LeCun Geoffrey Hinton John Hopfield Yoshua Bengio Lotfi A. Zadeh Stephen Grossberg Alex Graves Andrew Ng FeiFei Li Alex Krizhevsky Ilya Sutskever Demis Hassabis David Silver Ian Goodfellow Andrej Karpathy Architectures Neural Turing machine Differentiable neural computer Transformer Vision transformer ViT Recurrent neural network RNN Long shortterm memory LSTM Gated recurrent unit GRU Echo state network Multilayer perceptron MLP Convolutional neural network CNN Residual neural network RNN Highway network Mamba Autoencoder Variational autoencoder VAE Generative adversarial network GAN Graph neural network GNN Portals Technology Category Artificial neural networks Machine learning List Companies Projects', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e6ca3e70-f8c5-47a1-a6f9-775e5067e6e9', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Object_detection.txt', 'file_name': 'Object_detection.txt', 'file_type': 'text/plain', 'file_size': 11050, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Computer technology related to computer vision and image processing Objects detected with OpenCVs Deep Neural Network module dnn by using a YOLOv3 model trained on COCO dataset capable to detect objects of 80 common classes Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class such as humans buildings or cars in digital images and videos.  1  Wellresearched domains of object detection include face detection and pedestrian detection . Object detection has applications in many areas of computer vision including image retrieval and video surveillance . Uses  edit  Detection of objects on a road It is widely used in computer vision tasks such as image annotation   2  vehicle counting  3  activity recognition   4  face detection  face recognition  video object cosegmentation . It is also used in tracking objects  for example tracking a ball during a football match tracking movement of a cricket bat or tracking a person in a video. Often the test images are sampled from a different data distribution making the object detection task significantly more difficult.  5  To address the challenges caused by the domain gap between training and test data many unsupervised domain adaptation approaches have been proposed.  5   6   7   8   9  A simple and straightforward solution for reducing the domain gap is to apply an imagetoimage translation approach such as cycleGAN.  10  Among other uses crossdomain object detection is applied in autonomous driving where models can be trained on a vast amount of video game scenes since the labels can be generated without manual labor. Concept  edit  Every object class has its own special features that help in classifying the class  for example all circles are round.\\nObject class detection uses these special features. For example when looking for circles objects that are at a particular distance from a point i.e. the center are sought. Similarly when looking for squares objects that are perpendicular at corners and have equal side lengths are needed.  A similar approach is used for face identification where eyes nose and lips can be found and features like skin color and distance between eyes can be found. Benchmarks  edit  Intersection over union as a similarity measure for object detection on images\\xa0  an important task in computer vision . For object localization true positive is often measured by the thresholded intersection over union . For example if there is a traffic sign in the image with a bounding box drawn by a human ground truth label then a neural network has detected the traffic sign a true positive  at 0.5 threshold iff it has drawn a bounding box whose IoU with the ground truth is above 0.5. Otherwise the bounding box is a false positive . If there is only a single ground truth bounding box but multiple predictions then the IoU of each prediction is calculated. The prediction with the highest IoU is a true positive if it is above threshold else it is a false positive. All other predicted bounding boxes are false positives. If there is no prediction with an IoU above the threshold then the ground truth label has a false negative . For simultaneous object localization and classification a true positive is one where the class label is correct and the bounding box has an IoU exceeding the threshold. Simultaneous object localization and classification is benchmarked by the mean average precision mAP. The average precision AP of the network for a class of objects is the area under the precisionrecall curve as the IoU threshold is varied. The mAP is the average of AP over all classes. Methods  edit  Simplified example of training a neural network in object detection The network is trained by multiple images that are known to depict starfish and sea urchins  which are correlated with nodes that represent visual features . The starfish match with a ringed texture and a star outline whereas most sea urchins match with a striped texture and oval shape. However the instance of a ring textured sea urchin creates a weakly weighted association between them. Subsequent run of the network on an input image left  11  The network correctly detects the starfish. However the weakly weighted association between ringed texture and sea urchin also confers a weak signal to the latter from one of two intermediate nodes. In addition a shell that was not included in the training gives a weak signal for the oval shape also resulting in a weak signal for the sea urchin output. These weak signals may result in a false positive result for sea urchin. In reality textures and outlines would not be represented by single nodes but rather by associated weight patterns of multiple nodes. Methods for object detection generally fall into either neural networkbased or nonneural approaches. For nonneural approaches it becomes necessary to first define features using one of the methods below then using a technique such as support vector machine SVM to do the classification. On the other hand neural techniques are able to do endtoend object detection without specifically defining features and are typically based on convolutional neural networks CNN. Nonneural approaches ViolaJones object detection framework based on Haar features Scaleinvariant feature transform SIFT Histogram of oriented gradients HOG features  12  Neural network approaches OverFeat.  13  Region Proposals RCNN  14  Fast RCNN  15  Faster RCNN  16  cascade RCNN.  17   You Only Look Once YOLO.  18  Single Shot MultiBox Detector SSD  19  SingleShot Refinement Neural Network for Object Detection RefineDet  20  RetinaNet  21   17  Deformable convolutional networks  22   23  See also  edit  Feature detection computer vision Moving object detection Small object detection Outline of object recognition TeknomoFernandez algorithm References  edit   Dasiopoulou Stamatia et al.  Knowledgeassisted semantic video object detection . IEEE Transactions on Circuits and Systems for Video Technology 15.10 2005 12101224.  Ling Guan Yifeng He SunYuan Kung 1 March 2012. Multimedia Image and Video Processing . CRC Press. pp.\\xa0331. ISBN 9781439830871 .  Alsanabani Ala Ahmed Mohammed AL Smadi Ahmad 2020. Vehicle Counting Using DetectingTracking Combinations A Comparative Analysis. 2020 the 4th International Conference on Video and Image Processing . pp. 48 54. doi  10.11453447450.3447458 . ISBN 9781450389075 . S2CID 233194604 .  Wu Jianxin Osuntogun Adebola Choudhury Tanzeem Philipose Matthai Rehg James M. 2007. A Scalable Approach to Activity Recognition based on Object Use. 2007 IEEE 11th International Conference on Computer Vision . pp. 1 8. doi  10.1109ICCV.2007.4408865 . ISBN 9781424416301 .  a b Oza Poojan Sindagi Vishwanath A. VS Vibashan Patel Vishal M. 20210704. Unsupervised Domain Adaptation of Object Detectors A Survey. arXiv  2105.13502  cs.CV .  Khodabandeh Mehran Vahdat Arash Ranjbar Mani Macready William G. 20191118. A Robust Learning Approach to Domain Adaptive Object Detection. arXiv  1904.02361  cs.LG .  Soviany Petru Ionescu Radu Tudor Rota Paolo Sebe Nicu 20210301. Curriculum selfpaced learning for crossdomain object detection . Computer Vision and Image Understanding . 204  103166. arXiv  1911.06849 . doi  10.1016j.cviu.2021.103166 . ISSN 10773142 . S2CID 208138033 .  Menke Maximilian Wenzel Thomas Schwung Andreas October 2022. Improving GANbased Domain Adaptation for Object Detection . 2022 IEEE 25th International Conference on Intelligent Transportation Systems ITSC . pp. 3880 3885. doi  10.1109ITSC55140.2022.9922138 . ISBN 9781665468800 . S2CID 253251380 .  Menke Maximilian Wenzel Thomas Schwung Andreas 20220831. AWADA AttentionWeighted Adversarial Domain Adaptation for Object Detection. arXiv  2208.14662  cs.CV .  Zhu JunYan Park Taesung Isola Phillip Efros Alexei A. 20200824. Unpaired ImagetoImage Translation using CycleConsistent Adversarial Networks. arXiv  1703.10593  cs.CV .  Ferrie C.  Kaiser S. 2019. Neural Networks for Babies . Sourcebooks. ISBN 9781492671206 .  cite book    CS1 maint multiple names authors list  link   Dalal Navneet 2005. Histograms of oriented gradients for human detection PDF . Computer Vision and Pattern Recognition . 1 .  Sermanet Pierre Eigen David Zhang Xiang Mathieu Michael Fergus Rob LeCun Yann 20140223. OverFeat Integrated Recognition Localization and Detection using Convolutional Networks. arXiv  1312.6229  cs.CV .  Ross Girshick 2014. Rich feature hierarchies for accurate object detection and semantic segmentation PDF . Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . IEEE. pp. 580 587. arXiv  1311.2524 . doi  10.1109CVPR.2014.81 . ISBN 9781479951185 . S2CID 215827080 .  Girschick Ross 2015. Fast RCNN PDF . Proceedings of the IEEE International Conference on Computer Vision . pp. 1440 1448. arXiv  1504.08083 .  Shaoqing Ren 2015. Faster RCNN. Advances in Neural Information Processing Systems . arXiv  1506.01497 .  a b Pang Jiangmiao Chen Kai Shi Jianping Feng Huajun Ouyang Wanli Lin Dahua 20190404. Libra RCNN Towards Balanced Learning for Object Detection. arXiv  1904.02701v1  cs.CV .  Redmon Joseph Divvala Santosh Girshick Ross Farhadi Ali 20160509. You Only Look Once Unified RealTime Object Detection. arXiv  1506.02640  cs.CV .  Liu Wei October 2016. SSD Single Shot MultiBox Detector. Computer Vision  ECCV 2016 . Lecture Notes in Computer Science. Vol.\\xa09905. pp. 21 37. arXiv  1512.02325 . doi  10.10079783319464480_2 . ISBN 9783319464473 . S2CID 2141740 .  Zhang Shifeng 2018. SingleShot Refinement Neural Network for Object Detection. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . pp. 4203 4212. arXiv  1711.06897 .  Lin TsungYi 2020. Focal Loss for Dense Object Detection. IEEE Transactions on Pattern Analysis and Machine Intelligence . 42 2 318 327. arXiv  1708.02002 . doi  10.1109TPAMI.2018.2858826 . PMID 30040631 . S2CID 47252984 .  Zhu Xizhou 2018. Deformable ConvNets v2 More Deformable Better Results. arXiv  1811.11168  cs.CV .  Dai Jifeng 2017. Deformable Convolutional Networks. arXiv  1703.06211  cs.CV . Object Class Detection . Vision.eecs.ucf.edu. Archived from the original on 20130714 . Retrieved 20131009 . ETHZ  Computer Vision Lab Publications . Vision.ee.ethz.ch. Archived from the original on 20130603 . Retrieved 20131009 . External links  edit  Weng Lilian 20171029. Object Detection for Dummies Part 1 Gradient Vector HOG and SS . lilianweng.github.io . Retrieved 20240911 . Weng Lilian 20171215. Object Detection for Dummies Part 2 CNN DPM and Overfeat . lilianweng.github.io . Retrieved 20240911 . Weng Lilian 20171231. Object Detection for Dummies Part 3 RCNN Family . lilianweng.github.io . Retrieved 20240911 . Weng Lilian 20181227. Object Detection Part 4 Fast Detection Models . lilianweng.github.io . Retrieved 20240911 . Multiple object class detection Spatiotemporal action localization Online Object Detection Demo Video object detection and cosegmentation', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ade0a425-cc6e-4d9f-b45d-07cc7567df31', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Unmanned_aerial_vehicle.txt', 'file_name': 'Unmanned_aerial_vehicle.txt', 'file_type': 'text/plain', 'file_size': 104466, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Aircraft without any human pilot on board UAV redirects here. For other uses see UAV disambiguation . Elbit Systems Hermes 450 taking off Northrop Grumman Bat carrying EOIR and SAR sensors laser rangefinders laser designators infrared cameras Anka3  Hürjet and Hürkuş . A General Atomics MQ9 Reaper  a hunterkiller surveillance UAV Although most large military UAVs are fixedwing aircraft  rotorcraft designs i.e. RUAVs such as this MQ8B Fire Scout are also used. An unmanned aerial vehicle  UAV  or unmanned aircraft system  UAS  commonly known as a drone  is an aircraft with no human pilot  crew or passengers onboard but rather is controlled remotely or is autonomous.  1  UAVs were originally developed through the twentieth century for military missions too dull dirty or dangerous  2  for humans and by the twentyfirst they had become essential assets to most militaries. As control technologies improved and costs fell their use expanded to many nonmilitary applications.  3  These include aerial photography  area coverage  4  precision agriculture  forest fire monitoring  5  river monitoring  6   7  environmental monitoring   8   9   10   11  weather observation  policing and surveillance infrastructure inspections smuggling  12  product deliveries  entertainment drone racing  and combat . Terminology  edit  Many terms are used for aircraft which fly without any persons onboard. The term drone has been used from the early days of aviation  some being applied to remotely flown target aircraft used for practice firing of a battleships guns such as the 1920s Fairey Queen and 1930s de Havilland Queen Bee . Later examples included the Airspeed Queen Wasp and Miles Queen Martinet  before ultimate replacement by the GAF Jindivik .  13  The term remains in common use.  In addition to the software autonomous drones also employ a host of advanced technologies that allow them to carry out their missions without human intervention such as cloud computing computer vision artificial intelligence machine learning deep learning and thermal sensors.  14  For recreational uses an aerial photography drone is an aircraft that has firstperson video autonomous capabilities or both.  15  An unmanned aerial vehicle  UAV  is defined as a powered aerial vehicle that does not carry a human operator uses aerodynamic forces to provide vehicle lift can fly autonomously or be piloted remotely can be expendable or recoverable and can carry a lethal or nonlethal payload.  16  UAV is a term that is commonly applied to military use cases.  17  Missiles with warheads are generally not considered UAVs because the vehicle itself is a munition but certain types of propellerbased missile are often called  kamikaze drones  by the public and media. Also the relation of UAVs to remote controlled model aircraft is unclear in some jurisdictions.  The US FAA now defines any unmanned flying craft as a UAV regardless of weight.  18  A similar term is remotely piloted aerial vehicle  RPAV . UAVs or RPAVs can also be seen as a component of an unmanned aircraft system  UAS  which also includes a groundbased controller and a system of communications with the aircraft.  5  The term UAS was adopted by the United States Department of Defense DoD and the United States Federal Aviation Administration FAA in 2005 according to their Unmanned Aircraft System Roadmap 20052030.  19  The International Civil Aviation Organization ICAO and the British Civil Aviation Authority adopted this term also used in the European Unions Single European Sky SES Air Traffic Management ATM Research SESAR Joint Undertaking roadmap for 2020.  20  This term emphasizes the importance of elements other than the aircraft. It includes elements such as ground control stations data links and other support equipment. Similar terms are unmanned aircraft vehicle system  UAVS  and remotely piloted aircraft system  RPAS .  21  Many similar terms are in use. Under new regulations which came into effect 1 June 2019 the term RPAS has been adopted by the Canadian Government to mean a set of configurable elements consisting of a remotely piloted aircraft its control station the command and control links and any other system elements required during flight operation.  22   Uncrewed  is sometimes used rather than Unmanned.  23   24   25  Classification types  edit  UAVs may be classified like any other aircraft  according to design configuration such as weight or engine type maximum flight altitude degree of operational autonomy operational role etc. According to the United States Department of Defense  UAVs are classified into five categories below  26   27  Group Group 1 Group 2 Group 3 Group 4 Group 5 Size Small Medium Large Larger Largest Max takeoff weight  20\\xa0lb 9.1\\xa0kg  20   55  55   1320  1320\\xa0lb 600\\xa0kg  1320\\xa0lb 600\\xa0kg Operating altitude  1200\\xa0ft 370\\xa0m  3500\\xa0ft 1100\\xa0m  18000\\xa0ft 5500\\xa0m  18000\\xa0ft 5500\\xa0m  18000\\xa0ft 5500\\xa0m Speed  100\\xa0kn 190\\xa0kmh  250\\xa0kn 460\\xa0kmh  250\\xa0kn 460\\xa0kmh Any speed Any speed Other classifications of UAVs include  26  Range and endurance  edit  There are usually five categories when UAVs are classified by range and endurance  26  Range category Very close Close Short Medium Long Range km   5  5   50  50   150  150   650  650 Endurance hr  0.5  0.75 16 812 1236 or 48  36 or 48 Size  edit  There are usually four categories when UAVs are classified by size with at least one of the dimensions length or wingspan meet the following respective limits  26  Category MicroVery small MiniSmall Medium Large Lengthwingspan   50\\xa0cm  50\\xa0cm   2 m 5 10 m  10 m Weight  edit  Based on their weight drones can be classified into five categories Drone categories  28  Category Nano Micro MAV Miniature or Small SUAV Medium Large Weight   250\\xa0gm  250\\xa0gm   02 \\xa0kg  02\\xa0kg   25 \\xa0kg  25\\xa0kg   150 \\xa0kg  150\\xa0kg NATO uses a similar classification shown below  1  NATO classification of Unmanned Aerial Vehicles . Degree of autonomy  edit  Drones can also be classified based on the degree of autonomy in their flight operations. ICAO classifies unmanned aircraft as either remotely piloted aircraft or fully autonomous.  29  Some UAVs offer intermediate degrees of autonomy. For example a vehicle may be remotely piloted in most contexts but have an autonomous returntobase operation. Some aircraft types may optionally fly manned or as UAVs which may include manned aircraft transformed into manned or Optionally Piloted UAVs OPVs. The flight of UAVs may operate under remote control by a human operator as remotely piloted aircraft  RPA  or with various degrees of autonomy  such as autopilot assistance up to fully autonomous aircraft that have no provision for human intervention.  30   31  Altitude  edit  Based on the altitude the following UAV classifications have been used at industry events such as ParcAberporth Unmanned Systems forum Handheld 2000\\xa0ft 600\\xa0m altitude about 2\\xa0km range Close 5000\\xa0ft 1500\\xa0m altitude up to 10\\xa0km range NATO type 10000\\xa0ft 3000\\xa0m altitude up to 50\\xa0km range Tactical 18000\\xa0ft 5500\\xa0m altitude about 160\\xa0km range MALE medium altitude long endurance up to 30000\\xa0ft 9000\\xa0m and range over 200\\xa0km HALE high altitude long endurance over 30000\\xa0ft 9100\\xa0m and indefinite range Hypersonic highspeed supersonic Mach 15 or hypersonic Mach 5 50000\\xa0ft 15200\\xa0m or suborbital altitude range over 200\\xa0km Orbital low Earth orbit Mach 25 CIS Lunar EarthMoon transfer Computer Assisted Carrier Guidance System CACGS for UAVs Composite criteria  edit  An example of classification based on the composite criteria is U.S. Militarys unmanned aerial systems UAS classification of UAVs based on weight maximum altitude and speed of the UAV component. Power sources  edit  UAVs can be classified based on their power or energy source which significantly impacts their flight duration range and environmental impact. The main categories include Batterypowered electric These UAVs use rechargeable batteries offering quiet operation and lower maintenance but potentially limited flight times. The reduced noise levels make them suitable for urban environments and sensitive operations.  32  Fuelpowered internal combustion Utilizing traditional fuels like gasoline or diesel these UAVs often have longer flight times but may be noisier and require more maintenance. They are typically used for applications requiring extended endurance or heavy payload capacity.  33  Hybrid Combining electric and fuel power sources hybrid UAVs aim to balance the benefits of both systems for improved performance and efficiency. This configuration could allow for versatility in mission profiles and adaptability to different operational requirements.  34  Hydrogen fuel cell hydrogen fuel cells offer the potential for longer flight times than batteries yet stealthier no heat signature operation than combustion engines.  35  The high energy density of hydrogen makes it a promising option for future UAV propulsion systems.  36  Solarpowered Equipped with solar panels these UAVs can potentially achieve extended flight times by harnessing solar energy especially at high altitudes. Solarpowered UAVs may be particularly suited for longendurance missions and environmental monitoring applications.  37  Nuclearpowered While nuclear power has been explored for larger aircraft its application in UAVs remains largely theoretical due to safety concerns and regulatory challenges. Research in this area is ongoing but faces significant hurdles before practical implementation.  38  History  edit  Main article History of unmanned aerial vehicles Winston Churchill and others waiting to watch the launch of a de Havilland Queen Bee target drone  6 June 1941 A Ryan Firebee  one of a series of target dronesunpiloted aerial vehicles that first flew in 1951. Israeli Air Force Museum  Hatzerim airbase Israel 2006 Last preparations before the first tactical UAV mission across the Suez Canal 1969. Standing Major Shabtai Brill from the Israeli Intelligence Corps the innovator of the tactical UAV. The Israeli Tadiran Mastiff  which first flew in 1975 is seen by many as the first modern battlefield UAV due to its datalink system enduranceloitering and live videostreaming.  39  Early drones  edit  The earliest recorded use of an unmanned aerial vehicle for warfighting occurred in July 1849  40  with a balloon carrier the precursor to the aircraft carrier   41  in the first offensive use of air power in naval aviation .  42   43   44  Austrian forces besieging Venice attempted to launch some 200 incendiary balloons at the besieged city. The balloons were launched mainly from land however some were also launched from the Austrian ship SMS Vulcano . At least one bomb fell in the city however due to the wind changing after launch most of the balloons missed their target and some drifted back over Austrian lines and the launching ship Vulcano .  45   46   47  The Spanish engineer Leonardo Torres Quevedo introduced a radiobased controlsystem called the Telekino  48  at the Paris Academy of Science in 1903 as a way of testing airships without risking human life.  49   50   51  Significant development of drones started in the 1900s and originally focused on providing practice targets for training military personnel . The earliest attempt at a powered UAV was A. M. Low s Aerial Target in 1916.  52  Low confirmed that Geoffrey de Havillands monoplane was the one that flew under control on 21 March 1917 using his radio system.  53  Following this successful demonstration in the spring of 1917 Low was transferred to develop aircraft controlled fast motor launches D.C.B.s with the Royal Navy in 1918 intended to attack shipping and port installations and he also assisted Wing Commander Brock in preparations for the Zeebrugge Raid . Other British unmanned developments followed leading to the fleet of over 400 de Havilland 82 Queen Bee aerial targets that went into service in 1935. Nikola Tesla described a fleet of uncrewed aerial combat vehicles in 1915.  54  These developments also inspired the construction of the Kettering Bug by Charles Kettering from Dayton Ohio and the HewittSperry Automatic Airplane  initially meant as an uncrewed plane that would carry an explosive payload to a predetermined target. Development continued during World War I when the DaytonWright Airplane Company invented a pilotless aerial torpedo that would explode at a preset time.  55  The film star and modelairplane enthusiast Reginald Denny developed the first scaled remote piloted vehicle in 1935.  52  Soviet researchers experimented with controlling Tupolev TB1 bombers remotely in the late 1930s.  56  World War II  edit  In 1940 Denny started the Radioplane Company and more models emerged during World War II   used both to train antiaircraft gunners and to fly attackmissions. Nazi Germany produced and used various UAV aircraft during the war like the Argus As 292 and the V1 flying bomb with a jet engine . Fascist Italy developed a specialised drone version of the SavoiaMarchetti SM.79 flown by remote control although the Armistice with Italy was enacted prior to any operational deployment.  57  Postwar period  edit  After World War II development continued in vehicles such as the American JB4 using televisionradiocommand guidance the Australian GAF Jindivik and Teledyne Ryan Firebee I of 1951 while companies like Beechcraft offered their Model 1001 for the U.S. Navy in 1955.  52  Nevertheless they were little more than remotecontrolled airplanes until the Vietnam War . In 1959 the U.S. Air Force  concerned about losing pilots over hostile territory began planning for the use of uncrewed aircraft.  58  Planning intensified after the Soviet Union shot down a U2 in 1960. Within days a highly classified UAV program started under the code name of Red Wagon.  59  The August 1964 clash in the Tonkin Gulf between naval units of the U.S. and the North Vietnamese Navy initiated Americas highly classified UAVs  Ryan Model 147  Ryan AQM91 Firefly  Lockheed D21  into their first combat missions of the Vietnam War .  60  When the Chinese government  61  showed photographs of downed U.S. UAVs via Wide World Photos   62  the official U.S. response was no comment. During the War of Attrition 19671970 in the Middle East Israeli intelligence tested the first tactical UAVs installed with reconnaissance cameras which successfully returned photos from across the Suez Canal. This was the first time that tactical UAVs that could be launched and landed on any short runway unlike the heavier jetbased UAVs were developed and tested in battle.  63  In the 1973 Yom Kippur War  Israel used UAVs as decoys to spur opposing forces into wasting expensive antiaircraft missiles.  64  After the 1973 Yom Kippur War a few key people from the team that developed this early UAV joined a small startup company that aimed to develop UAVs into a commercial product eventually purchased by Tadiran and leading to the development of the first Israeli UAV.  65   pages\\xa0needed  In 1973 the U.S. military officially confirmed that they had been using UAVs in Southeast Asia Vietnam.  66  Over 5000 U.S. airmen had been killed and over 1000 more were missing or captured . The USAF 100th Strategic Reconnaissance Wing flew about 3435 UAV missions during the war  67  at a cost of about 554 UAVs lost to all causes. In the words of USAF General George S. Brown  Commander Air Force Systems Command  in 1972 The only reason we need UAVs is that we dont want to needlessly expend the man in the cockpit.  68  Later that year General John C. Meyer  Commander in Chief Strategic Air Command  stated we let the drone do the highrisk flying\\xa0... the loss rate is high but we are willing to risk more of them\\xa0...they save lives  68  During the 1973 Yom Kippur War  Sovietsupplied surfacetoair missile batteries in Egypt and Syria caused heavy damage to Israeli fighter jets . As a result Israel developed the IAI Scout as the first UAV with realtime surveillance.  69   70   71  The images and radar decoys provided by these UAVs helped Israel to completely neutralize the Syrian air defenses at the start of the 1982 Lebanon War  resulting in no pilots downed.  72  In Israel in 1987 UAVs were first used as proofofconcept of superagility poststall controlled flight in combatflight simulations that involved tailless stealthtechnologybased threedimensional thrust vectoring flightcontrol and jetsteering.  73  Modern UAVs  edit  The Turkish STM Kargu was the first lethal autonomous weapon to attack enemy combatants in warfare. With the maturing and miniaturization of applicable technologies in the 1980s and 1990s interest in UAVs grew within the higher echelons of the U.S. military. The U.S. funded the Counterterrorism Center CTC within the CIA which sought to fight terrorism with the aid of modernized drone technology.  74  In the 1990s the U.S. DoD gave a contract to AAI Corporation along with Israeli company Malat. The U.S. Navy bought the AAI Pioneer UAV that AAI and Malat developed jointly. Many of these UAVs saw service in the 1991 Gulf War . UAVs demonstrated the possibility of cheaper more capable fightingmachines deployable without risk to aircrews. Initial generations primarily involved surveillance aircraft  but some carried armaments  such as the General Atomics MQ1 Predator  that launched AGM114 Hellfire airtoground missiles . CAPECON  a European Union project to develop UAVs  75  ran from 1 May 2002 to 31 December 2005.  76  As of 2012 update  the United States Air Force USAF employed 7494 UAVs\\xa0  almost one in three USAF aircraft.  77   78  The Central Intelligence Agency also operated UAVs .  79  By 2013 at least 50 countries used UAVs. China Iran Israel Pakistan Turkey and others designed and built their own varieties. The use of drones has continued to increase.  80  Due to their wide proliferation no comprehensive list of UAV systems exists.  78   81  The development of smart technologies and improved electricalpower systems led to a parallel increase in the use of drones for consumer and general aviation activities. As of 2021 update  quadcopter drones exemplify the widespread popularity of hobby radiocontrolled aircraft and toys but the use of UAVs in commercial and general aviation is limited by a lack of autonomy  clarification needed  and by new regulatory environments which require lineofsight contact with the pilot.  citation needed  In 2020 a Kargu 2 drone hunted down and attacked a human target in Libya  according to a report from the UN Security Council s Panel of Experts on Libya published in March 2021. This may have been the first time an autonomous killerrobot armed with lethal weaponry attacked human beings.  82  Superior drone technology specifically the Turkish Bayraktar TB2  played a role in Azerbaijans successes in the 2020 NagornoKarabakh war against Armenia.  83  Artists concept of Ingenuity landing on Mars UAVs are also used in NASA missions. The Ingenuity helicopter is an autonomous UAV that operated on Mars from 2021 to 2024. As of 2024 update the Dragonfly spacecraft is being developed and is aiming to reach and examine Saturn s moon Titan . Its primary goal is to roam around the surface expanding the amount of area to be researched previously seen by landers . As a UAV Dragonfly allows examination of potentially diverse types of soil. The drone is set to launch in 2027 and is estimated to take seven more years to reach the Saturnian system. Miniaturization is also supporting the development of small UAVs which can be used as individual system or in a fleet offering the possibility to survey large areas in a relatively small amount of time.  84  According to data from GlobalData  the global military uncrewed aerial systems UAS market which forms a significant part of the UAV industry is projected to experience a compound annual growth rate of 4.8 over the next decade. This represents a near doubling in market size from 12.5 billion in 2024 to an estimated 20 billion by 2034.  85  Design  edit  General physical structure of a UAV Crewed and uncrewed aircraft of the same type generally have recognizably similar physical components. The main exceptions are the cockpit and environmental control system or life support systems . Some UAVs carry payloads such as a camera that weigh considerably less than an adult human and as a result can be considerably smaller. Though they carry heavy payloads weaponized military UAVs are lighter than their crewed counterparts with comparable armaments. Small civilian UAVs have no lifecritical systems  and can thus be built out of lighter but less sturdy materials and shapes and can use less robustly tested electronic control systems. For small UAVs the quadcopter design has become popular though this layout is rarely used for crewed aircraft. Miniaturization means that lesspowerful propulsion technologies can be used that are not feasible for crewed aircraft such as small electric motors and batteries. Control systems for UAVs are often different from crewed craft. For remote human control a camera and video link almost always replace the cockpit windows radiotransmitted digital commands replace physical cockpit controls. Autopilot software is used on both crewed and uncrewed aircraft with varying feature sets.  86   87   88  Aircraft configuration  edit  UAVs can be designed in different configurations than manned aircraft both because there is no need for a cockpit and its windows and there is no need to optimize for human comfort although some UAVs are adapted from piloted examples or are designed for optionally piloted modes. Air safety is also less of a critical requirement for unmanned aircraft allowing the designer greater freedom to experiment. Instead UAVs are typically designed around their onboard payloads and their ground equipment. These factors have led to a great variety of airframe and motor configurations in UAVs. For conventional flight the flying wing and blended wing body offer light weight combined with low drag and stealth  and are popular configurations for many use cases. Larger types which carry a variable payload are more likely to feature a distinct fuselage with a tail for stability control and trim although the wing configurations in use vary widely. For uses that require vertical flight or hovering the tailless quadcopter requires a relatively simple control system and is common for smaller UAVs. Multirotor designs with 6 or more rotors is more common with larger UAVs where redundancy is prioritized.  89   90  Propulsion  edit  Traditional internal combustion and jet engines remain in use for drones requiring long range. However for shorterrange missions electric power has almost entirely taken over. The distance record for a UAV built from balsa wood and mylar skin across the North Atlantic Ocean is held by a gasoline model airplane or UAV. Manard Hill in 2003 when one of his creations flew 1882 miles across the Atlantic Ocean on less than a gallon of fuel holds this record.  91  Besides the traditional piston engine the Wankel rotary engine is used by some drones. This type offers high power output for lower weight with quieter and more vibrationfree running. Claims have also been made for improved reliability and greater range.  citation needed  Small drones mostly use lithiumpolymer batteries LiPo while some larger vehicles have adopted the hydrogen fuel cell .  92   93   94  Hydrogen fueled protonexchange membrane fuel cells for UAVs have the advantages of longer flight duration than rechargeable lithiumion batteries  of lower total cost of ownership than primary lithium metal batteries and of better stealth than heat engines .  95  The energy density of modern LiPo batteries is far less than gasoline or hydrogen. However electric motors are cheaper lighter and quieter. Complex multiengine multipropeller installations are under development with the goal of improving aerodynamic and propulsive efficiency. For such complex power installations battery elimination circuitry BEC may be used to centralize power distribution and minimize heating under the control of a microcontroller unit MCU. Ornithopters  wing propulsion  edit  Flappingwing ornithopters  imitating birds or insects have been flown as microUAVs . Their inherent stealth recommends them for spy missions. Sub1g microUAVs inspired by flies albeit using a power tether have been able to land on vertical surfaces.  96  Other projects mimic the flight of beetles and other insects.  97  Computer control systems  edit  A flight controller run on either CleanFlight or BaseFlight firmware for multirotor UAVs UAV computing capability followed the advances of computing technology beginning with analog controls and evolving into microcontrollers then systemonachip SOC and singleboard computers SBC. Modern system hardware for UAV control is often called the flight controller FC flight controller board FCB or autopilot. Common UAVsystems control hardware typically incorporate a primary microprocessor a secondary or failsafe processor and sensors such as accelerometers gyroscopes magnetometers and barometers into a single module. In 2024 EASA agreed on the first certification basis for a UAV flight controller in compliance with the ETSOC198 for Embentions autopilot. The certification of the UAV flight control systems aims to facilitate the integration of UAVs within the airspace and the operation of drones in critical areas.  98  Architecture  edit  Sensors  edit  Position and movement sensors give information about the aircraft state. Exteroceptive sensors deal with external information like distance measurements while exproprioceptive ones correlate internal and external states.  99  Noncooperative sensors are able to detect targets autonomously so they are used for separation assurance and collision avoidance.  100  Degrees of freedom DOF refers to both the amount and quality of onboard sensors 6 DOF implies 3axis gyroscopes and accelerometers a typical inertial measurement unit   IMU 9 DOF refers to an IMU plus a compass 10 DOF adds a barometer and 11 DOF usually adds a GPS receiver.  101  In addition to the navigation sensors the UAV or UAS can be also equipped with monitoring devices such as RGB  multispectral  hyperspectral cameras or LiDAR  which may allow providing specific measurements or observations.  102  Actuators  edit  UAV actuators include digital electronic speed controllers which control the RPM of the motors linked to motors engines and propellers  servomotors for planes and helicopters mostly weapons payload actuators LEDs and speakers. Software  edit  Modern UAVs run a software stack that ranges from lowlevel firmware that directly controls actuators to high level flight planning. At the lowest level firmware directly controls reading from sensors such as an IMU  103  and commanding actuators such as motors. Control software often referred to as an autopilot is responsible for computing actuator speeds given desired vehicle velocity. Due to its direct interaction with hardware this software is timecritical and may run on microcontrollers . This software may also handle radio communications in the case of UAVs that are not autonomous. One popular example is the PX4 autopilot. At the next level autonomy algorithms compute the desired velocity given higher level goals. For example trajectory optimization  104  may be used to calculate a flight trajectory given a desired goal location. This software is not necessarily timecritical and can often run on a single board computer running an operating system such as Linux with relaxed time constraints. Loop principles  edit  Typical flightcontrol loops for a multirotor UAVs employ openloop closedloop or hybrid control architectures. Open loop   This type provides a positive control signal faster slower left right up down without incorporating feedback from sensor data. Closed loop   This type incorporates sensor feedback to adjust behavior reduce speed to reflect tailwind move to altitude 300 feet. The PID controller is common. Sometimes feedforward is employed transferring the need to close the loop further.  105  Communications  edit  UAVs use a radio for control and exchange of video and other data . Early UAVs had only narrowband uplink. Downlinks came later. These bidirectional narrowband radio links carried command and control CC and telemetry data about the status of aircraft systems to the remote operator. In most modern UAV applications video transmission is required. So instead of having separate links for CC telemetry and video traffic a broadband link is used to carry all types of data. These broadband links can leverage quality of service techniques and carry TCPIP traffic that can be routed over the internet. The radio signal from the operator side can be issued from either Ground control  a human operating a radio transmitter receiver a smartphone a tablet a computer or the original meaning of a military ground control station GCS . Remote network system such as satellite duplex data links for some military powers . Downstream digital video over mobile networks has also entered consumer markets while direct UAV control uplink over the cellular mesh and LTE have been demonstrated and are in trials.  106  Another aircraft serving as a relay or mobile control station\\xa0  military mannedunmanned teaming MUMT.  107  Modern networking standards have explicitly considered drones and therefore include optimizations. The 5G standard has mandated reduced user plane latency to 1ms while using ultrareliable and lowlatency communications.  108  UAVtoUAV coordination supported by Remote ID communication technology. Remote ID messages containing the UAV coordinates are broadcast and can be used for collisionfree navigation.  109  Autonomy  edit  Main article Autonomous aircraft UAVs degrees of autonomy The level of autonomy in UAVs varies widely. UAV manufacturers often build in specific autonomous operations such as  110  Selflevel attitude stabilization on the pitch and roll axes. Altitude hold The aircraft maintains its altitude using barometric pressure andor GPS data. Hoverposition hold Keep level pitch and roll stable yaw heading and altitude while maintaining position using GNSS or inertial sensors. Headless mode Pitch control relative to the position of the pilot rather than relative to the vehicles axes. Carefree automatic roll and yaw control while moving horizontally Takeoff and landing using a variety of aircraft or groundbased sensors and systems see also  autoland  Failsafe automatic landing or returntohome upon loss of control signal Returntohome Fly back to the point of takeoff often gaining altitude first to avoid possible intervening obstructions such as trees or buildings. Followme Maintain relative position to a moving pilot or other object using GNSS image recognition or homing beacon. GPS waypoint navigation Using GNSS to navigate to an intermediate location on a travel path. Orbit around an object Similar to Followme but continuously circle a target. Preprogrammed aerobatics such as rolls and loops Preprogrammed delivery delivery drones One approach to quantifying autonomous capabilities is based on OODA terminology as suggested by a 2002 US Air Force Research Laboratory report and used in the table on the right.  111  A Northrop Grumman X47B unmanned combat aircraft demonstrator of the US Navy refuels in flight from a tanker aircraft. Full autonomy is available for specific tasks such as airborne refueling  112  or groundbased battery switching. Other functions available or under development include collective flight realtime collision avoidance  wall following corridor centring simultaneous localization and mapping and swarming   113  cognitive radio  and machine learning . In this context computer vision can play an important role for automatically ensuring flight safety. Performance considerations  edit  Flight envelope  edit  UAVs can be programmed to perform aggressive maneuvers or landingperching on inclined surfaces  114  and then to climb toward better communication spots.  115  Some UAVs can control flight with varying flight modelisation  116   117  such as VTOL designs. UAVs can also implement perching on a flat vertical surface.  118  Endurance  edit  UEL UAV741 Wankel engine for UAV operations used on AAI RQ7 Shadow Flight time against mass of small less than 1\\xa0kg drones  99  UAV endurance is not constrained by the physiological capabilities of a human pilot. Because of their small size low weight low vibration and high power to weight ratio Wankel rotary engines are used in many large UAVs. Their engine rotors cannot seize the engine is not susceptible to shockcooling during descent and it does not require an enriched fuel mixture for cooling at high power. These attributes reduce fuel usage increasing range or payload. Proper drone cooling is essential for longterm drone endurance. Overheating and subsequent engine failure is the most common cause of drone failure.  119  Hydrogen fuel cells  using hydrogen power may be able to extend the endurance of small UAVs up to several hours.  120   121  Micro air vehicles endurance is so far best achieved with flappingwing UAVs followed by planes and multirotors standing last due to lower Reynolds number .  99  Solarelectric UAVs a concept originally championed by the AstroFlight Sunrise in 1974 have achieved flight times of several weeks. Solarpowered atmospheric satellites atmosats designed for operating at altitudes exceeding 20\\xa0km 12 miles or 60000 feet for as long as five years could potentially perform duties more economically and with more versatility than low Earth orbit satellites. Likely applications include weather drones for weather monitoring  disaster recovery  Earth imaging and communications. Electric UAVs powered by microwave power transmission or laser power beaming are other potential endurance solutions.  122  Another application for a high endurance UAV would be to stare at a battlefield for a long interval ARGUSIS Gorgon Stare Integrated Sensor Is Structure to record events that could then be played backwards to track battlefield activities. Lengthy endurance flights UAV Flight time hoursminutes Date Notes Boeing Condor 5811 1989 The aircraft is currently in the Hiller Aviation Museum .  123  General Atomics Gnat 4000 1992  124   125  TAM5 3852 11 August 2003 Smallest UAV to cross the Atlantic  126  QinetiQ Zephyr Solar Electric 5400 September 2007  127   128  RQ4 Global Hawk 3306 22 March 2008 Set an endurance record for a fullscale operational uncrewed aircraft.  129  QinetiQ Zephyr Solar Electric 8237 2831 July 2008  130  QinetiQ Zephyr 7 33622 923 July 2010 Solar electric powered. Remained aloft for 14 days. Also filed for FAI altitude record of 70740\\xa0ft 21561 m  131  The delicacy of the British PHASA35 military drone at a late stage of development is such that traversing the first turbulent twelve miles of atmosphere is a hazardous endeavor. It has however remained on station at 65000 feet for 24 hours. Airbus Zephyr in 2023 has attained 70000 feet and flown for 64 days 200 days aimed at. This is sufficiently close enough to nearspace for them to be regarded in pseudosatellites as regards to their operational capabilities.  132  Reliability  edit  Reliability improvements target all aspects of UAV systems using resilience engineering and fault tolerance techniques. Individual reliability covers robustness of flight controllers to ensure safety without excessive redundancy to minimize cost and weight.  133  Besides dynamic assessment of flight envelope allows damageresilient UAVs using nonlinear analysis with ad hoc designed loops or neural networks.  134  UAV software liability is bending toward the design and certifications of crewed avionics software .  135  Swarm resilience involves maintaining operational capabilities and reconfiguring tasks given unit failures.  136  Applications  edit  Main article List of unmanned aerial vehicle applications In recent years autonomous drones have begun to transform various application areas as they can fly beyond visual line of sight BVLOS  137  while maximizing production reducing costs and risks ensuring site safety security and regulatory compliance  138  and protecting the human workforce in times of a pandemic.  139  They can also be used for consumerrelated missions like package delivery as demonstrated by Amazon Prime Air  and critical deliveries of health supplies. There are numerous civilian commercial military and aerospace applications for UAVs.  3  These include General Recreation  disaster relief  archeology  conservation of biodiversity and habitat   140  law enforcement  crime  and terrorism . Commercial Aerial surveillance  filmmaking   141  journalism  scientific research  surveying  cargo transport  mining  manufacturing  forestry  solar farming  thermal energy  ports and agriculture . Warfare  edit  Main articles Unmanned combat aerial vehicle  Drone warfare  Loitering munition  Unmanned surveillance and reconnaissance aerial vehicle  Miniature UAV  Micro air vehicle  and Target drone A Baykar Bayraktar TB2 of the Ukrainian Air Force armed with MAML  two ground control stations in the background As of 2020 seventeen countries have armed UAVs and more than 100 countries use UAVs in a military capacity.  142  The first five countries producing domestic UAV designs are the United States China Israel Iran and Turkey.  143   144   145   146  Top military UAV manufactures are including General Atomics  Lockheed Martin  Northrop Grumman  Boeing  Baykar   147   144  TAI  IAIO  CASC and CAIG .  146  China has established and expanded its presence in military UAV market  146  since 2010. In the early 2020s Turkey also established and expanded its presence in the military UAV market.  143   146   144   147  In the early 2010s Israeli companies mainly focused on small surveillance UAV systems and by the number of drones Israel exported 60.7 2014 of UAVs on the market while the United States exported 23.9 2014.  148  Between 2010 and 2014 there were 439 drones exchanged compared to 322 in the five years previous to that among these only small fraction of overall trade  just 11 2.5 of the 439 are armed drones.  148  The US alone operated over 9000 military UAVs in 2014 among them more than 7000 are RQ11 Raven miniature UAVs .  149  Since 2010 Chinese drone companies have begun to export large quantities of drones to the global military market. Of the 18 countries that are known to have received military drones between 2010 and 2019 the top 12 all purchased their drones from China.  146   150  The shift accelerated in the 2020s due to Chinas advancement in drone technologies and manufacturing compounded by market demand from the Russian invasion of Ukraine and the IsraelGaza conflict .  151   152   153   154  For intelligence and reconnaissance missions the inherent stealth of micro UAV flappingwing ornithopters  imitating birds or insects offers potential for covert surveillance and makes them difficult targets to bring down. Unmanned surveillance and reconnaissance aerial vehicle are used for reconnaissance  attack  demining  and target practice . Following the 2022 Russian invasion of Ukraine a dramatic increase in UAV development took place with Ukraine creating the Brave1 platform to promote rapid development of innovative systems. Civil applications  edit  Ziplines aircraft being launched from a base in Rwanda to deliver blood products The civilian commercial and general drone market is dominated by Chinese companies. Chinese manufacturer DJI alone had 74 of the civil market share in 2018 with no other company accounting for more than 5.  155  The companies continue to hold over 70 of global market share by 2023 despite under increasing scrutinies and sanctions from the United States.  156  The US Interior Department grounded its fleet of DJI drones in 2020 while the Justice Department prohibited the use of federal funds for the purchase of DJI and other foreignmade UAVs.  157   158  DJI is followed by American company 3D Robotics  Chinese company Yuneec  Autel Robotics  and French company Parrot .  159   160  As of May 2021 873576 UAVs had been registered with the US FAA  of which 42 were categorized as commercial and 58 as recreational.  161  2018 NPD point to consumers increasingly purchasing drones with more advanced features with 33 percent growth in both the 500 and 1000 market segments.  162  The civil UAV market is relatively new compared to the military one. Companies are emerging in both developed and developing nations at the same time. Many earlystage startups have received support and funding from investors as is the case in the United States and from government agencies as is the case in India.  163  Some universities offer research and training programs or degrees.  164  Private entities also provide online and inperson training programs for both recreational and commercial UAV use.  165  Consumer drones are widely used by police and military organizations worldwide because of the costeffective nature of consumer products. Since 2018 the Israeli military have used DJI UAVs for light reconnaissance missions.  166   167   152  DJI drones have been used by Chinese police in Xinjiang since 2017  168   169  and American police departments nationwide since 2018.  170   171  Both Ukraine and Russia used commercial DJI drones extensively during the Russian invasion of Ukraine .  172  These civilian DJI drones were sourced by governments hobbyists international donations to Ukraine and Russia to support each side on the battlefield and were often flown by drone hobbyists recruited by the armed forces. The prevalence of DJI drones was attributable to their market dominance affordability high performance and reliability.  173  Entertainment  edit  See also Drone art and Drone racing Drones are also used in nighttime displays for artistic and advertising purposes with the main benefits are that they are safer quieter and better for the environment than fireworks. They can replace or be an adjunct for fireworks displays to reduce the financial burden of festivals. In addition they can complement fireworks due to the ability for drones to carry them creating new forms of artwork in the process.  174   175   176  Drones can also be used for racing either with or without VR functionality. Aerial photography  edit  See also Drone journalism Drones are ideally suited to capturing aerial shots in photography and cinematography and are widely used for this purpose.  141  Small drones avoid the need for precise coordination between pilot and cameraman with the same person taking on both roles. Big drones with professional cine cameras usually have a drone pilot and a camera operator who controls camera angle and lens. For example the AERIGON cinema drone used in film production is operated by two people.  177   full citation needed  Drones provide access to dangerous remote or otherwise inaccessible sites. Environmental monitoring  edit  UASs or UAVs offer the great advantage for environmental monitoring to generate a new generation of survey at veryhigh or ultrahigh resolution both in space and time.  178  This gives the opportunity to bridge the existing gap between satellite data and field monitoring. This has stimulated a huge number of activities in order to enhance the description of natural and agricultural ecosystems. Most common applications are Topographic surveys  179  for the production of orthomosaics digital surface models and 3D models Monitoring of natural ecosystems for biodiversity monitoring  180  habitat mapping  181  detection of invasive alien species  182  and study of ecosystem degradation due to invasive species or disturbances Precision agriculture  183  which exploits all available technologies including UAV in order to produce more with less e.g. optimisation of fertilizers pesticides irrigation River monitoring several methods have been developed to perform flow monitoring using image velocimetry methods which allow to properly describe the 2D flow velocity fields.  184  Structural integrity of any type of structure whether it be a dam railway or other dangerous inaccessible or massive locations for building monitoring.  185  Mineral detection for acid mine drainage using UAVs and hyperspectral cameras can produce detailed maps of proxy minerals e.g. goethite  jarosite  for certain pHvalues in natural mining and postmining environments such as remediated sites.  186   187  These activities can be completed with different measurements such as photogrammetry  thermography  multispectral images 3D field scanning and normalized difference vegetation index maps. Geological hazards  edit  UAVs have become a widely used tool for studying geohazards such as landslides .  188  Various sensors including radar optical and thermal can be mounted on UAVs to monitor different properties. UAVs enable the capture of images of various landslide features such as transverse radial and longitudinal cracks ridges scarps and surfaces of rupture even in inaccessible areas of the sliding mass.  189   190  Moreover processing the optical images captured by UAVs also allows for the creation of point clouds and 3D models from which these properties can be derived.  191  Comparing point clouds obtained at different times allows for the detection of changes caused by landslide deformation.  192   193  Mineral exploration  edit  UAVs may help in the discovery of new or reevaluation of known mineral deposits to meet the demand for raw materials such as critical raw metals e.g. cobalt  nickel  rare earths and battery minerals. By employing a suite of sensors e.g. spectral imaging  Lidar  magnetics  gammaray spectroscopy   194   195  and similar to those used in environmental monitoring UAVbased data can produce maps of geological surface and subsurface features contributing to more efficient and targeted mineral exploration.  196   197  Agriculture forestry and environmental studies  edit  Main article Agricultural drone Agricultural drone on trailer setup As global demand for food production grows exponentially resources are depleted farmland is reduced and agricultural labor is increasingly in short supply there is an urgent need for more convenient and smarter agricultural solutions than traditional methods and the agricultural drone and robotics industry is expected to make progress.  198  Agricultural drones have been used to help build sustainable agriculture all over the world leading to a new generation of agriculture.  199  In this context there is a proliferation of innovations in both tools and methodologies which allow precise description of vegetation state and also may help to precisely distribute nutrients pesticides or seeds over a field.  6  The use of UAVs is also being investigated to help detect and fight wildfires whether through observation or launching pyrotechnic devices to start backfires .  200  UAVs are also now widely used to survey wildlife such as nesting seabirds seals and even wombat burrows.  201  Law enforcement  edit  Main article Use of UAVs in law enforcement Police can use drones for applications such as search and rescue and traffic monitoring .  202  Humanitarian aid  edit  See also Delivery drone Drones are increasingly finding their application in humanitarian aid and disaster relief where they are used for a wide range of applications such as delivering food medicine and essential items to remote areas or image mapping before and following disasters.  203  Safety and security  edit  See also List of UAVrelated incidents and Unmanned combat aerial vehicle US Department of Agriculture poster warning about the risks of flying UAVs near wildfires Threats  edit  Nuisance  edit  UAVs can threaten airspace security in numerous ways including unintentional collisions or other interference with other aircraft deliberate attacks or by distracting pilots or flight controllers. The first incident of a droneairplane collision occurred in midOctober 2017 in Quebec City Canada.  204  The first recorded instance of a drone collision with a hot air balloon occurred on 10 August 2018 in Driggs Idaho  United States although there was no significant damage to the balloon nor any injuries to its 3 occupants the balloon pilot reported the incident to the National Transportation Safety Board  stating that I hope this incident helps create a conversation of respect for nature the airspace and rules and regulations.  205  Unauthorized UAV flights into or near major airports have prompted extended shutdowns of commercial flights.  206  Drones caused significant disruption at Gatwick Airport during December 2018  needing the deployment of the British Army.  207   208  In the United States flying close to a wildfire is punishable by a maximum 25000 fine. Nonetheless in 2014 and 2015 firefighting air support in California was hindered on several occasions including at the Lake Fire  209  and the North Fire .  210   211  In response California legislators introduced a bill that would allow firefighters to disable UAVs which invaded restricted airspace.  212  The FAA later required registration of most UAVs. Security vulnerabilities  edit  By 2017 drones were being used to drop contraband into prisons.  213  The interest in UAVs cybersecurity has been raised greatly after the Predator UAV video stream hijacking incident in 2009  214  where Islamic militants used cheap offtheshelf equipment to stream video feeds from a UAV. Another risk is the possibility of hijacking or jamming a UAV in flight. Several security researchers have made public some vulnerabilities in commercial UAVs in some cases even providing full source code or tools to reproduce their attacks.  215  At a workshop on UAVs and privacy in October 2016 researchers from the Federal Trade Commission showed they were able to hack into three different consumer quadcopters and noted that UAV manufacturers can make their UAVs more secure by the basic security measures of encrypting the WiFi signal and adding password protection.  216  Aggression  edit  Many UAVs have been loaded with dangerous payloads andor crashed into targets. Payloads have included or could include explosives chemical radiological or biological hazards. UAVs with generally nonlethal payloads could possibly be hacked and put to malicious purposes. CounterUAV systems CUAS from detection to electronic warfare to UAVs designed to destroy other UAVs are in development and being deployed by states to counter this threat. Such developments have occurred despite the difficulties. As J. Rogers stated in a 2017 interview to AT There is a big debate out there at the moment about what the best way is to counter these small UAVs whether they are used by hobbyists causing a bit of a nuisance or in a more sinister manner by a terrorist actor.  217  Countermeasures  edit  Counter unmanned air system  edit  Further information Electronic warfare Italian Army soldiers of the 17th Antiaircraft Artillery Regiment Sforzesca with a portable drone jammer in Rome Cannon antidrone system The malicious use of UAVs has led to the development of counter unmanned air system CUAS technologies. Automatic tracking and detection of UAVs from commercial cameras have become accurate thanks to the development of deep learning based machine learning algorithms.  218  It is also possible to automatically identify UAVs across different cameras with different viewpoints and hardware specification with reidentification methods.  219  Commercial systems such as the Aaronia AARTOS have been installed on major international airports.  220   221  Once a UAV is detected it can be countered with kinetic force missiles projectiles or another UAV or by nonkinetic force laser microwaves communications jamming.  222  Antiaircraft missile systems such as the Iron Dome are also being enhanced with CUAS technologies. Utilising a smart UAV swarm to counter one or more hostile UAVs is also proposed.  223  Regulation  edit  Main article Regulation of unmanned aerial vehicles Regulatory bodies around the world are developing unmanned aircraft system traffic management solutions to better integrate UAVs into airspace.  224  The use of unmanned aerial vehicles is becoming increasingly regulated by the civil aviation authorities of individual countries. Regulatory regimes can differ significantly according to drone size and use. The International Civil Aviation Organization ICAO began exploring the use of drone technology as far back as 2005 which resulted in a 2011 report.  225  France was among the first countries to set a national framework based on this report and larger aviation bodies such as the FAA and the EASA quickly followed suit.  226  In 2021 the FAA published a rule requiring all commercially used UAVs and all UAVs regardless of intent weighing 250 g or more to participate in Remote ID  which makes drone locations controller locations and other information public from takeoff to shutdown this rule has since been challenged in the pending federal lawsuit RaceDayQuads v. FAA .  227   228  EU Drone Certification  Class Identification Label  edit  The implementation of the Class Identification Label serves a crucial purpose in the regulation and operation of drones.  229  The label is a verification mechanism designed to confirm that drones within a specific class meet the rigorous standards set by administrations for design and manufacturing.  230  These standards are necessary to ensure the safety and reliability of drones in various industries and applications. By providing this assurance to customers the Class Identification Label helps to increase confidence in drone technology and encourages wider adoption across industries. This in turn contributes to the growth and development of the drone industry and supports the integration of drones into society. Export controls  edit  The export of UAVs or technology capable of carrying a 500\\xa0kg payload at least 300\\xa0km is restricted in many countries by the Missile Technology Control Regime . See also  edit  List of unmanned aerial vehicles Delivery drone Drone in a Box Glide bomb International Aerial Robotics Competition List of films featuring drones List of military electronics of the United States MARSS Interceptor Micromechanical Flying Insect ParcAberporth Quadcopter Radiocontrolled aircraft Autonomous aircraft Optionally piloted vehicle Sypaq Corvo Precision Payload Delivery System Satellite Sentinel Project Tactical Control System UAV ground control station Unmanned underwater vehicle Portals  Aviation Systems science Engineering Telecommunication References  edit  Citations  edit   a b De Gruyter Handbook of Drone Warfare 2024. eISBN PDF 9783110742039.  Tice Brian P. Spring 1991. Unmanned Aerial Vehicles  The Force Multiplier of the 1990s . Airpower Journal . Archived from the original on 24 July 2009 . Retrieved 6 June 2013 . When used UAVs should generally perform missions characterized by the three Ds dull dirty and dangerous.  a b Alvarado Ed 3 May 2021. 237 Ways Drone Applications Revolutionize Business . Drone Industry Insights . Archived from the original on 11 May 2021 . Retrieved 11 May 2021 .  F.  RekabiBana Hu J. T. Krajník Arvin F.  Unified Robust Path Planning and Optimal Trajectory Generation for Efficient 3D Area Coverage of Quadrotor UAVs  IEEE Transactions on Intelligent Transportation Systems 2023.  a b Hu J. Niu H. Carrasco J. Lennox B. Arvin F.  Faulttolerant cooperative navigation of networked UAV swarms for forest fire monitoring  Aerospace Science and Technology 2022.  a b Remote sensing of the environment using unmanned aerial systems UAS . S.l. ELSEVIER  HEALTH SCIENCE. 2023. ISBN 9780323852838 . OCLC 1329422815 . Archived from the original on 27 February 2023 . Retrieved 11 January 2023 .  Perks Matthew T. Dal Sasso Silvano Fortunato Hauet Alexandre Jamieson Elizabeth Le Coz Jérôme Pearce Sophie PeñaHaro Salvador Pizarro Alonso Strelnikova Dariia Tauro Flavia Bomhof James Grimaldi Salvatore Goulet Alain Hortobágyi Borbála Jodeau Magali 8 July 2020. Towards harmonisation of image velocimetry techniques for river surface velocity observations . Earth System Science Data . 12 3 1545 1559. Bibcode  2020ESSD...12.1545P . doi  10.5194essd1215452020 . hdl  11563161555 . ISSN 18663516 . Archived from the original on 12 January 2023 . Retrieved 12 January 2023 .  Koparan Cengiz Koc A. Bulent Privette Charles V. Sawyer Calvin B. March 2020. Adaptive Water Sampling Device for Aerial Robots . Drones . 4 1 5. Bibcode  2020Drone...4....5K . doi  10.3390drones4010005 . ISSN 2504446X .  Koparan Cengiz Koc Ali Bulent Privette Charles V. Sawyer Calvin B. Sharp Julia L. May 2018. Evaluation of a UAVAssisted Autonomous Water Sampling . Water . 10 5 655. Bibcode  2018Water..10..655K . doi  10.3390w10050655 .  Koparan Cengiz Koc Ali Bulent Privette Charles V. Sawyer Calvin B. March 2018. In Situ Water Quality Measurements Using an Unmanned Aerial Vehicle UAV System . Water . 10 3 264. Bibcode  2018Water..10..264K . doi  10.3390w10030264 .  Koparan Cengiz Koc Ali Bulent Privette Charles V. Sawyer Calvin B. March 2019. Autonomous In Situ Measurements of Noncontaminant Water Quality Indicators and Sample Collection with a UAV . Water . 11 3 604. Bibcode  2019Water..11..604K . doi  10.3390w11030604 .  Drones smuggling porn drugs to inmates around the world . Fox News . 17 April 2017. Archived from the original on 31 August 2018 . Retrieved 17 April 2017 .  Note the term  drone  refers to the male bee that serves only to fertilize the queen bee  hence the use of the name in reference to the DH Queen Bee aerial target.  Drones and Artificial Intelligence . Drone Industry Insights . 28 August 2018. Archived from the original on 17 September 2020 . Retrieved 11 April 2020 .  What is the difference between a drone and an RC plane or helicopter . Drones Etc . Drones Etc. Archived from the original on 17 November 2015 . Retrieved 12 October 2015 .  unmanned aerial vehicle . TheFreeDictionary.com . Archived from the original on 8 January 2015 . Retrieved 8 January 2015 .  Guilmartin John F. unmanned aerial vehicle . Encyclopedia Britannica . Archived from the original on 29 March 2020 . Retrieved 24 March 2020 .  14 CFR Part 107 Docket FAA20150150 Amdt. 1071 81 FR 42209 June 28 2016 as amended by Amdt. No. 1078 86 FR 4381 Jan. 15 2021 . eCFR\\xa0 14 CFR Part 107  Small Unmanned Aircraft Systems FAR Part 107 . Federal Aviation Administration Department of Transportation. 15 January 2021 . Retrieved 16 February 2025 .  cite web    CS1 maint urlstatus  link   Unmanned Aircraft Systems Roadmap PDF . Archived from the original PDF on 2 October 2008.  European ATM Master Plan 2015  SESAR . www.sesarju.eu . Archived from the original on 6 February 2016 . Retrieved 3 February 2016 .  State government gears up for autonomous RPAS mapping . 23 January 2017. Archived from the original on 25 February 2017 . Retrieved 1 February 2017 .  Canadian Aviation Regulations . Government of Canada  Justice Laws Website . 1 June 2019. Archived from the original on 6 January 2022 . Retrieved 16 January 2019 .  The FAA is shifting from unmanned to uncrewed .  Defence Drone Strategy  the UKs approach to Defence Uncrewed Systems .  Aviation Management Chapter 12  Uncrewed Aircraft Systems PDF .  a b c d UAV classification . Archived from the original on 23 May 2022 . Retrieved 10 June 2022 .  Eyes of the Army U.S. Army Roadmap for UAS 20102035 PDF . Archived PDF from the original on 18 February 2022 . Retrieved 10 June 2022 .  Nano micro small The different drone types in India  if Jammulike strike can be averted . Archived 29 June 2021 at the Wayback Machine . ThePrint  29 June 2021.  Drones Percepto 3 January 2019. The Differences Between UAV UAS and Autonomous Drones . Percepto . Archived from the original on 18 February 2020 . Retrieved 18 February 2020 .  Cary Leslie Coyne James. ICAO Unmanned Aircraft Systems UAS Circular 328. 20112012 UAS Yearbook  UAS The Global Perspective PDF . Blyenburgh  Co. pp. 112 115. Archived from the original PDF on 4 March 2016 . Retrieved 26 February 2022 .  Hu J. Lanzon A. 2018. An innovative trirotor drone and associated distributed aerial drone swarm control . Robotics and Autonomous Systems . 103  162 174. doi  10.1016j.robot.2018.02.019 .  Garrow Laurie A. German Brian J. Leonard Caroline E. 1 November 2021. Urban air mobility A comprehensive review and comparative analysis with autonomous and electric ground transportation for informing future research . Transportation Research Part C Emerging Technologies . 132  103377. Bibcode  2021TRPC..13203377G . doi  10.1016j.trc.2021.103377 . ISSN 0968090X .  Exploring Gas Powered Drones Uses and Benefits . www.flyability.com . Retrieved 8 August 2024 .  Zhang Caizhi Qiu Yuqi Chen Jiawei Li Yuehua Liu Zhitao Liu Yang Zhang Jiujun Hwa Chan Siew 1 August 2022. A comprehensive review of electrochemical hybrid power supply systems and intelligent energy managements for unmanned aerial vehicles in public services . Energy and AI . 9  100175. Bibcode  2022EneAI...900175Z . doi  10.1016j.egyai.2022.100175 . hdl  10356164036 . ISSN 26665468 .  Nefedkin S. I. Klimova M. A. Glasov V. S. Pavlov V. I. Tolmachev Y. V. Effect of the corrugated bipolar plate design on the selfhumidification of a high power density PEMFC stack for UAVs. Fuel Cells 2021 21 3 234253  10.1002fuce.202000163.  Powering Solutions for Your Drone in 2024 New Fuels . Commercial Uav News . Retrieved 8 August 2024 .  jenks2026 30 January 2024. SolarPowered Drones and UAVs . Green.org . Retrieved 8 August 2024 .  cite web    CS1 maint numeric names authors list  link   Fabled Sky Research 2024. Revolutionizing UAV Capabilities Exploring the Potential of Nuclear Propulsion Systems . UAV Technologies  219399 Bytes. doi  10.6084M9.FIGSHARE.26198462.V1 .  The Encyclopedia of the ArabIsraeli Conflict A Political Social and Military History A Political Social and Military History  ABCCLIO 12 May 2008 by Spencer C. Tucker Priscilla Mary Roberts pages 105455 ISBN  The Future of Drone Use Opportunities and Threats from Ethical and Legal Perspectives Archived 27 February 2023 at the Wayback Machine  Asser Press\\xa0  Springer chapter by Alan McKenna page 355  Kaplan Philip 2013. Naval Aviation in the Second World War . Pen and Sword. p.\\xa019. ISBN 9781473829978 . Archived from the original on 27 February 2023 . Retrieved 19 August 2019 .  Hallion Richard P. 2003. Taking Flight Inventing the Aerial Age from Antiquity through the First World War . Oxford University Press. p. 66 . ISBN 9780190289591 .  Naval Aviation in the First World War Its Impact and Influence  R. D. Layman page 56  Renner Stephen L. 2016. Broken Wings The Hungarian Air Force 191845 . Indiana University Press. p.\\xa02. ISBN 9780253023391 . Archived from the original on 27 February 2023 . Retrieved 26 October 2019 .  Murphy Justin D. 2005. Military Aircraft Origins to 1918 An Illustrated History of Their Impact . ABCCLIO. pp. 9 10. ISBN 9781851094882 . Archived from the original on 27 February 2023 . Retrieved 19 August 2019 .  Haydon F. Stansbury 2000. Military Ballooning During the Early Civil War . JHU Press. pp. 18 20. ISBN 9780801864421 .  Mikesh Robert C. 1973. Japans World War II balloon bomb attacks on North America PDF . Smithsonian Annals of Flight 9. Washington DC 1 85. doi  10.5479si.AnnalsFlight.9 . hdl  1008818679 . ISSN 00810207 . Archived PDF from the original on 6 December 2017 . Retrieved 12 July 2018 .  Tapan K. Sarkar  History of wireless  John Wiley and Sons 2006 ISBN 0471718149  p. 97.  Biodiversity Heritage Library . Mécanique Appliquée.  Sur le télékine. Note de M. L. Torres présentée par M. Appell 3 August 1903 pp. 317319 Comptes rendus de lAcadémie des Sciences.  Randy Alfred  Nov. 7 1905 Remote Control Wows Public  Wired  7 November 2011.  H. R. Everett 2015. Unmanned Systems of World Wars I and II . MIT Press . pp. 91 95. ISBN 9780262029223 .  a b c Taylor John W. R.. Janes Pocket Book of Remotely Piloted Vehicles .  Professor A. M. Low FLIGHT 3 October 1952 page 436 The First Guided Missile  Dempsey Martin E. 9 April 2010. Eyes of the ArmyU.S. Army Roadmap for Unmanned Aircraft Systems 20102035 PDF . U.S. Army . Archived from the original PDF on 22 September 2018 . Retrieved 6 March 2011 .  Says Robert Kanyike 21 May 2012. History of U.S. Drones . Archived from the original on 26 September 2019 . Retrieved 17 February 2014 .  Andersson Lennart 1994. Soviet Aircraft and Aviation 19171941 . The Putnam Aviation Series. Annapolis Maryland Naval Institute Press. p.\\xa0249. ISBN 9781557507709 . Archived from the original on 27 February 2023 . Retrieved 18 December 2021 . Experiments with a pilotless drone version of the TB1 controlled by radio from other aircraft started in 1935 and continued until 1939.  H. R. Everett 2015. Unmanned Systems of World Wars I and II . MIT Press . p. 318 . ISBN 9780262029223 .  Wagner 1982  p.\\xa0xi.  Wagner 1982  p.\\xa0xi xii.  Wagner 1982  p.\\xa0xii.  Wagner 1982  p.\\xa079.  Wagner 1982  p.\\xa078 79.  Dunstan Simon 2013. Israeli Fortifications of the October War 1973 . Osprey Publishing. p.\\xa016. ISBN 9781782004318 . Retrieved 25 October 2015 . The War of Attrition was also notable for the first use of UAVs or unmanned aerial vehicles carrying reconnaissance cameras in combat.  permanent dead link    Saxena V. K. 2013. The Amazing Growth and Journey of UAVs and Ballistic Missile Defence Capabilities Where the Technology is Leading to . Vij Books India Pvt Ltd. p.\\xa06. ISBN 9789382573807 . Archived from the original on 27 February 2023 . Retrieved 25 October 2015 . During the Yom Kippur War the Israelis used Teledyne Ryan 124 R RPVs along with the homegrown Scout and Mastiff UAVs for reconnaissance surveillance and as decoys to draw fire from Arab SAMs. This resulted in Arab forces expending costly and scarce missiles on inappropriate targets ....  Blum Howard 2003. The eve of destruction the untold story of the Yom Kippur War . HarperCollins. ISBN 9780060013998 .  Wagner 1982  p.\\xa0202.  Wagner 1982  p.\\xa0200 212.  a b Wagner 1982  p.\\xa0208.  A Brief History of UAVs . Howstuffworks.com. 22 July 2008. Archived from the original on 22 May 2013 . Retrieved 8 January 2015 .  Russia Buys A Bunch of Israeli UAVs . Strategypage.com. Archived from the original on 26 October 2013 . Retrieved 8 January 2015 .  Azoulai Yuval 24 October 2011. Unmanned combat vehicles shaping future warfare . Globes . Archived from the original on 3 December 2013 . Retrieved 8 January 2015 .  Levinson Charles 13 January 2010. Israeli Robots Remake Battlefield . The Wall Street Journal . p.\\xa0A10. Archived from the original on 13 March 2020 . Retrieved 13 January 2010 .  GalOr Benjamin 1990. Vectored Propulsion Supermaneuverability  Robot Aircraft . Springer Verlag. ISBN 9783540971610 .  Fuller Christopher J. 2015. The Eagle Comes Home to Roost The Historical Origins of the CIAs Lethal Drone Program . Intelligence and National Security . 30 6 769 792. doi  10.108002684527.2014.895569 . S2CID 154927243 .  Z. Goraj A. Frydrychewicz R. Świtkiewicz B. Hernik J. Gadomski T. GoetzendorfGrabowski M. Figat St Suchodolski W. Chajec. report PDF . Bulletin of the Polish Academy of Sciences Technical Sciences Volume 52. Number 3 2004. Archived PDF from the original on 4 March 2016 . Retrieved 9 December 2015 .  Community Research and Development Information Service . Civil UAV application and economic effectiveness of potential configuration solutions . Publications Office of the European Union. Archived from the original on 29 January 2016 . Retrieved 9 December 2015 .  Ackerman Spencer Shachtman Noah 9 January 2012. Almost 1 in 3 U.S. Warplanes Is a Robot . Wired . Archived from the original on 23 March 2020 . Retrieved 8 January 2015 .  a b Singer Peter W. A Revolution Once More Unmanned Systems and the Middle East . Archived 6 August 2011 at the Wayback Machine . The Brookings Institution. November 2009.  Radsan A. J. Murphy Richard 2011. Measure Twice Shoot Once Higher Care for CIA Targeted Killing. University of Illinois Law Review . 2011 4 1201 1241. SSRN 1625829 .  Sayler 2015  Franke Ulrike Esther 2015. The global diffusion of unmanned aerial vehicles UAVs or drones  . In Mike Aaronson ed. Precision Strike Warfare and International Intervention . Routledge.  Hambling David. Drones may have attacked humans fully autonomously for the first time . New Scientist . Archived from the original on 30 July 2021 . Retrieved 30 May 2021 .  ForestierWalker Robin 13 October 2020. NagornoKarabakh New weapons for an old conflict spell danger . Al Jazeera . Archived from the original on 13 October 2020 . Retrieved 18 December 2021 . ...\\xa0battlefield videos and the known military capabilities of the two warring sides suggest Azerbaijan has the technological advantage especially with its combat drones purchased from Israel and Turkey.  BailonRuiz Rafael Lacroix Simon BitMonnot Arthur October 2018. Planning to Monitor Wildfires with a Fleet of UAVs . 2018 IEEERSJ International Conference on Intelligent Robots and Systems IROS . Madrid IEEE. pp. 4729 4734. doi  10.1109IROS.2018.8593859 . ISBN 9781538680940 . S2CID 52970107 . Archived from the original on 29 December 2022 . Retrieved 11 January 2023 .  Hill John 7 May 2024. In data UAS market projected to nearly double in ten years . Army Technology . Retrieved 8 May 2024 .  Design Simulation and New Applications of Unmanned Aerial Vehicles . www.mdpi.com . Retrieved 24 March 2023 .  Nagel Huub Bondt Geert Custers Bart Vergouw Bas 16 July 2016. Drone Technology Types Payloads Applications Frequency Spectrum Issues and Future Developments . The Future of Drone Use .  da Silva F.B Scott S.D Cummings M.L December 2007. Design Methodology for Unmannded Aerial Vehicle UAV Team Coordination PDF . Design Methodology for Unmannded Aerial Vehicle UAV Team Coordination .  TorresSánchez Jorge LópezGranados Francisca Castro Ana Isabel De PeñaBarragán José Manuel 6 March 2013. Configuration and Specifications of an Unmanned Aerial Vehicle UAV for Early Site Specific Weed Management . PLOS ONE . 8 3 e58210. Bibcode  2013PLoSO...858210T . doi  10.1371journal.pone.0058210 . ISSN 19326203 . PMC 3590160 . PMID 23483997 .  TorresSánchez Jorge LópezGranados Francisca De Castro Ana Isabel PeñaBarragán José Manuel 2013. Configuration and specifications of an Unmanned Aerial Vehicle UAV for early site specific weed management . PLOS ONE . 8 3 e58210. Bibcode  2013PLoSO...858210T . doi  10.1371journal.pone.0058210 . ISSN 19326203 . PMC 3590160 . PMID 23483997 .  Model airplane historymaker Maynard Hill dies at the age of 85 . The Washington Post . Archived from the original on 4 July 2018 . Retrieved 17 May 2018 .  Al S. Xie Y. Malandrakis K. Lopez M. Tsourdos A. Ieee. Development of a Fuel Cell HybridPowered Unmanned Aerial Vehicle. In 2016 24th Mediterranean Conference on Control and Automation Mediterranean Conference on Control and Automation Ieee 2016 pp 12421247. Go to ISIWOS000391154900205  Baldic J. Osenar P. Lauder N. Launie P. Fuel Cell Systems for Long Duration Electric UAVs and UGVs. In Defense Transformation and NetCentric Systems 2010 Suresh R. Ed. Proceedings of SPIEThe International Society for Optical Engineering Vol. 7707 SpieInt Soc Optical Engineering 2010   770703. 10.111712.851779. Go to ISIWOS000285718300002.  Chu D. Jiang R. Dunbar Z. Grew K. McClure J. Fuel Cell Powered Small Unmanned Aerial Systems UASs For Extended Endurance Flights. In Unmanned Systems Technology Xvii Karlsen R. E. Gage D. W. Shoemaker C. M. Gerhart G. R. Eds. Proceedings of SPIE Vol. 9468 SpieInt Soc Optical Engineering 2015   94680e 10.111712.2087336. Go to ISIWOS000357636900011.  Nefedkin S. I. Klimova M. A. Glasov V. S. Pavlov V. I. Tolmachev Y. V. Effect of the corrugated bipolar plate design on the selfhumidification of a high power density PEMFC stack for UAVs. Fuel Cells 2021 21 3 234253  10.1002fuce.202000163. httpsonlinelibrary.wiley.comdoi10.1002fuce.202000163 .  Chirarattananon Pakpong Ma Kevin Y Wood J 22 May 2014 Adaptive control of a millimeterscale flappingwing robot PDF  Bioinspiration  Biomimetics  9 2 025004 Bibcode  2014BiBi....9b5004C  CiteSeerX 10.1.1.650.3728  doi  10.10881748318292025004  PMID 24855052  S2CID 12799012  archived from the original PDF on 16 April 2016  Sarah Knapton 29 March 2016. Giant remotecontrolled beetles and biobot insects could replace drones . The Telegraph . Archived from the original on 1 April 2016.  Antonio 11 July 2024. EASA Approves ETSO Certification Basis for Veronte Autopilot . Embention . Retrieved 2 August 2024 .  a b c Floreano Dario Wood Robert J. 27 May 2015. Science technology and the future of small autonomous drones . Nature . 521 7553 460 466. Bibcode  2015Natur.521..460F . doi  10.1038nature14542 . PMID 26017445 . S2CID 4463263 . Archived from the original on 26 October 2019 . Retrieved 26 October 2019 .  Fasano Giancarmine Accardo Domenico Tirri Anna Elena Moccia Antonio De Lellis Ettore 1 October 2015. Radarelectrooptical data fusion for noncooperative UAS sense and avoid . Aerospace Science and Technology . 46  436 450. Bibcode  2015AeST...46..436F . doi  10.1016j.ast.2015.08.010 .  Arduino Playground  WhatIsDegreesOfFreedom6DOF9DOF10DOF11DOF . playground.arduino.cc . Archived from the original on 18 February 2016 . Retrieved 4 February 2016 .  Manfreda Salvatore McCabe Matthew Miller Pauline Lucas Richard Pajuelo Madrigal Victor Mallinis Giorgos Ben Dor Eyal Helman David Estes Lyndon Ciraolo Giuseppe Müllerová Jana Tauro Flavia de Lima M. de Lima João Maltese Antonino 20 April 2018. On the Use of Unmanned Aerial Systems for Environmental Monitoring . Remote Sensing . 10 4 641. Bibcode  2018RemS...10..641M . doi  10.3390rs10040641 . hdl  10251127481 . ISSN 20724292 .  7.3. Sensing for Drones  Introduction to Robotics and Perception . www.roboticsbook.org .  7.5. Trajectory Optimization  Introduction to Robotics and Perception . www.roboticsbook.org .  PierreJean Bristeau François Callou David Vissière Nicolas Petit 2011. The Navigation and Control technology inside the AR.Drone micro UAV PDF . IFAC World Congress . Archived PDF from the original on 27 February 2023 . Retrieved 4 February 2016 .  Cellular enables safer drone deployments . Qualcomm . Archived from the original on 9 May 2018 . Retrieved 9 May 2018 .  Identifying Critical MannedUnmanned Teaming Skills for Unmanned Aircraft System Operators PDF . U.S. Army Research Institute for the Behavioral and Social Sciences . September 2012. Archived PDF from the original on 6 February 2016.  Minimum requirements related to technical performance for IMT2020 radio interfaces . www.itu.int . Archived from the original on 6 August 2020 . Retrieved 8 October 2020 .  Vinogradov Evgenii Kumar A. V. S. Sai Bhargav Minucci Franco Pollin Sofie Natalizio Enrico 2023. Remote ID for separation provision and multiagent navigation. 2023 IEEEAIAA 42nd Digital Avionics Systems Conference DASC . pp. 1 10. arXiv  2309.00843 . doi  10.1109DASC58513.2023.10311133 . ISBN 9798350333572 .  Automated Vehicles for Safety . United States National Highway Traffic Safety Administration . Archived from the original on 7 October 2021 . Retrieved 8 October 2021 .  Clough Bruce August 2002. Metrics Schmetrics How The Heck Do You Determine A UAVs Autonomy Anyway . US Air Force Research Laboratory . Archived from the original on 24 September 2020.  Davenport Christian 23 April 2015. Watch a step in Navy history an autonomous drone gets refueled midair . The Washington Post . ISSN 01908286 . Archived from the original on 20 January 2016 . Retrieved 3 February 2016 .  Tahir Anam Böling Jari Haghbayan MohammadHashem Toivonen Hannu T. Plosila Juha 2019. Swarms of Unmanned Aerial Vehicles  A Survey . Journal of Industrial Information Integration . 16  100106. doi  10.1016j.jii.2019.100106 .  Teaching tiny drones how to fly themselves . Ars Technica . 27 November 2012. Archived from the original on 5 February 2016 . Retrieved 4 February 2016 .  Biomimetics and Dextrous Manipulation Lab  MultiModalRobots . bdml.stanford.edu . Archived from the original on 23 March 2016 . Retrieved 21 March 2016 .  DAndrea Raffaello 11 June 2013. The astounding athletic power of quadcopters . www.ted.com . Archived from the original on 5 February 2016 . Retrieved 4 February 2016 .  Yanguo Song Huanjin Wang 1 June 2009. Design of Flight Control System for a Small Unmanned Tilt Rotor Aircraft . Chinese Journal of Aeronautics . 22 3 250 256. Bibcode  2009ChJAn..22..250Y . doi  10.1016S1000936108600953 .  The device designed for landing UAV helicopter type on a flat vertical surface . patents.google.com . Archived from the original on 7 March 2017 . Retrieved 6 November 2016 .  The Importance of Proper Cooling and Airflow for Optimal Drone Performance . Pelonis Technologies . Archived from the original on 22 June 2018 . Retrieved 22 June 2018 .  Flying on Hydrogen Georgia Tech Researchers Use Fuel Cells to Power Unmanned Aerial Vehicle  Georgia Tech Research Institute . www.gtri.gatech.edu . Archived from the original on 3 February 2016 . Retrieved 4 February 2016 .  Hydrogenpowered Hycopter quadcopter could fly for 4 hours at a time . www.gizmag.com . 20 May 2015. Archived from the original on 4 February 2016 . Retrieved 4 February 2016 .  Gibbs Yvonne 31 March 2015. NASA Armstrong Fact Sheet Beamed Laser Power for UAVs . NASA . Archived from the original on 5 April 2019 . Retrieved 22 June 2018 .  Vertical Challenge Monsters of the sky PDF  archived from the original PDF on 11 September 2013  General Atomics Gnat . Designationsystems.net. Archived from the original on 11 December 2008 . Retrieved 8 January 2015 .  UAV Notes . Archived from the original on 30 July 2013.  Trans atlantic Model . Tam.plannet21.com. Archived from the original on 22 May 2016 . Retrieved 8 January 2015 .  QinetiQs Zephyr UAV exceeds official world record for longest duration unmanned flight Press release. QinetiQ. 10 September 2007. Archived from the original on 23 April 2011.  Simonite Tom. New Scientist Technology Blog Solar plane en route to everlasting flight . New Scientist . Archived from the original on 2 April 2015 . Retrieved 8 January 2015 .  Northrop Grummans Global Hawk Unmanned Aircraft Sets 33Hour Flight Endurance Record . Spacewar.com. Archived from the original on 1 July 2013 . Retrieved 27 August 2013 .  QinetiQs Zephyr UAV flies for three and a half days to set unofficial world record for longest duration unmanned flight Press release. QinetiQ. 24 August 2008. Archived from the original on 24 May 2011.  QinetiQ files for three world records for its Zephyr Solar powered UAV . QinetiQ Press release. 24 August 2010. Archived from the original on 24 September 2010.  MacDonald Alistair 14 July 2023. Drones Reach Stratospheric Heights in Race to Fly Higher Longer . Wall Street Journal  via www.wsj.com.  Boniol December 2014. Towards Modular and Certified Avionics for UAV PDF . Aerospacelab Journal . Archived PDF from the original on 4 February 2016 . Retrieved 4 February 2016 .  D. Boskovic and Knoebel 2009. A Comparison Study of Several Adaptive Control Strategies for Resilient Flight Control PDF . AIAA Guidance Navigation andControl Conference . Archived from the original PDF on 4 February 2016.  Atkins. Certifiable Autonomous Flight Management for Unmanned Aircraft Systems . University of Michigan . Archived from the original on 5 March 2017 . Retrieved 4 February 2016 .  Subhav Pradhan William Otte Abhishek Dubey Aniruddha Gokhale Gabor Karsai 2013. Key Considerations for a Resilient and Autonomous Deployment and Configuration Infrastructure for CyberPhysical Systems PDF . Dept. of Electrical Engineering and Computer Science Vanderbilt University Nashville . Archived PDF from the original on 4 February 2016 . Retrieved 4 February 2016 .  How Autonomous Drone Flights Will Go Beyond Line of Sight . Nanalyze . 31 December 2019. Archived from the original on 20 May 2020 . Retrieved 16 April 2020 .  McNabb Miriam 28 February 2020. Drones Get the Lights Back on Faster for Florida Communities . DRONELIFE . Archived from the original on 12 March 2020 . Retrieved 16 April 2020 .  Peck Abe 19 March 2020. Coronavirus Spurs Perceptos DroneinaBox Surveillance Solution . Inside Unmanned Systems . Archived from the original on 24 March 2020 . Retrieved 16 April 2020 .  Valle Roberto G. January 2022. Rapid drone semiautomated counts of wintering Greater Flamingos  Phoenicopterus roseus  as a tool for amateur researchers . Ibis . 164 1 320 328. doi  10.1111ibi.12993 . ISSN 00191019 . S2CID 237865267 . Archived from the original on 13 October 2022 . Retrieved 13 October 2022 .  a b Mademlis Ioannis Nikolaidis Nikos Tefas Anastasios Pitas Ioannis Wagner Tilman Messina Alberto 2019. Autonomous UAV Cinematography A Tutorial and a Formalized ShotType Taxonomy . ACM Computing Surveys . 52 5. Association for Computing Machinery. doi  10.11453347713 . S2CID 202676119 . Archived from the original on 3 November 2022 . Retrieved 3 November 2022 .  Horowitz Michael C. 2020. Do Emerging Military Technologies Matter for International Politics . Annual Review of Political Science . 23 1 385 400. doi  10.1146annurevpolisci050718032725 .  a b Strengthening Turkish Policy on Drone Exports . Carnegie Endowment for International. Archived from the original on 23 March 2022 . Retrieved 17 March 2022 .  a b c Turkeys defense industry targets more than 4 billion in exports this year Official . Hürriyet Daily News. 6 March 2022. Archived from the original on 17 March 2022 . Retrieved 17 March 2022 .  Combat drones in China are coming to a conflict near you . www.intelligentaerospace.com . 19 March 2021. Archived from the original on 7 June 2021 . Retrieved 7 June 2021 .  a b c d e Market for Military Drones will Surge . 27 October 2016. Archived from the original on 19 February 2018 . Retrieved 19 February 2018 .  a b Turkish defence industry grows as Akinci UCAV signs first export deal . TRTWORLD. 23 January 2022. Archived from the original on 30 January 2022 . Retrieved 17 March 2022 .  a b Arnett George 16 March 2015. The numbers behind the worldwide trade in UAVs . The Guardian . Archived from the original on 19 December 2016 . Retrieved 13 December 2016 .  Pentagon Plans for Cuts to Drone Budgets . DoD Buzz . 2 January 2014. Archived from the original on 8 January 2015 . Retrieved 17 March 2022 .  Is China at the Forefront of Drone Technology . Center for Strategic and Internation Studies . 29 May 2018.  Seong Hyeon Choi 25 November 2023. Drone tech gives China an edge in Middle East arms sales but IsraelGaza war brings risks analysts . South China Morning Post .  a b Somerville Heather 9 November 2023. Chinese AmericanIt Doesnt Matter. Israel Wants Inexpensive Drones . The Wall Street Journal .  Skove Sam 1 May 2024. UK eyes Chinese drone parts for Ukraine . Defense One .  Joe Rick 5 February 2020. Chinas Military Advancements in the 2010s Air and Ground . The Diplomat .  Bateman Joshua 1 September 2017. China drone maker DJI Alone atop the unmanned skies . News Ledge . Archived from the original on 19 February 2018 . Retrieved 19 February 2018 .  Anwar Nessa 7 February 2023. Worlds largest drone maker is unfazed  even if its blacklisted by the U.S. CNBC .  Friedman Lisa McCabe David 29 January 2020. Interior Dept. Grounds Its Drones Over Chinese Spying Fears . The New York Times . ISSN 03624331 . Archived from the original on 29 January 2020 . Retrieved 17 November 2020 .  Miller Maggie 8 October 2020. DOJ bans use of grant funds for certain foreignmade drones . The Hill . Archived from the original on 28 November 2020 . Retrieved 17 November 2020 .  DJI market share heres exactly how rapidly it has grown in just a few years . Emberify Blog . 18 September 2018. Archived from the original on 24 September 2018 . Retrieved 18 September 2018 .  Daly David 2021. 5 Major Drone Manufacturers Powering the Industry . Consortiq .  UAS by the Numbers . www.faa.gov . Archived from the original on 17 May 2021 . Retrieved 24 May 2021 .  Consumer Drones By the Numbers in 2018 and Beyond  News Ledge . News Ledge . 4 April 2017. Archived from the original on 14 October 2018 . Retrieved 13 October 2018 .  Skylark Drones set to raise its first round of funding to boost expansion . 14 September 2015. Archived from the original on 14 September 2016 . Retrieved 28 August 2016 .  Peterson Andrea 19 August 2013. States are competing to be the Silicon Valley of drones . The Washington Post . ISSN 01908286 . Archived from the original on 13 February 2016 . Retrieved 4 February 2016 .  Drone Training Courses  The Complete List . Drone Business Marketer . Archived from the original on 16 November 2016 . Retrieved 1 December 2016 .  IDF buying massmarket DJI drones . Janes 360 . Archived from the original on 11 December 2017.  Greenwood Faine 16 August 2017. The U.S. Military Shouldnt Use Commercial Drones . Slate . ISSN 10912339 . Archived from the original on 17 April 2018 . Retrieved 2 June 2023 .  DJI Won the Drone Wars and Now Its Paying the Price . Bloomberg . 26 March 2020. Archived from the original on 19 November 2020 . Retrieved 18 November 2020 .  大疆创新与新疆自治区公安厅结为警用无人机战略合作伙伴 . YouUAV.com . 24 December 2017. Archived from the original on 18 December 2020 . Retrieved 18 November 2020 .  The Next Frontier of Police Surveillance Is Drones . Slate . 7 June 2018. Archived from the original on 11 December 2019 . Retrieved 10 December 2019 .  These Police Drones are Watching You . Project On Government Oversight . 25 September 2018. Archived from the original on 11 December 2019 . Retrieved 10 December 2019 .  Sangma Mike 25 December 2022. Ukraine has an unlikely ally in fight against Russia DJI drones . East Mojo . Archived from the original on 20 February 2023 . Retrieved 26 December 2022 .  Greenwood Faine 16 February 2023. The Drone War in Ukraine Is Cheap Deadly and Made in China . Archived from the original on 26 September 2023 . Retrieved 6 March 2023 .  Drone Light Shows Powered by Intel . Intel . Archived from the original on 23 June 2021 . Retrieved 28 June 2021 .  Hirsch Lauren 1 July 2023. Fireworks Have a New Competitor Drones . The New York Times . Retrieved 10 August 2023 .  Fireworks and Drones Combine to Create Amazing Long Exposure Images . Moss and Fog . 1 May 2023 . Retrieved 10 August 2023 .  AERIGON cinema drone UAV pioneering in film production . Archived from the original on 26 August 2021 . Retrieved 26 August 2021 .  Eltner Anette Hoffmeister Dirk Kaiser Andreas Karrasch Pierre Klingbeil Lasse Stöcker Claudia Rovere Alessio eds. 2022. UAVs for the environmental sciences methods and applications . Darmstadt wbg Academic. ISBN 9783534405886 .  Ferreira Edgar Chandler Jim Wackrow Rene Shiono Koji April 2017. Automated extraction of free surface topography using SfMMVS photogrammetry . Flow Measurement and Instrumentation . 54  243 249. Bibcode  2017FloMI..54..243F . doi  10.1016j.flowmeasinst.2017.02.001 . S2CID 56307390 .  Reddy C. Sudhakar Kurian Ayushi Srivastava Gaurav Singhal Jayant Varghese A. O. Padalia Hitendra Ayyappan N. Rajashekar G. Jha C. S. Rao P. V. N. January 2021. Remote sensing enabled essential biodiversity variables for biodiversity assessment and monitoring technological advancement and potentials . Biodiversity and Conservation . 30 1 1 14. Bibcode  2021BiCon..30....1R . doi  10.1007s10531020020738 . ISSN 09603115 . S2CID 254281346 . Archived from the original on 27 February 2023 . Retrieved 12 January 2023 .  Gonçalves João Henriques Renato Alves Paulo SousaSilva Rita Monteiro António T. Lomba Ângela Marcos Bruno Honrado João January 2016. Rocchini Duccio ed.. Evaluating an unmanned aerial vehiclebased approach for assessing habitat extent and condition in finescale early successional mountain mosaics . Applied Vegetation Science . 19 1 132 146. Bibcode  2016AppVS..19..132G . doi  10.1111avsc.12204 . Archived from the original on 12 January 2023 . Retrieved 12 January 2023 .  Barbizan Sühs R. Ziller S. R. Dechoum M. 2023. Is the use of drones costeffective and efficient in detecting invasive alien trees A case study from a subtropical coastal ecosystem. Biological Invasions . 26 2 357 363. doi  10.1007s10530023031905 . S2CID 265016887 .  Zhang Chunhua Kovacs John M. December 2012. The application of small unmanned aerial systems for precision agriculture a review . Precision Agriculture . 13 6 693 712. Bibcode  2012PrAgr..13..693Z . doi  10.1007s1111901292745 . ISSN 13852256 . S2CID 254938502 . Archived from the original on 27 February 2023 . Retrieved 12 January 2023 .  Perks Matthew T. Russell Andrew J. Large Andrew R. G. 5 October 2016. Technical Note Advances in flash flood monitoring using unmanned aerial vehicles UAVs . Hydrology and Earth System Sciences . 20 10 4005 4015. Bibcode  2016HESS...20.4005P . doi  10.5194hess2040052016 . ISSN 16077938 . Archived from the original on 12 January 2023 . Retrieved 12 January 2023 .  Zhou Jianguo He Linshu Luo Haitao 19 March 2023. RealTime Positioning Method for UAVs in Complex Structural Health Monitoring Scenarios . Drones . 7 3 212. Bibcode  2023Drone...7..212Z . doi  10.3390drones7030212 . ISSN 2504446X .  Jackisch Robert Lorenz Sandra Zimmermann Robert Möckel Robert Gloaguen Richard 2018. DroneBorne Hyperspectral Monitoring of Acid Mine Drainage An Example from the Sokolov Lignite District . Remote Sensing . 10 3 385. doi  10.3390rs10030385 . ISSN 20724292 .  Flores Hernan Lorenz Sandra Jackisch Robert Tusa Laura Contreras I. Cecilia Zimmermann Robert Gloaguen Richard 2021. UASBased Hyperspectral Environmental Monitoring of Acid Mine Drainage Affected Waters . Minerals . 11 2 182. Bibcode  2021Mine...11..182F . doi  10.3390min11020182 . ISSN 2075163X .  Sun Jianwei Yuan Guoqin Song Laiyun Zhang Hongwen January 2024. Unmanned Aerial Vehicles UAVs in Landslide Investigation and Monitoring A Review . Drones . 8 1 30. Bibcode  2024Drone...8...30S . doi  10.3390drones8010030 . ISSN 2504446X .  Dai Keren Li Zhiyu Xu Qiang Tomas Roberto Li Tao Jiang Liming Zhang Jianyong Yin Tao Wang Hao 1 July 2023. Identification and evaluation of the high mountain upper slope potential landslide based on multisource remote sensing the Aniangzhai landslide case study . Landslides . 20 7 1405 1417. Bibcode  2023Lands..20.1405D . doi  10.1007s10346023020444 . hdl  10045133124 . ISSN 16125118 .  Yang Yuchuan Wang Xiaobo Jin Wei Cao Jiayun Cheng Baogen MaosenXiong Zhou Shunwen ChaoZhang 1 October 2019. Characteristics analysis of the reservoir landslides base on unmanned aerial vehicle UAV scanning technology at the Maoergai Hydropower Station Southwest China . IOP Conference Series Earth and Environmental Science . 349 1 012009. Bibcode  2019EES..349a2009Y . doi  10.1088175513153491012009 . ISSN 17551307 .  Tomás Roberto Pinheiro Marisa Pinto Pedro Pereira Eduardo Miranda Tiago 31 May 2023. Preliminary analysis of the mechanisms characteristics and causes of a recent catastrophic structurally controlled rock planar slide in Esposende northern Portugal . Landslides . 20 8 1657 1665. Bibcode  2023Lands..20.1657T . doi  10.1007s1034602302082y . hdl  182288576 . ISSN 1612510X .  Zhou Jiawen Jiang Nan Li Congjiang Li Haibo 9 February 2024. A landslide monitoring method using data from unmanned aerial vehicle and terrestrial laser scanning with insufficient and inaccurate ground control points . Journal of Rock Mechanics and Geotechnical Engineering . 16 10 4125 4140. Bibcode  2024JRMGE..16.4125Z . doi  10.1016j.jrmge.2023.12.004 . ISSN 16747755 .  Peterman V. 26 August 2015. Landslide Activity Monitoring with the Help of Unmanned Aerial Vehicle . The International Archives of the Photogrammetry Remote Sensing and Spatial Information Sciences . XL1  W4  215 218. Bibcode  2015ISPAr.XL1..215P . doi  10.5194isprsarchivesXL1W42152015 . ISSN 16821750 .  Heincke Björn Jackisch Robert Saartenoja Ari Salmirinne Heikki Rapp Sönke Zimmermann Robert Pirttijärvi Markku Vest Sörensen Erik Gloaguen Richard Ek Lisa Bergström Johan Karinen Arto Salehi Sara Madriz Yuleika Middleton Maarit 29 July 2019. Developing multisensor drones for geological mapping and mineral exploration setup and first results from the MULSEDRO project . Geological Survey of Denmark and Greenland Bulletin . 43 . doi  10.34194GEUSB2019430302 . ISSN 16048156 .  Šálek Ondřej Matolín Milan Gryc Lubomír 1 February 2018. Mapping of radiation anomalies using UAV miniairborne gammaray spectrometry . Journal of Environmental Radioactivity . 182  101 107. Bibcode  2018JEnvR.182..101S . doi  10.1016j.jenvrad.2017.11.033 . ISSN 0265931X . PMID 29220714 .  Jackisch Robert 2020. Dronebased surveys of mineral deposits . Nature Reviews Earth  Environment . 1 4 187. Bibcode  2020NRvEE...1..187J . doi  10.1038s4301702000421 . ISSN 2662138X .  Jackisch Robert Heincke Björn H. Zimmermann Robert Sørensen Erik V. Pirttijärvi Markku Kirsch Moritz Salmirinne Heikki Lode Stefanie Kuronen Urpo Gloaguen Richard 7 April 2022. Dronebased magnetic and multispectral surveys to develop a 3D model for mineral exploration at Qullissat Disko Island Greenland . Solid Earth . 13 4 793 825. Bibcode  2022SolE...13..793J . doi  10.5194se137932022 . hdl  112503044853 . ISSN 18699510 .  Global Agriculture Drones and Robots Market Analysis  Forecast 20182028  ResearchAndMarkets.com . finance.yahoo.com . Archived from the original on 7 July 2019 . Retrieved 23 May 2019 .  Africa Farming Problems Aided With Drone Technology . Drone Addicts . 12 March 2018. Archived from the original on 29 June 2018 . Retrieved 23 May 2019 .  Drones That Launch Flaming Balls Are Being Tested To Help Fight Wildfires . NPR.org . Archived from the original on 25 April 2018 . Retrieved 5 April 2018 .  Old JM Lin S H Franklin MJM 2019. Mapping out barenosed wombat  Vombatus ursinus  burrows with the use of a drone. BMC Ecology. 1939. DOI 10.1186s1289801902575  Faust Daniel R. 2015. Police Drones 1\\xa0ed.. New York The Rosen Publishing Group Inc. ISBN 9781508145028 . Archived from the original on 27 February 2023 . Retrieved 20 February 2020 .  Sindi  Zarei 15 September 2023. Drones in humanitarian aid  Can they be a gamechanger .  Dent Steve 16 October 2017. Drone hits a commercial plane for the first time in Canada . Engadget. Archived from the original on 16 October 2017 . Retrieved 16 October 2017 .  Tellman Julie 28 September 2018. Firstever recorded dronehot air balloon collision prompts safety conversation . Teton Valley News . Boise Idaho United States Boise PostRegister. Archived from the original on 3 October 2018 . Retrieved 3 October 2018 .  Drones need to be encouraged and people protected . The Economist . 26 January 2019. ProQuest 2171135630 . Archived from the original on 27 June 2020 . Retrieved 28 June 2020 .  Halon Eytan 21 December 2018. Israeli antidrone technology brings an end to Gatwick Airport chaos  International news  Jerusalem Post . jpost.com . Archived from the original on 22 December 2018 . Retrieved 22 December 2018 .  Matthew Weaver Damien Gayle Patrick Greenfield Frances Perraudin 20 December 2018. Military called in to help with Gatwick drone crisis . The Guardian . Archived from the original on 22 December 2018 . Retrieved 22 December 2018 .  In The Heat of the Moment Drones Are Getting in the Way of Firefighters . NPR.org . Archived from the original on 5 March 2018 . Retrieved 5 April 2018 .  Michael Martinez Paul Vercammen Ben Brumfield 18 July 2015. Drones visit California wildfire angering firefighters . CNN . Archived from the original on 8 November 2016 . Retrieved 22 August 2016 .  Medina Jennifer 19 July 2015. Chasing Video With Drones Hobbyists Imperil California Firefighting Efforts . The New York Times . Archived from the original on 21 July 2015  via NYTimes.com.  Rocha Veronica 21 July 2015. Attack on the drones Legislation could allow California firefighters to take them down . Archived from the original on 28 August 2016 . Retrieved 22 August 2016  via LA Times.  Prisons Work To Keep Out DrugSmuggling Drones . NPR.org . Archived from the original on 19 January 2018 . Retrieved 19 January 2018 .  Mike Mount Elaine Quijano. Iraqi insurgents hacked Predator drone feeds U.S. official indicates . CNN.com . Archived from the original on 5 March 2017 . Retrieved 6 December 2016 .  Walters Sander 29 October 2016. How Can Drones Be Hacked The updated list of vulnerable drones  attack tools . Medium . Archived from the original on 23 July 2018 . Retrieved 6 December 2016 .  Glaser April 4 January 2017. The U.S. government showed just how easy it is to hack drones made by Parrot DBPower and Cheerson . Recode . Archived from the original on 5 January 2017 . Retrieved 6 January 2017 .  Antidrone technology to be test flown on UK base amid terror fears . 6 March 2017. Archived from the original on 7 May 2017 . Retrieved 9 May 2017 .  IsaacMedina Brian K. S. Poyser Matthew Organisciak Daniel Willcocks Chris G. Breckon Toby P. Shum Hubert P. H. 2021. Unmanned Aerial Vehicle Visual Detection and Tracking using Deep Neural Networks A Performance Benchmark . pp. 1223 1232. arXiv  2103.13933 .  Organisciak Daniel Poyser Matthew Alsehaim Aishah Hu Shanfeng IsaacMedina Brian K. S. Breckon Toby P. Shum Hubert P. H. 2022. UAVReID A Benchmark on Unmanned Aerial Vehicle Reidentification in Video Imagery. Proceedings of the 17th International Joint Conference on Computer Vision Imaging and Computer Graphics Theory and Applications . SciTePress. pp. 136 146. arXiv  2104.06219 . doi  10.52200010836600003124 . ISBN 9789897585555 .  Heathrow picks CUAS to combat drone disruption . Archived from the original on 9 November 2019 . Retrieved 13 March 2019 .  Muscat International Airport to install USD10 million Aaronia counterUAS system . 21 January 2019. Archived from the original on 9 November 2019 . Retrieved 21 January 2019 .  GrandClément Sarah Bajon Theò 19 October 2022. Uncrewed Aerial Systems A Primer . United Nations Institute for Disarmament Research . Archived from the original on 5 January 2023 . Retrieved 5 January 2023 .  cite journal    CS1 maint bot original URL status unknown  link   Hartley John Shum Hubert P. H. Ho Edmond S. L. Wang He Ramamoorthy Subramanian 2022. Formation Control for UAVs Using a Flux Guided Approach. Expert Systems with Applications . 205 . Elsevier 117665. arXiv  2103.09184 . doi  10.1016j.eswa.2022.117665 . ISSN 09574174 . S2CID 232240581 .  What is unmanned traffic management . Airbus . Archived from the original on 8 February 2021 . Retrieved 28 January 2021 .  Cary Leslie Coyne James. ICAO Unmanned Aircraft Systems UAS Circular 328. 20112012 UAS Yearbook  UAS The Global Perspective PDF . Blyenburgh  Co. pp. 112 115. Archived from the original PDF on 4 March 2016 . Retrieved 26 February 2022 .  Boedecker Hendrik. The 2021 Drone Regulation  What is new What is planned . Drone Industry Insights . Archived from the original on 17 May 2021 . Retrieved 17 May 2021 .  UAS Remote Identification Overview . www.faa.gov . Archived from the original on 27 May 2021 . Retrieved 29 May 2021 .  FAA Legal Battle  Challenging Remote ID . RaceDayQuads . Archived from the original on 27 May 2021 . Retrieved 29 May 2021 .  UAS Class Label . www.eudronport.com . August 2022. Archived from the original on 5 October 2022 . Retrieved 21 February 2023 .  Consolidated text Commission Delegated Regulation EU 2019945 of 12 March 2019 on unmanned aircraft systems and on thirdcountry operators of unmanned aircraft systems Bibliography  edit  Axe David 2021. Drone War Vietnam . Yorkshire Pen  Sword Military . ISBN 9781526770264 . Sayler Kelley June 2015. A world of proliferated drones a technology primer PDF . Center for a New American Security . Archived from the original PDF on 6 March 2016. Wagner William 1982 Lightning Bugs and other Reconnaissance Drones The cando story of Ryans unmanned spy planes  Armed Forces Journal International\\xa0 Aero Publishers ISBN 9780816866540 Further reading  edit  Cahill Bill April 2022. Lightning Bugs  Buffalo Hunters The Ryan Model 147 Drone in Vietnam. The Aviation Historian 39 18 27. ISSN 20511930 . Hill John Rogers Ann 2014. The rise of the drones From The Great War to Gaza . Arts  Humanities Colloquium Series. Vancouver Island University. hdl  106132480 . GarciaBernardoa Javier Dodds Peter Sheridan Johnson Neil F. 2016. Quantitative patterns in drone wars PDF . Science direct . Archived from the original PDF on 6 February 2016. Rogers Ann Hill John 2014. Unmanned Drone warfare and global security . Between the Lines. ISBN 9781771131544 . External links  edit  Wikimedia Commons has media related to Unmanned aerial vehicles . Wikiquote has quotations related to Drones . How Intelligent Drones Are Shaping the Future of Warfare Archived 2 May 2018 at the Wayback Machine  Rolling Stone Magazine v t e Lists of aircraft By name pre1914 0Ah AiAm AnAz BBe BfBo BrBz CCc CdCn CoCz D E F GGn GoGz H I J K LaLh LiLz M N O P Q R S T U V W X Y Z Gliders List of humanpowered aircraft List of unmanned aerial vehicle Civil aircraft By characteristic Type Aerobatic Bush planes Electric aircraft Flying wings Gliders Humanpowered Pronepilot Rocketpowered Flying boats and floatplanes STOL Supersonic Trimotors Triplanes Unmanned VTOL Fuselage Doubledeck Narrowbody Widebody Weight Size Maximum takeoff weight Light aircraft very light jets Large aircraft Manufacturer Airbus Antonov Boeing Bombardier Douglas\\xa0 McDonnell Douglas Embraer Ilyushin Tupolev Engine number Twinjets Trijets Trimotors Fourengined jet aircraft Range Jet airliners Regional airliners Use Racers Regional airliner regional jet Research Early flying machines Experimental Xplanes Rotorpowered Rotorcraft utility Tiltrotors Executive Private Business jets Lightsport aircraft Flying car Other lists By date and usage By tail number Mostproduced Military aircraft Role AEW Attack Bomber Torpedo Carrierbased Fighter Maritime patrol Submarineborne Tanker Nation Afghanistan Albania Argentina Australia Bangladesh Belize Brazil Bulgaria Canada Chile China Czech Republic Denmark Egypt Finland France Germany Greece India Indonesia Iran Ireland Israel Italy Japan Malaysia Morocco New Zealand Norway Pakistan Philippines Poland Portugal Romania Russia South Africa Spain Sri Lanka Sweden Switzerland Thailand Turkey United Kingdom United States Era WWI Entente WWI Central Powers Interwar World War II World War II jets v t e Countries producing stealth aircraft Stealth technology United States Experimental Boeing Model 85321 Quiet Bird BoeingSikorsky RAH66 Comanche Boeing Bird of Prey Boeing X32 Boeing X45 F19 Lockheed Have Blue Lockheed YF22 Lockheed Martin FB22 Lockheed Martin X35 Lockheed Martin X44 MANTA McDonnell Douglas A12 Avenger II Northrop Tacit Blue Northrop Grumman X47B Northrop YF23 Fighters Boeing F47 Lockheed Martin F22 Raptor Lockheed Martin F35 Lightning II Attack Lockheed F117 Nighthawk Bombers Northrop B2 Spirit Northrop Grumman B21 Raider UAVs General Atomics MQ20 Avenger Boeing MQ25 Stingray Boeing Phantom Ray Lockheed Martin Sea Ghost Lockheed Martin RQ170 Sentinel Northrop Grumman RQ180 Kratos XQ58 Valkyrie General Atomics XQ67A Australia UAVs Boeing MQ28 Ghost Bat China Fighters Chengdu J20 Shenyang J35 Bombers Xian H20 Experimental JHXX Chengdu J36 Shenyang JXD UAVs Hongdu GJ11 AVIC Dark Sword CAIG Wing Loong10 CASC Rainbow7 FL71 Russia Experimental Yakovlev Yak43 Sukhoi Su47 Mikoyan Project 1.44 Fighters Mikoyan LMFS Mikoyan PAK DP Sukhoi Su57 Sukhoi Su75 Checkmate SukhoiHAL FGFA Bombers Tupolev PAK DA UAVs Mikoyan Skat Sukhoi S70 OkhotnikB United Kingdom Experimental British Aerospace P.125 BAE Systems Replica UAVs BAE Systems Taranis Japan Experimental Mitsubishi X2 Shinshin Italy UAVs Dassault nEUROn France UAVs Dassault nEUROn Spain UAVs Dassault nEUROn Turkey Fighters TAI TF Kaan UAVs Bayraktar Kızılelma TAI Anka3 South Korea Fighters KAI KF21 Boramae Authority control databases National Germany 2 United States France BnF data Czech Republic 2 3 Israel Other NARA', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6484bb51-fd23-4dbb-b207-f229abb70bd2', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/VisDrone-Dataset.txt', 'file_name': 'VisDrone-Dataset.txt', 'file_type': 'text/plain', 'file_size': 0, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/secufibre/drone_v2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://secufibre/drone_v2 loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "ds = deeplake.load(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "\n",
    "for tensor_name in ds.tensors:\n",
    "    tensor_data = ds[tensor_name].numpy()\n",
    "\n",
    "    if tensor_data.ndim > 1:\n",
    "        data[tensor_name] = [np.array(e).flatten().tolist() for e in tensor_data]\n",
    "    else:\n",
    "        if tensor_name == \"text\":\n",
    "            data[tensor_name] = [t.tobytes().decode('utf-8') if t else \"\" for t in tensor_data]\n",
    "        else:\n",
    "            data[tensor_name] = tensor_data.tolist()\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0027042930014431477, 0.007869635708630085,...</td>\n",
       "      <td>[668b88ea-59f2-496b-86b0-35219acff460]</td>\n",
       "      <td>[{'file_path': '/storage2/RAG/003_RAG_index-ba...</td>\n",
       "      <td>[High Energy Physics  Theory arXiv1804.06985 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.014088690280914307, 0.014641465619206429, ...</td>\n",
       "      <td>[bb732a80-c435-416b-88df-51415d4b19ac]</td>\n",
       "      <td>[{'file_path': '/storage2/RAG/003_RAG_index-ba...</td>\n",
       "      <td>[Computer Science  Computer Vision and Pattern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.014408417046070099, -0.0004371690738480538...</td>\n",
       "      <td>[fea05bc2-e717-4a11-8e32-1480be7231ad]</td>\n",
       "      <td>[{'file_path': '/storage2/RAG/003_RAG_index-ba...</td>\n",
       "      <td>[Computerized information extraction from imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.004417059011757374, -0.0012542684562504292...</td>\n",
       "      <td>[93a9d953-f1d4-4e17-8678-63562939a727]</td>\n",
       "      <td>[{'file_path': '/storage2/RAG/003_RAG_index-ba...</td>\n",
       "      <td>[These include the concept of scalespace  the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.018791090697050095, 0.00625045457854867, 0...</td>\n",
       "      <td>[1e4ffa59-1f44-4861-8386-1eb19358dbb7]</td>\n",
       "      <td>[{'file_path': '/storage2/RAG/003_RAG_index-ba...</td>\n",
       "      <td>[Also some of the learningbased methods develo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           embedding  \\\n",
       "0  [-0.0027042930014431477, 0.007869635708630085,...   \n",
       "1  [-0.014088690280914307, 0.014641465619206429, ...   \n",
       "2  [-0.014408417046070099, -0.0004371690738480538...   \n",
       "3  [-0.004417059011757374, -0.0012542684562504292...   \n",
       "4  [-0.018791090697050095, 0.00625045457854867, 0...   \n",
       "\n",
       "                                       id  \\\n",
       "0  [668b88ea-59f2-496b-86b0-35219acff460]   \n",
       "1  [bb732a80-c435-416b-88df-51415d4b19ac]   \n",
       "2  [fea05bc2-e717-4a11-8e32-1480be7231ad]   \n",
       "3  [93a9d953-f1d4-4e17-8678-63562939a727]   \n",
       "4  [1e4ffa59-1f44-4861-8386-1eb19358dbb7]   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  [{'file_path': '/storage2/RAG/003_RAG_index-ba...   \n",
       "1  [{'file_path': '/storage2/RAG/003_RAG_index-ba...   \n",
       "2  [{'file_path': '/storage2/RAG/003_RAG_index-ba...   \n",
       "3  [{'file_path': '/storage2/RAG/003_RAG_index-ba...   \n",
       "4  [{'file_path': '/storage2/RAG/003_RAG_index-ba...   \n",
       "\n",
       "                                                text  \n",
       "0  [High Energy Physics  Theory arXiv1804.06985 h...  \n",
       "1  [Computer Science  Computer Vision and Pattern...  \n",
       "2  [Computerized information extraction from imag...  \n",
       "3  [These include the concept of scalespace  the ...  \n",
       "4  [Also some of the learningbased methods develo...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_record(record_number):\n",
    "    record = df.iloc[record_number]\n",
    "    display_data = {\n",
    "        \"ID\": record[\"id\"] if \"id\" in record else \"N/A\",\n",
    "        \"Metadata\": record[\"metadata\"] if \"metadata\" in record else \"N/A\",\n",
    "        \"Text\": record[\"text\"] if \"text\" in record else \"N/A\",\n",
    "        \"Embedding\": record[\"embedding\"] if \"embedding\" in record else \"N/A\"\n",
    "    }\n",
    "    # Print the ID\n",
    "    print(\"ID:\")\n",
    "    print(display_data[\"ID\"])\n",
    "    print()\n",
    "\n",
    "    # Print the metadata in a structured format\n",
    "    print(\"Metadata:\")\n",
    "    metadata = display_data[\"Metadata\"]\n",
    "    if isinstance(metadata, list):\n",
    "        for item in metadata:\n",
    "            for key, value in item.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(metadata)\n",
    "    print()\n",
    "\n",
    "    # Print the text\n",
    "    print(\"Text:\")\n",
    "    print(display_data[\"Text\"])\n",
    "    print()\n",
    "\n",
    "    # Print the embedding\n",
    "    print(\"Embedding:\")\n",
    "    print(display_data[\"Embedding\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:\n",
      "['668b88ea-59f2-496b-86b0-35219acff460']\n",
      "\n",
      "Metadata:\n",
      "file_path: /storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/1804.06985.txt\n",
      "file_name: 1804.06985.txt\n",
      "file_type: text/plain\n",
      "file_size: 3798\n",
      "creation_date: 2025-04-03\n",
      "last_modified_date: 2025-04-03\n",
      "_node_content: {\"id_\": \"668b88ea-59f2-496b-86b0-35219acff460\", \"embedding\": null, \"metadata\": {\"file_path\": \"/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/1804.06985.txt\", \"file_name\": \"1804.06985.txt\", \"file_type\": \"text/plain\", \"file_size\": 3798, \"creation_date\": \"2025-04-03\", \"last_modified_date\": \"2025-04-03\"}, \"excluded_embed_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"excluded_llm_metadata_keys\": [\"file_name\", \"file_type\", \"file_size\", \"creation_date\", \"last_modified_date\", \"last_accessed_date\"], \"relationships\": {\"1\": {\"node_id\": \"958609f8-f8f4-4ff8-b0b4-718934cb602a\", \"node_type\": \"4\", \"metadata\": {\"file_path\": \"/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/1804.06985.txt\", \"file_name\": \"1804.06985.txt\", \"file_type\": \"text/plain\", \"file_size\": 3798, \"creation_date\": \"2025-04-03\", \"last_modified_date\": \"2025-04-03\"}, \"hash\": \"1d705b35b384a7ced7d26fc653e6620e54f3a939bf0ab6781b22add2019cec27\", \"class_name\": \"RelatedNodeInfo\"}}, \"metadata_template\": \"{key}: {value}\", \"metadata_separator\": \"\\n\", \"text\": \"High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF Abstract A new solution of fourdimensional vacuum General Relativity is presented. It describes the near horizon region of the extreme maximally spinning binary black hole system with two identical extreme Kerr black holes held in equilibrium by a massless strut. This is the first example of a nonsupersymmetric asymptotically flat near horizon extreme binary black hole geometry of two uncharged black holes. The black holes are corotating and the solution is uniquely specified by the mass. The binary extreme system has finite entropy. The distance between the black holes is fixed but there is a zerodistance limit where the objects collapse into one. This limiting geometry corresponds to the near horizon extreme Kerr NHEK black hole. Comments 1 figure Subjects High Energy Physics  Theory hepth  High Energy Astrophysical Phenomena astroph.HE General Relativity and Quantum Cosmology grqc Cite as arXiv1804.06985 hepth or arXiv1804.06985v1 hepth for this version httpsdoi.org10.48550arXiv.1804.06985 Focus to learn more arXivissued DOI via DataCite Related DOI  httpsdoi.org10.1140epjcs1005201971883 Focus to learn more DOIs linking to related resources Submission history From Maria J. Rodriguez  view email  v1 Thu 19 Apr 2018 031545 UTC 173 KB Fulltext links Access Paper View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF TeX Source Other Formats view license Current browse context hepth \\u00a0prev  next\\u00a0 new  recent  201804 Change to browse by astroph astroph.HE grqc References  Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation  loading... Data provided by Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer  What is the Explorer  Connected Papers Toggle Connected Papers  What is Connected Papers  Litmaps Toggle Litmaps  What is Litmaps  scite.ai Toggle scite Smart Citations  What are Smart Citations  Code Data Media Code Data and Media Associated with this Article alphaXiv Toggle alphaXiv  What is alphaXiv  Links to Code Toggle CatalyzeX Code Finder for Papers  What is CatalyzeX  DagsHub Toggle DagsHub  What is DagsHub  GotitPub Toggle Gotit.pub  What is GotitPub  Huggingface Toggle Hugging Face  What is Huggingface  Links to Code Toggle Papers with Code  What is Papers with Code  ScienceCast Toggle ScienceCast  What is ScienceCast  Demos Demos Replicate Toggle Replicate  What is Replicate  Spaces Toggle Hugging Face Spaces  What is Spaces  Spaces Toggle TXYZ.AI  What is TXYZ.AI  Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower  What are Influence Flowers  Core recommender toggle CORE Recommender  What is CORE  IArxiv recommender toggle IArxiv Recommender  What is IArxiv  Author Venue Institution Topic About arXivLabs arXivLabs experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness community excellence and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXivs community Learn more about arXivLabs . Which authors of this paper are endorsers  Disable MathJax  What is MathJax\", \"mimetype\": \"text/plain\", \"start_char_idx\": 0, \"end_char_idx\": 3795, \"metadata_seperator\": \"\\n\", \"text_template\": \"{metadata_str}\\n\\n{content}\", \"class_name\": \"TextNode\"}\n",
      "_node_type: TextNode\n",
      "document_id: 958609f8-f8f4-4ff8-b0b4-718934cb602a\n",
      "doc_id: 958609f8-f8f4-4ff8-b0b4-718934cb602a\n",
      "ref_doc_id: 958609f8-f8f4-4ff8-b0b4-718934cb602a\n",
      "\n",
      "\n",
      "Text:\n",
      "['High Energy Physics  Theory arXiv1804.06985 hepth Submitted on 19 Apr 2018 Title A Near Horizon Extreme Binary Black Hole Geometry Authors Jacob Ciafre  Maria J. Rodriguez View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF Abstract A new solution of fourdimensional vacuum General Relativity is presented. It describes the near horizon region of the extreme maximally spinning binary black hole system with two identical extreme Kerr black holes held in equilibrium by a massless strut. This is the first example of a nonsupersymmetric asymptotically flat near horizon extreme binary black hole geometry of two uncharged black holes. The black holes are corotating and the solution is uniquely specified by the mass. The binary extreme system has finite entropy. The distance between the black holes is fixed but there is a zerodistance limit where the objects collapse into one. This limiting geometry corresponds to the near horizon extreme Kerr NHEK black hole. Comments 1 figure Subjects High Energy Physics  Theory hepth  High Energy Astrophysical Phenomena astroph.HE General Relativity and Quantum Cosmology grqc Cite as arXiv1804.06985 hepth or arXiv1804.06985v1 hepth for this version httpsdoi.org10.48550arXiv.1804.06985 Focus to learn more arXivissued DOI via DataCite Related DOI  httpsdoi.org10.1140epjcs1005201971883 Focus to learn more DOIs linking to related resources Submission history From Maria J. Rodriguez  view email  v1 Thu 19 Apr 2018 031545 UTC 173 KB Fulltext links Access Paper View a PDF of the paper titled A Near Horizon Extreme Binary Black Hole Geometry by Jacob Ciafre and Maria J. Rodriguez View PDF TeX Source Other Formats view license Current browse context hepth \\xa0prev  next\\xa0 new  recent  201804 Change to browse by astroph astroph.HE grqc References  Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar a export BibTeX citation Loading... BibTeX formatted citation  loading... Data provided by Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer  What is the Explorer  Connected Papers Toggle Connected Papers  What is Connected Papers  Litmaps Toggle Litmaps  What is Litmaps  scite.ai Toggle scite Smart Citations  What are Smart Citations  Code Data Media Code Data and Media Associated with this Article alphaXiv Toggle alphaXiv  What is alphaXiv  Links to Code Toggle CatalyzeX Code Finder for Papers  What is CatalyzeX  DagsHub Toggle DagsHub  What is DagsHub  GotitPub Toggle Gotit.pub  What is GotitPub  Huggingface Toggle Hugging Face  What is Huggingface  Links to Code Toggle Papers with Code  What is Papers with Code  ScienceCast Toggle ScienceCast  What is ScienceCast  Demos Demos Replicate Toggle Replicate  What is Replicate  Spaces Toggle Hugging Face Spaces  What is Spaces  Spaces Toggle TXYZ.AI  What is TXYZ.AI  Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower  What are Influence Flowers  Core recommender toggle CORE Recommender  What is CORE  IArxiv recommender toggle IArxiv Recommender  What is IArxiv  Author Venue Institution Topic About arXivLabs arXivLabs experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness community excellence and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXivs community Learn more about arXivLabs . Which authors of this paper are endorsers  Disable MathJax  What is MathJax']\n",
      "\n",
      "Embedding:\n",
      "[-0.0027042930014431477, 0.007869635708630085, -0.012820351868867874, -0.0030011930502951145, -0.00997297465801239, 0.019903024658560753, -0.014036568813025951, -0.025340227410197258, -0.012834660708904266, -0.034368846565485, 0.01264149695634842, 0.01742766611278057, -0.009543722495436668, 0.011060415767133236, -0.007361686788499355, 0.02054690383374691, 0.020689988508820534, 0.01354292780160904, 0.02732909843325615, -0.014644676819443703, -0.007383149117231369, 0.006885931361466646, -0.011604135856032372, -0.006474563851952553, -0.00825596321374178, 0.007368840742856264, 0.02137679234147072, -0.006646265275776386, -0.010924485512077808, -0.024195553734898567, 0.01081717200577259, -0.002486089477315545, -0.021834662184119225, 0.013142292387783527, -0.006753578316420317, 0.02950398065149784, 0.020346585661172867, 0.005179651081562042, 0.03411129489541054, 0.009186011739075184, 0.02013195864856243, 0.01711288094520569, -0.008327505551278591, -0.014487284235656261, 0.006682036444544792, -0.01372893713414669, 0.024553263559937477, -0.019201911985874176, -0.0034000403247773647, 0.0007422497728839517, 0.028330689296126366, 0.025683630257844925, -0.024596190080046654, 0.0038811613339930773, 0.018715424463152885, -0.016798095777630806, -0.002972576068714261, 0.022120831534266472, -0.002507552271708846, -0.006996821612119675, 0.0051546115428209305, -0.02307949587702751, -0.009178857319056988, -0.0005419317167252302, -0.011217808350920677, -0.00970111507922411, -0.0154960285872221, 0.00022781701409257948, -0.006964627653360367, -0.014000797644257545, 0.026957079768180847, 0.01975993998348713, -0.016054056584835052, -0.03371065855026245, 0.016383150592446327, -0.02727186493575573, -0.01387917622923851, -0.005802067928016186, -0.012562800198793411, -0.002641693688929081, 0.007905406877398491, 0.0030459067784249783, 0.0009738674270920455, 0.02037520334124565, 0.006964627653360367, -0.010409382171928883, -0.006041734013706446, 0.024782199412584305, -0.009658189490437508, -0.0053406208753585815, 0.02558347024023533, -0.011661369353532791, 0.02702862210571766, 0.006120430305600166, -0.007361686788499355, -0.00017103043501265347, 0.007504770997911692, 0.022922102361917496, -0.01981717348098755, -0.01953100599348545, -0.013578698970377445, -0.003147854469716549, -0.01795707829296589, -0.020532594993710518, -0.017813993617892265, 0.005673292092978954, -0.010173292830586433, -0.001800179248675704, 0.0008607414201833308, 0.0026202311273664236, 0.009500796906650066, -0.012755963951349258, -0.0002709658583626151, -0.03711606562137604, 0.023165347054600716, 0.018000002950429916, 0.014923691749572754, -0.01628299243748188, -0.013149445876479149, -0.017341814935207367, 0.0208473801612854, 0.025096984580159187, -0.006792926695197821, -0.00420667789876461, 0.01910175196826458, 0.030047699809074402, -0.003283784491941333, -0.02535453625023365, 0.005068760830909014, -0.013914947398006916, 0.0007333069806918502, 0.015052467584609985, 0.001756359706632793, 0.023451514542102814, -0.008427664637565613, 0.02468203939497471, -0.04590144008398056, -0.029704298824071884, -0.015639113262295723, -0.031106524169445038, 0.007000398822128773, 0.03273768350481987, -0.015567570924758911, 0.00734737841412425, -0.01904451847076416, 0.028316380456089973, -0.0004245579184498638, -0.0011652426328510046, -0.0011357315815985203, -0.012276631779968739, 0.002793720690533519, 0.0036236096639186144, 0.008692370727658272, 0.02079014666378498, 0.013771862722933292, 0.0012895471882075071, -0.010344994254410267, 0.023537365719676018, -0.027543725445866585, -0.04558665305376053, -0.017742451280355453, 0.005580287426710129, 0.013170909136533737, -0.013986488804221153, 0.03365342319011688, 0.026456285268068314, 0.009164548479020596, 0.0044606528244912624, 0.01039507333189249, -0.02642766758799553, -0.014966616407036781, 0.02144833467900753, -0.0330524705350399, -0.013929255306720734, -0.013550082221627235, 0.01543879508972168, 0.024195553734898567, 0.0031049291137605906, -0.03600000590085983, -0.005029412917792797, -0.0020765108056366444, -0.0026345395017415285, 0.01904451847076416, 0.03299523890018463, -0.00342508009634912, 0.012877586297690868, 0.033910974860191345, -0.03016216866672039, 0.01339984405785799, -0.019717015326023102, 0.012605725787580013, 0.02031796984374523, -0.029704298824071884, 0.008742449805140495, -0.6300287246704102, -0.018100162968039513, 0.006907394155859947, -0.024710657075047493, -0.024910975247621536, -0.0020747222006320953, 0.0051152631640434265, 0.022435616701841354, -0.009286170825362206, 0.021834662184119225, -0.024238478392362595, -0.0034107717219740152, -0.005186805501580238, -0.019359303638339043, -0.01729889027774334, -0.012992053292691708, -0.0037488082889467478, -0.005405008792877197, -0.0038310817908495665, -0.0015184819931164384, -0.015968207269906998, 0.005351352505385876, -0.011668523773550987, 0.0049292538315057755, 0.02030366100370884, 0.010559620335698128, 0.03708744794130325, -0.013271068222820759, -0.009021464735269547, 0.004979333374649286, -0.010802864097058773, -0.0028223376721143723, 0.0013235296355560422, -0.0038668529596179724, 0.047303665429353714, -0.051395878195762634, 0.016497619450092316, 0.018343405798077583, 0.012419716455042362, 0.03225119784474373, -0.017570750787854195, -0.006152624264359474, 0.02307949587702751, 0.005254770629107952, -0.00637082802131772, 0.002904611174017191, 0.017084263265132904, -0.02409539371728897, -0.011375200934708118, -0.020947540178894997, -0.014308429323136806, 0.012848969548940659, 0.007411766331642866, 0.007855327799916267, 0.0063565196469426155, -0.01252702996134758, 0.03665819391608238, -0.012870431877672672, -0.004371224902570248, -0.0035019880160689354, -0.009486488066613674, -0.0031907795928418636, -0.011403817683458328, -0.019373612478375435, -0.012562800198793411, -0.010266297496855259, -0.01372893713414669, 0.01370032038539648, 0.00692527974024415, 0.012777427211403847, 0.013657395727932453, 0.023651832714676857, -0.01940223015844822, 0.0029636332765221596, 0.024496030062437057, 0.020289352163672447, 0.03376789391040802, 0.0007945649558678269, -0.0072722588665783405, 0.0109387943521142, 0.0049113682471215725, 0.01456598099321127, -0.011618444696068764, -0.009643880650401115, 0.02217806503176689, 0.014201115816831589, -0.004693164490163326, 0.01189745869487524, -0.0006586348754353821, -0.010309223085641861, 0.014029414393007755, 0.009751194156706333, 0.0006054253899492323, -0.031106524169445038, -0.007440383080393076, 0.01609698310494423, 0.007021861616522074, 0.015524645335972309, 0.016268683597445488, -0.011861687526106834, -0.003097774926573038, -0.026756761595606804, 0.007397457957267761, -0.016969796270132065, 0.011482514441013336, 0.00862082839012146, -0.009665343910455704, -0.03082035668194294, 0.033367257565259933, -0.0510810911655426, -0.012305248528718948, -0.002065779408439994, -0.026270275935530663, 0.019158985465765, 0.00014084859867580235, -0.03322417289018631, 0.011511131189763546, 0.006270668935030699, -0.009665343910455704, -0.017627984285354614, 0.04673133045434952, 0.0154960285872221, 0.006102544721215963, 0.0005884341662749648, 0.01213354803621769, 0.007640701252967119, 0.023995235562324524, -0.02468203939497471, -0.052540551871061325, -0.00901431031525135, 0.010130367241799831, 0.01243402436375618, 0.039977751672267914, -0.0109387943521142, 0.04847695678472519, -0.0019423692720010877, 0.019259145483374596, 0.014315582811832428, 0.0018287961138412356, -0.02312242053449154, -0.01724165678024292, -0.010158984921872616, 0.014923691749572754, -0.004371224902570248, -0.012019080109894276, -0.022922102361917496, -0.005691177677363157, 0.009007155895233154, 0.016984105110168457, -0.0056017497554421425, -0.010981719009578228, 0.0200031828135252, -0.005744834430515766, 0.012698730453848839, -0.004610890988260508, -0.023594599217176437, -0.009751194156706333, -0.052769485861063004, 0.00338573195040226, -0.0016240066615864635, 0.019960258156061172, 0.019030209630727768, -0.02024642750620842, 0.008105725049972534, 0.0067857722751796246, 0.00171254004817456, 0.00019908837566617876, 0.023165347054600716, -0.015767889097332954, -0.02768681012094021, -0.005261924583464861, -0.013922100886702538, -0.025168526917696, 0.0035359705798327923, -0.023165347054600716, 0.010795709677040577, -0.015238476917147636, -0.008320351131260395, -0.0065818773582577705, 0.002507552271708846, 0.0044034188613295555, 0.0109387943521142, -0.03771701827645302, 0.0023161768913269043, 0.013893484137952328, 0.019674090668559074, 0.006864468567073345, -0.004821940325200558, 0.004700318910181522, 0.005365660879760981, -0.008391893468797207, 0.03411129489541054, -0.009643880650401115, 0.027858510613441467, -0.018944360315799713, -0.015882356092333794, 0.0016562006203457713, 0.015166934579610825, -0.01399364322423935, 0.027915744110941887, 0.02612719126045704, 0.001581081422045827, 0.018071545287966728, -0.006381559185683727, 0.003630763851106167, -0.017513517290353775, 0.006975359283387661, -0.014208270236849785, 0.002940382109954953, -0.009472180157899857, 0.010945947840809822, -0.027672501280903816, -0.007147060241550207, -0.021662961691617966, 0.004775437992066145, 0.02368045039474964, -0.0006613177247345448, 0.031049290671944618, 0.0006197338225319982, 0.013364072889089584, 0.00281518348492682, 0.021290943026542664, 0.016597777605056763, 0.011353738605976105, -0.013120829127728939, -0.00870667863637209, 0.02493959106504917, 0.025755172595381737, 0.012262323871254921, -0.01699841395020485, 0.0073330700397491455, -0.002521860646083951, 0.007125597447156906, -0.0022374805994331837, 0.023594599217176437, 0.02679968811571598, 0.009186011739075184, -0.006721384357661009, 0.02614150010049343, -0.0006496920832432806, -0.00837758556008339, 0.00425318069756031, 0.007984103634953499, -0.004399842116981745, -0.002402027603238821, -0.004489269573241472, 0.01656915992498398, 0.00814149621874094, -0.006621225271373987, -0.021062007173895836, -0.019201911985874176, 0.026241658255457878, -0.0163402259349823, 0.03196502849459648, 0.03828935697674751, 0.010638317093253136, -0.004389110486954451, 0.011811608448624611, 0.00740461191162467, 0.01754213310778141, 0.009937203489243984, 0.0031067177187651396, -0.004060016479343176, -0.0277011189609766, 0.011782990768551826, -0.02800159528851509, -0.021419718861579895, -0.003673689207062125, -0.010144676081836224, 0.009851353242993355, -0.02505405992269516, -0.01579650491476059, 0.007662163581699133, -0.008134341798722744, 0.016426077112555504, -0.002473569707944989, 0.000288627838017419, -0.0056625609286129475, 0.030505569651722908, 0.004979333374649286, -0.03837520629167557, -0.03196502849459648, 0.03179332986474037, 0.02252146787941456, 0.0023215427063405514, -0.01054531242698431, 0.0032068765722215176, 0.022578701376914978, 0.006775041110813618, 0.034883949905633926, 0.007504770997911692, -0.013263913802802563, 0.0025594201870262623, -0.008248809725046158, -0.029418129473924637, -0.012026234529912472, 0.028688399121165276, -0.021963438019156456, 0.009143086150288582, -0.008720987476408482, 0.004285374656319618, 0.0051581887528300285, -0.015352943912148476, 0.004757552407681942, 0.037344999611377716, -0.019659781828522682, -0.004296105820685625, -0.008635137230157852, -0.009658189490437508, -0.024295711889863014, 0.011976155452430248, -0.012090622447431087, -0.003006558632478118, -0.002452106913551688, -0.010502386838197708, -0.01861526630818844, -0.014179653488099575, 0.015596187673509121, 0.019917333498597145, 0.002607711125165224, -0.007390303537249565, -0.006120430305600166, -0.013442768715322018, 0.000913056603167206, 0.06192687898874283, 0.02114785835146904, -0.01951669715344906, 0.009829890914261341, -0.0063744052313268185, -0.012655805796384811, 0.0037309229373931885, 0.002901033964008093, 0.006242052186280489, 0.0031943568028509617, 0.02342289872467518, -0.0163402259349823, -0.009958666749298573, 0.011625598184764385, 0.033252790570259094, -0.016669319942593575, 0.010566774755716324, -0.026928463950753212, -0.0009515105048194528, 0.023222580552101135, -0.01881558448076248, 0.00549801392480731, 0.0018833469366654754, 0.014794915914535522, 0.012126393616199493, -0.01282750628888607, 0.031879179179668427, 0.0025612087920308113, 0.00579491350799799, -0.025883948430418968, 0.008441973477602005, -0.006957473699003458, -0.0007261527935042977, 0.0007109500584192574, -0.006692767608910799, -0.007150637451559305, 0.032594602555036545, -0.010445153340697289, 0.01910175196826458, -0.01682671159505844, -0.004231717903167009, 0.0013548294082283974, 0.007726551499217749, 0.0021462643053382635, 0.00507591525092721, 0.002369833644479513, -0.0030906207393854856, 0.027372024953365326, -0.031449925154447556, 0.0004317121347412467, 0.018944360315799713, -0.0008500100811943412, -0.020532594993710518, -0.021605728194117546, -0.010094597004354, 0.015267093665897846, -0.0005361189250834286, -0.022678859531879425, -0.005072338040918112, -0.01808585412800312, -0.005426471587270498, -0.023508748039603233, 0.01676947809755802, 0.0075763133354485035, -0.008735296316444874, -0.028745634481310844, -0.023093804717063904, -0.010023054666817188, -0.01759936846792698, 0.008813992142677307, -0.007941178046166897, -0.023709066212177277, -0.03846105560660362, 0.020446745678782463, 0.010058825835585594, -0.004246026277542114, -0.0061490475200116634, -0.01138950977474451, -0.010903023183345795, -0.01778537780046463, -0.029647065326571465, -0.002849165815860033, 0.011410972103476524, -0.021906204521656036, -0.0008294417639262974, 0.0019405806669965386, -0.003253379138186574, -0.0015596187440678477, -0.006524643395096064, 0.026599369943141937, 0.0007972477469593287, -0.0015757157234475017, 0.017828302457928658, -0.0006411964423023164, 0.013313992880284786, 0.0014988079201430082, 0.020761530846357346, -0.0006358308019116521, -0.006116853561252356, -0.012362482957541943, -0.020046109333634377, -0.00901431031525135, -0.0011893881019204855, -0.005354929715394974, 0.009922895580530167, 0.01543879508972168, 0.009536568075418472, 0.022206680849194527, 0.00032864673994481564, -0.01664070226252079, -0.0012367848539724946, 0.0011008547153323889, 0.007948332466185093, -0.003246224718168378, 0.01609698310494423, 0.004167329985648394, 0.03828935697674751, 0.009858507663011551, -0.018472181633114815, -0.00862082839012146, -0.00018578600429464132, -0.00930763315409422, 0.024109702557325363, 0.00879968423396349, 0.0021766696590930223, 0.021963438019156456, -0.01645469292998314, -0.0230079535394907, -0.036858513951301575, 0.007275836076587439, -0.01113911159336567, -0.009264707565307617, 0.0021981324534863234, -0.0210333913564682, -0.02715739794075489, -0.015596187673509121, -0.007157791405916214, -0.016540544107556343, 0.013442768715322018, -0.017098572105169296, 0.014651831239461899, -0.00811287946999073, -0.005032989662140608, -0.010058825835585594, -0.022750401869416237, -0.030562805011868477, -0.02463911473751068, 0.024910975247621536, -0.006606916896998882, -0.004153021611273289, -0.003319555427879095, -0.01438712514936924, 0.0011616655392572284, -0.024410178884863853, -0.024767890572547913, -0.03033386915922165, 0.005769873969256878, 0.003473371034488082, 0.034683629870414734, 0.017441974952816963, 0.03989189863204956, -0.0060739279724657536, 0.01171144936233759, 0.039491262286901474, 0.011797299608588219, 0.0012484104372560978, 0.009629572741687298, 0.005086646415293217, -0.010874406434595585, 0.008127187378704548, 0.020689988508820534, -0.010616853833198547, -0.007007553242146969, -0.03688712790608406, 0.011847378686070442, 0.027472183108329773, 0.014193961396813393, 0.003992051817476749, -0.0045786970295012, -0.06152624264359474, -0.014952308498322964, -0.008549286052584648, 0.005236885044723749, -0.00033870735205709934, -0.0430111363530159, -0.02704293094575405, 0.017613675445318222, 0.004610890988260508, 0.015038158744573593, -0.007869635708630085, 0.02060413733124733, -0.010023054666817188, 0.0188728179782629, 0.010044516995549202, 0.03170747682452202, -0.03185056149959564, -0.006696344818919897, -0.0015640901401638985, 0.012591417878866196, 0.01874404214322567, -0.0031746826134622097, 0.024825124070048332, 0.011546902358531952, -0.020561212673783302, 0.020990464836359024, -0.0011509342584758997, 0.010981719009578228, 0.0054693971760571, -0.010974564589560032, -0.021605728194117546, -0.0044463444501161575, -0.03476948291063309, -0.006900239735841751, -0.014480129815638065, -0.017742451280355453, 0.014465821906924248, -0.00037157200858928263, 0.03351034224033356, -0.027500800788402557, -0.009171702899038792, -2.5053723220480606e-05, 0.013285376131534576, 0.04086487367749214, 0.011632752604782581, 0.030505569651722908, 0.041608911007642746, 0.012620034627616405, -0.017470592632889748, 0.006943165324628353, -0.007243642117828131, 0.009379175491631031, 0.023623216897249222, 0.016798095777630806, -0.03957711532711983, -0.025855330750346184, 0.030505569651722908, 0.003108506090939045, -0.026055648922920227, -0.04063593968749046, 0.02163434401154518, -0.02926073782145977, 0.02313672937452793, -0.005108109209686518, -0.0018672499572858214, -0.02126232534646988, -0.012519875541329384, -0.007036169990897179, 0.01472337357699871, -0.021720195189118385, -0.002622019499540329, -0.0012251592706888914, 0.015367252752184868, -0.002920708153396845, 0.03803180530667305, 0.017828302457928658, -0.01861526630818844, 0.011461051180958748, -0.011582673527300358, -0.007891098968684673, 0.007225756533443928, -0.020346585661172867, 0.04049285501241684, -0.025511927902698517, -0.002207075245678425, 0.008577902801334858, -0.005852147471159697, -0.0006152624264359474, -0.029933232814073563, -0.0022857715375721455, 0.028917334973812103, -0.002716813003644347, -0.004131558816879988, -0.011654214933514595, -0.027600958943367004, 0.0054693971760571, 0.006664150860160589, 0.00226073176600039, 0.007919715717434883, 0.00885691773146391, 0.011811608448624611, 0.009300478734076023, 0.01951669715344906, 0.001175974030047655, -0.0146947568282485, 0.0025147064588963985, -0.009507951326668262, -0.025912564247846603, 0.0004048838163726032, -0.008484898135066032, -0.04055008664727211, -0.03356757387518883, -0.006789349485188723, -0.002915342338383198, 0.00994435790926218, -0.00092915358254686, -0.008434819057583809, -0.014322737231850624, 0.02582671493291855, -0.0260127242654562, 0.010824326425790787, 0.02524006925523281, 0.015453102998435497, -0.025812406092882156, -0.0010731321526691318, -0.0013566178968176246, 0.027257557958364487, 0.012734501622617245, -0.009078698232769966, -0.006621225271373987, -0.02775835245847702, -0.0009604532970115542, 0.018715424463152885, 0.01573927141726017, 0.009193165227770805, -0.0017393684247508645, 0.004074325319379568, 0.008749604225158691, -0.01483784057199955, 0.002296502934768796, 0.036200325936079025, -0.007562004495412111, -0.0070433239452540874, -0.011289350688457489, -0.01543879508972168, 0.011918921023607254, -0.006589031312614679, -0.009228936396539211, -0.00600596284493804, -0.01970270648598671, 0.004081479273736477, 0.0012466218322515488, 0.0033964633475989103, -0.01861526630818844, -0.013957872055470943, -0.020017491653561592, -0.018000002950429916, -0.026813995093107224, -0.004660970531404018, 0.01598251424729824, 0.007418920285999775, 0.006385136395692825, 0.02522576041519642, -0.007325915619730949, -0.004324722569435835, -0.002273251535370946, -0.007955486886203289, 0.018844200298190117, 0.016483310610055923, -0.055173300206661224, -0.0024449527263641357, 0.006546106189489365, 0.032165348529815674, 0.009722577407956123, -0.03322417289018631, 0.0006273351609706879, -0.029389513656497, -0.0036665350198745728, 0.018343405798077583, -0.013500003144145012, 0.020275043323636055, 0.02265024371445179, 0.0018708270508795977, 0.023823535069823265, 0.040464237332344055, 0.01827186346054077, 0.03124960884451866, 0.009879969991743565, 0.005151034332811832, -0.006685613188892603, 0.00692527974024415, 0.012462642043828964, -0.017213039100170135, -0.04627345874905586, -0.005941574927419424, 0.032880768179893494, 0.015066775493323803, 0.01459459774196148, 0.044298894703388214, 0.008456281386315823, 0.00012039201828883961, 0.031135141849517822, -0.0075548505410552025, -0.006571146193891764, 0.01820032112300396, 0.001860095770098269, -0.0640445277094841, -0.02114785835146904, 0.004621622618287802, 0.0005777028272859752, -0.02227822318673134, 0.002750795567408204, 0.016025440767407417, 0.0036665350198745728, 0.010402227751910686, -0.008399047888815403, -0.01480922382324934, 0.01910175196826458, -0.03660096228122711, 0.031879179179668427, 0.012584263458848, 0.009479334577918053, 0.025440387427806854, 0.029589831829071045, -0.012004772201180458, -0.00040309526957571507, 0.0023751992266625166, -0.014880766160786152, -0.002797297900542617, 0.008277426473796368, -0.01897297613322735, 0.01609698310494423, -0.015553262084722519, 0.005759142804890871, -0.010166138410568237, 0.008484898135066032, -0.029961850494146347, -0.019502388313412666, -0.020804455503821373, 0.020174885168671608, 0.012949127703905106, -0.025383152067661285, -0.022793326526880264, 0.010023054666817188, -0.011875996366143227, 0.017456283792853355, 0.008127187378704548, -0.014508746564388275, -0.0063350568525493145, 0.009372021071612835, -0.001076709246262908, -0.018457872793078423, -0.0158680472522974, 0.01940223015844822, 0.004750398453325033, 0.002167726866900921, 0.0158680472522974, 0.19093167781829834, -0.024839432910084724, 0.017027029767632484, 0.01669793576002121, -0.027844201773405075, -0.007819556631147861, 0.01754213310778141, 0.0033785777632147074, -0.009350558742880821, 0.023208271712064743, 0.00584141630679369, 0.012047696858644485, -0.014093802310526371, -0.001192071009427309, 0.024481721222400665, -0.022564392536878586, -0.03797456994652748, -0.023222580552101135, -0.0039026238955557346, -0.009243245236575603, -0.004174483940005302, 0.02162003517150879, -0.0034858910366892815, -0.009815582074224949, 0.02781558595597744, -0.023866459727287292, -0.014408587478101254, -0.01947377249598503, -0.004185215570032597, -0.004714627284556627, -0.02066137082874775, -0.020704297348856926, 0.023279814049601555, -0.0038883155211806297, -0.005648252088576555, 0.008370431140065193, 0.024667730554938316, 0.01795707829296589, 0.010695550590753555, 0.02054690383374691, -0.008077108301222324, -0.0026631562504917383, 0.005025835707783699, -0.015267093665897846, 0.012684422545135021, 0.010137521661818027, -0.011675678193569183, 0.003992051817476749, -0.005684023257344961, 0.0015623015351593494, -0.020275043323636055, 0.0012806043960154057, 0.03634341061115265, 0.03233705088496208, -0.011632752604782581, -0.012269477359950542, -0.005719794426113367, 0.011103340424597263, 6.595291779376566e-05, 0.025554854422807693, -0.020275043323636055, 0.010387919843196869, -0.003611089661717415, 0.04080763831734657, -0.0068430062383413315, 0.01141812652349472, -0.009901433251798153, -0.018958669155836105, 0.005637520924210548, -0.019158985465765, 0.016812404617667198, -0.01945946365594864, -0.010073133744299412, -0.02192051336169243, -0.019216220825910568, -0.024138320237398148, 0.007848173379898071, -0.002638116478919983, 0.019602548331022263, 0.02847377397119999, 0.015538954176008701, -0.013979335315525532, 0.019845791161060333, -0.01947377249598503, -0.02101908251643181, -0.04258188605308533, 0.0017670909874141216, 0.004714627284556627, -0.01645469292998314, -0.010867252014577389, 0.0007552167517133057, 0.014644676819443703, -0.01171144936233759, -0.011697140522301197, 0.0041601755656301975, -0.006274246145039797, -0.010795709677040577, -0.0038775841239839792, -0.040893491357564926, 0.007397457957267761, -0.014165344648063183, 0.0426391176879406, -0.0036432836204767227, -0.010488077998161316, -0.0020443168468773365, -0.012455487623810768, 0.0028956683818250895, 0.008162958547472954, 0.024181244894862175, -0.009429254569113255, 0.01910175196826458, -0.025254376232624054, -0.007197139784693718, -0.008499206975102425, 0.0033141898456960917, 0.024982517585158348, 0.020089033991098404, -0.012047696858644485, -0.010738476179540157, -0.025011133402585983, -0.01201192568987608, -0.025039751082658768, 0.003791733644902706, -0.002430644351989031, -0.009851353242993355, -0.03348172456026077, -0.01370032038539648, -0.012569954618811607, -0.018400639295578003, -0.012684422545135021, 0.007633546832948923, -0.016354534775018692, 0.042381566017866135, -0.0029493249021470547, 0.004428458865731955, 0.0077766310423612595, 0.011804454028606415, -0.028559623286128044, -0.017198732122778893, 0.006403021980077028, -0.012112084776163101, -0.0016812403919175267, 0.005301272962242365, 0.002731121378019452, 0.02445310540497303, -0.031936414539813995, 0.01808585412800312, -0.013621624559164047, -0.008735296316444874, -0.016812404617667198, -0.019001593813300133, -0.0032927272841334343, -0.006460255477577448, 0.004085056483745575, 0.008041337132453918, -0.0176566019654274, -0.023108113557100296, -0.05179651081562042, -0.0022535775788128376, 0.004106519278138876, -0.030248017981648445, 0.011089032515883446, 0.00862082839012146, -0.016855329275131226, -0.007919715717434883, -0.004711050074547529, -0.18578064441680908, 0.0016919716726988554, 0.022206680849194527, -0.008298888802528381, 0.015267093665897846, 0.02204928919672966, 0.013750400394201279, 0.008642290718853474, -0.004553657490760088, -0.0015256361803039908, 0.007998411543667316, -0.0003273053152952343, -0.017685217782855034, -0.021076316013932228, 0.020990464836359024, -0.0036039354745298624, 0.004142289981245995, 0.00555524742230773, 0.015009541995823383, 0.004321145359426737, 0.010738476179540157, -0.034454695880413055, 0.04129412770271301, 0.0013315781252458692, 0.007476154249161482, 0.010552465915679932, -0.010988873429596424, 0.03296662122011185, 0.0039312406443059444, 0.00518322829157114, 0.004614468198269606, -0.0036915745586156845, 0.03983466699719429, 0.006406599190086126, 0.009379175491631031, 0.006624802481383085, -0.005515899509191513, 0.02319396287202835, -0.02067567966878414, 0.006692767608910799, 0.0460159070789814, -0.002627385314553976, -0.0065783001482486725, -0.008806837722659111, -0.022335456684231758, 0.018543723970651627, 0.010330685414373875, -0.0004927465342916548, 0.009994437918066978, -0.032709069550037384, 0.004192369524389505, -0.031821947544813156, 0.021190783008933067, 0.00856359489262104, 0.017627984285354614, -0.002414547372609377, -0.017327507957816124, 0.02672814577817917, 0.006635534111410379, -0.008949922397732735, -0.03170747682452202, -0.011232116259634495, -0.0031335458625108004, -0.016740862280130386, 0.013972180895507336, -0.02330842986702919, 0.011067570187151432, -0.008213038556277752, -0.021534185856580734, -0.006538952235132456, -0.018157396465539932, -0.012519875541329384, -8.998660632641986e-05, 0.007275836076587439, 0.011339429765939713, 0.02307949587702751, -0.026399051770567894, 0.006857314612716436, 0.012090622447431087, -0.006986090447753668, -0.006989667657762766, 0.01396502647548914, -0.008499206975102425, -0.01105326134711504, 0.008656599558889866, -0.013077904470264912, -0.021176474168896675, -0.011403817683458328, -0.008248809725046158, -0.006789349485188723, 0.014680447988212109, -0.02283625304698944, 0.01772814430296421, -0.0210333913564682, 0.004102942068129778, -0.0010668722679838538, -0.002019277075305581, -0.003999205771833658, 0.017213039100170135, -0.0038811613339930773, 0.034282997250556946, 0.014172499068081379, -0.005773451179265976, -0.010495232418179512, 0.027829894796013832, 0.008391893468797207, -0.02944674715399742, 0.021248016506433487, 0.05136726051568985, -0.014709064736962318, -0.012620034627616405, -0.0075763133354485035, 0.021648652851581573, 0.013979335315525532, 0.00013280010898597538, 0.024825124070048332, 0.0033821549732238054, -0.02678537927567959, 0.015238476917147636, -0.009286170825362206, 0.038546908646821976, -0.0044606528244912624, -0.04272496700286865, 0.012419716455042362, -0.016597777605056763, -0.019244836643338203, -0.1001017689704895, -0.014823532663285732, 0.0015587244415655732, 0.015453102998435497, -0.004378379322588444, 0.006606916896998882, -0.007633546832948923, -0.003233704948797822, -0.009901433251798153, 0.03302385285496712, -0.02768681012094021, -0.017985695973038673, -0.0065568373538553715, 0.01441574189811945, -0.0018654614686965942, -0.01393640972673893, 0.005186805501580238, -0.02372337505221367, -0.00368799758143723, 0.017942769452929497, -0.0003641942166723311, 0.0012806043960154057, -0.01147536002099514, 0.005215422250330448, 0.01729889027774334, 0.0009953300468623638, -0.02529730275273323, 0.030419720336794853, 0.013421306386590004, -0.009500796906650066, -0.009558030404150486, -0.0013002784689888358, -0.015596187673509121, -0.02343720570206642, -0.017942769452929497, -0.015753580257296562, -0.00071363290771842, -0.0006774147041141987, 0.012412562035024166, -0.03972020000219345, 0.0033946747425943613, 0.023465823382139206, 0.02625596709549427, 0.004235295113176107, -0.00817011296749115, -0.014337046071887016, -0.022621626034379005, 0.022306840866804123, -0.006288554519414902, -0.00901431031525135, -0.025612087920308113, -0.008914151228964329, -0.025440387427806854, 0.002622019499540329, 0.031020672991871834, -0.019502388313412666, 0.01639745943248272, 0.02127663418650627, -0.010860097594559193, -0.0038489673752337694, -0.014766298234462738, 0.023823535069823265, -0.006156201474368572, 0.02060413733124733, 0.014709064736962318, 0.013593007810413837, -0.02847377397119999, -0.030906205996870995, -0.0019012325210496783, -0.017327507957816124, -0.007014707196503878, 0.03248013183474541, 0.008363276720046997, 0.001960254739969969, -0.016297301277518272, -0.013578698970377445, -0.02698569744825363, -0.02223529852926731, 0.007862481288611889, -0.016669319942593575, -0.016669319942593575, -0.025096984580159187, -0.007107711862772703, -0.014909382909536362, 0.0025629973970353603, 0.01585373841226101, 0.0014818166382610798, -0.002264308976009488, 0.032709069550037384, -0.03248013183474541, 0.00859221164137125, 0.04017806798219681, 0.018357714638113976, -0.04309698939323425, 0.008341814391314983, 0.006102544721215963, 0.013049286790192127, -0.00808426272124052, 0.01382194273173809, -0.0066033401526510715, -0.04220986366271973, 0.018672499805688858, -0.06553260236978531, 0.048934828490018845, 0.021848971024155617, -0.02079014666378498, -0.02877425029873848, -0.041608911007642746, 0.013507156632840633, 0.0070647867396473885, -0.012956282123923302, 0.023480132222175598, -0.013521465472877026, 0.008291734382510185, -0.005959460511803627, -0.027000006288290024, -0.017828302457928658, -0.03476948291063309, 0.0002223395713372156, 0.004982910584658384, 0.005648252088576555, 0.0030155014246702194, 0.007490462623536587, 0.021949129179120064, 0.01953100599348545, 0.02894595079123974, -0.012033388949930668, 0.01699841395020485, -0.03665819391608238, 0.02871701680123806, 0.00019797052664216608, -0.014337046071887016, 0.019545312970876694, -0.02918919548392296, 0.007397457957267761, 0.05036567151546478, 0.0009640303906053305, -0.008735296316444874, 0.004453498404473066, 0.007154214661568403, 0.023580290377140045, 0.04678856208920479, -0.030534187331795692, -0.04218124970793724, -0.01036645658314228, 0.003287361469119787, 0.020174885168671608, 0.03502703458070755, 0.008842608891427517, 0.009786965325474739, 0.01861526630818844, -0.0005034778150729835, 0.03147854283452034, 0.021891895681619644, -0.01168283261358738, -0.04092210531234741, 0.001443362794816494, 0.005487282294780016, -0.03236566483974457, -0.00107044936157763, 0.008048491552472115, -0.0035681645385921, 0.04072178900241852, 0.007504770997911692, 0.017384741455316544, -0.01459459774196148, 0.028745634481310844, -0.0024395871441811323, -0.013271068222820759, -0.01820032112300396, 0.0051367259584367275, -0.034282997250556946, -0.012126393616199493, 0.002956479089334607, 0.008842608891427517, 0.033367257565259933, -0.0037845794577151537, -0.024968208745121956, -0.01784261129796505, 0.013464231975376606, -0.003019078401848674, 0.002348370850086212, 0.01345707755535841, -0.010488077998161316, -0.022922102361917496, -0.00817011296749115, 0.02824483811855316, 0.007361686788499355, -0.010101750493049622, 0.017170114442706108, 0.0020103342831134796, 0.015181243419647217, 0.0019423692720010877, 0.019974566996097565, 0.010895868763327599, 0.009894278831779957, 0.002992250258103013, 0.004807631950825453, -0.004728935658931732, -0.025941181927919388, 0.033739276230335236, 0.015839431434869766, 0.020575521513819695, 0.002833068836480379, -0.0036021468695253134, -0.030248017981648445, -0.010509541258215904, 0.021233707666397095, -0.026627985760569572, -0.031821947544813156, 0.007891098968684673, 0.010023054666817188, 0.010974564589560032, -0.0002508446341380477, 0.010030209086835384, 0.020775839686393738, -0.03021940216422081, 0.024667730554938316, -0.011403817683458328, -0.030505569651722908, -0.00034161374787800014, 0.03262321650981903, 0.008291734382510185, 0.0033589035738259554, 0.018042929470539093, 0.0108457887545228, 0.018643882125616074, 0.03202226385474205, 0.04381240904331207, -0.01475199032574892, 0.01694118045270443, -0.03677266091108322, 0.013743245974183083, -0.005301272962242365, -0.006424484774470329, 0.0025862485636025667, -0.04189508035778999, -0.00740461191162467, 0.011675678193569183, -0.0034966222010552883, 0.023537365719676018, 0.0954086035490036, 0.020647063851356506, -0.005018681287765503, 0.030419720336794853, -0.026413360610604286, 0.020031800493597984, 0.014909382909536362, -0.00285453163087368, -0.009543722495436668, -0.06810811907052994, -0.012984898872673512, -0.01435850840061903, 0.01592528074979782, -0.04530048742890358, -0.0013423095224425197, 0.012455487623810768, -0.0121621647849679, 0.016683628782629967, -0.029647065326571465, -0.021949129179120064, 0.010645471513271332, -0.011310813017189503, 0.03448331356048584, 0.009050081484019756, -0.028402231633663177, 0.021047698333859444, 0.014909382909536362, 0.020518286153674126, 0.014208270236849785, -0.00428179744631052, -0.0007811507675796747, 0.003999205771833658, -0.0279872864484787, -0.03579968959093094, 0.001511327805928886, -0.015910973772406578, -0.015381560660898685, -0.001806439133360982, 0.04392687603831291, 0.007032592780888081, 0.00743322866037488, 0.025855330750346184, -0.01628299243748188, -0.01898728497326374, -0.011482514441013336, -0.0036593805998563766, -0.008162958547472954, 0.003752385498955846, -0.04198092967271805]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = 0\n",
    "display_record(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이프라인 3: 색인 기반 RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"How do drones identify vehicles?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "temp = 0.1\n",
    "mt = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
    "    embeddings1 = model.encode(text1)\n",
    "    embeddings2 = model.encode(text2)\n",
    "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_store_index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(vector_store_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = vector_store_index.as_query_engine(\n",
    "    similarity_top_k=k,\n",
    "    temperature=temp,\n",
    "    num_output=mt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "def index_query(input_query):\n",
    "    response = vector_query_engine.query(input_query)\n",
    "    print(textwrap.fill(str(response), width=100))\n",
    "\n",
    "    node_data = []\n",
    "    for node_with_score in response.source_nodes:\n",
    "        node = node_with_score.node\n",
    "        node_info = {\n",
    "            'Node ID': node.id_,\n",
    "            'Score': node_with_score.score,\n",
    "            'Text': node.text\n",
    "        }\n",
    "        node_data.append(node_info)\n",
    "    \n",
    "    df = pd.DataFrame(node_data)\n",
    "    return df, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drones can identify vehicles across different cameras with different viewpoints and hardware\n",
      "specifications using reidentification methods.\n",
      "Query execution time: 1.5290 seconds\n",
      "| Node ID                              | Score    | Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|:-------------------------------------|:---------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| 9882d5d1-8ad4-4e93-88ae-54ce9aefc25e | 0.841674 | Automatic tracking and detection of UAVs from commercial cameras have become accurate thanks to the development of deep learning based machine learning algorithms.  218  It is also possible to automatically identify UAVs across different cameras with different viewpoints and hardware specification with reidentification methods.  219  Commercial systems such as the Aaronia AARTOS have been installed on major international airports.  220   221  Once a UAV is detected it can be countered with kinetic force missiles projectiles or another UAV or by nonkinetic force laser microwaves communications jamming.  222  Antiaircraft missile systems such as the Iron Dome are also being enhanced with CUAS technologies. Utilising a smart UAV swarm to counter one or more hostile UAVs is also proposed.  223  Regulation  edit  Main article Regulation of unmanned aerial vehicles Regulatory bodies around the world are developing unmanned aircraft system traffic management solutions to better integrate UAVs into airspace.  224  The use of unmanned aerial vehicles is becoming increasingly regulated by the civil aviation authorities of individual countries. Regulatory regimes can differ significantly according to drone size and use. The International Civil Aviation Organization ICAO began exploring the use of drone technology as far back as 2005 which resulted in a 2011 report.  225  France was among the first countries to set a national framework based on this report and larger aviation bodies such as the FAA and the EASA quickly followed suit.  226  In 2021 the FAA published a rule requiring all commercially used UAVs and all UAVs regardless of intent weighing 250 g or more to participate in Remote ID  which makes drone locations controller locations and other information public from takeoff to shutdown this rule has since been challenged in the pending federal lawsuit RaceDayQuads v. FAA .  227   228  EU Drone Certification  Class Identification Label  edit  The implementation of the Class Identification Label serves a crucial purpose in the regulation and operation of drones.  229  The label is a verification mechanism designed to confirm that drones within a specific class meet the rigorous standards set by administrations for design and manufacturing.  230  These standards are necessary to ensure the safety and reliability of drones in various industries and applications. By providing this assurance to customers the Class Identification Label helps to increase confidence in drone technology and encourages wider adoption across industries. This in turn contributes to the growth and development of the drone industry and supports the integration of drones into society. Export controls  edit  The export of UAVs or technology capable of carrying a 500 kg payload at least 300 km is restricted in many countries by the Missile Technology Control Regime . See also  edit  List of unmanned aerial vehicles Delivery drone Drone in a Box Glide bomb International Aerial Robotics Competition List of films featuring drones List of military electronics of the United States MARSS Interceptor Micromechanical Flying Insect ParcAberporth Quadcopter Radiocontrolled aircraft Autonomous aircraft Optionally piloted vehicle Sypaq Corvo Precision Payload Delivery System Satellite Sentinel Project Tactical Control System UAV ground control station Unmanned underwater vehicle Portals  Aviation Systems science Engineering Telecommunication References  edit  Citations  edit   a b De Gruyter Handbook of Drone Warfare 2024. eISBN PDF 9783110742039.  Tice Brian P. Spring 1991. Unmanned Aerial Vehicles  The Force Multiplier of the 1990s . Airpower Journal . Archived from the original on 24 July 2009 . Retrieved 6 June 2013 . When used UAVs should generally perform missions characterized by the three Ds dull dirty and dangerous.  a b Alvarado Ed 3 May 2021. 237 Ways Drone Applications Revolutionize Business . Drone Industry Insights . Archived from the original on 11 May 2021 . Retrieved 11 May 2021 .  F.  RekabiBana Hu J. T. Krajník Arvin F.  Unified Robust Path Planning and Optimal Trajectory Generation for Efficient 3D Area Coverage of Quadrotor UAVs  IEEE Transactions on Intelligent Transportation Systems 2023.  a b Hu J. Niu H. Carrasco J. Lennox B. Arvin F.  Faulttolerant cooperative navigation of networked UAV swarms for forest fire monitoring  Aerospace Science and Technology 2022.  a b Remote sensing of the environment using unmanned aerial systems UAS . S.l. ELSEVIER  HEALTH SCIENCE. 2023. ISBN 9780323852838 . OCLC 1329422815 . Archived from the original on 27 February 2023 . Retrieved 11 January 2023 .                                                                                                                                                                                                                                                                                                                       |\n",
      "| cf53226b-ac11-4092-a3b2-9945f3203f87 | 0.828269 | Degree of autonomy  edit  Drones can also be classified based on the degree of autonomy in their flight operations. ICAO classifies unmanned aircraft as either remotely piloted aircraft or fully autonomous.  29  Some UAVs offer intermediate degrees of autonomy. For example a vehicle may be remotely piloted in most contexts but have an autonomous returntobase operation. Some aircraft types may optionally fly manned or as UAVs which may include manned aircraft transformed into manned or Optionally Piloted UAVs OPVs. The flight of UAVs may operate under remote control by a human operator as remotely piloted aircraft  RPA  or with various degrees of autonomy  such as autopilot assistance up to fully autonomous aircraft that have no provision for human intervention.  30   31  Altitude  edit  Based on the altitude the following UAV classifications have been used at industry events such as ParcAberporth Unmanned Systems forum Handheld 2000 ft 600 m altitude about 2 km range Close 5000 ft 1500 m altitude up to 10 km range NATO type 10000 ft 3000 m altitude up to 50 km range Tactical 18000 ft 5500 m altitude about 160 km range MALE medium altitude long endurance up to 30000 ft 9000 m and range over 200 km HALE high altitude long endurance over 30000 ft 9100 m and indefinite range Hypersonic highspeed supersonic Mach 15 or hypersonic Mach 5 50000 ft 15200 m or suborbital altitude range over 200 km Orbital low Earth orbit Mach 25 CIS Lunar EarthMoon transfer Computer Assisted Carrier Guidance System CACGS for UAVs Composite criteria  edit  An example of classification based on the composite criteria is U.S. Militarys unmanned aerial systems UAS classification of UAVs based on weight maximum altitude and speed of the UAV component. Power sources  edit  UAVs can be classified based on their power or energy source which significantly impacts their flight duration range and environmental impact. The main categories include Batterypowered electric These UAVs use rechargeable batteries offering quiet operation and lower maintenance but potentially limited flight times. The reduced noise levels make them suitable for urban environments and sensitive operations.  32  Fuelpowered internal combustion Utilizing traditional fuels like gasoline or diesel these UAVs often have longer flight times but may be noisier and require more maintenance. They are typically used for applications requiring extended endurance or heavy payload capacity.  33  Hybrid Combining electric and fuel power sources hybrid UAVs aim to balance the benefits of both systems for improved performance and efficiency. This configuration could allow for versatility in mission profiles and adaptability to different operational requirements.  34  Hydrogen fuel cell hydrogen fuel cells offer the potential for longer flight times than batteries yet stealthier no heat signature operation than combustion engines.  35  The high energy density of hydrogen makes it a promising option for future UAV propulsion systems.  36  Solarpowered Equipped with solar panels these UAVs can potentially achieve extended flight times by harnessing solar energy especially at high altitudes. Solarpowered UAVs may be particularly suited for longendurance missions and environmental monitoring applications.  37  Nuclearpowered While nuclear power has been explored for larger aircraft its application in UAVs remains largely theoretical due to safety concerns and regulatory challenges. Research in this area is ongoing but faces significant hurdles before practical implementation.  38  History  edit  Main article History of unmanned aerial vehicles Winston Churchill and others waiting to watch the launch of a de Havilland Queen Bee target drone  6 June 1941 A Ryan Firebee  one of a series of target dronesunpiloted aerial vehicles that first flew in 1951. Israeli Air Force Museum  Hatzerim airbase Israel 2006 Last preparations before the first tactical UAV mission across the Suez Canal 1969. Standing Major Shabtai Brill from the Israeli Intelligence Corps the innovator of the tactical UAV. The Israeli Tadiran Mastiff  which first flew in 1975 is seen by many as the first modern battlefield UAV due to its datalink system enduranceloitering and live videostreaming.  39  Early drones  edit  The earliest recorded use of an unmanned aerial vehicle for warfighting occurred in July 1849  40  with a balloon carrier the precursor to the aircraft carrier   41  in the first offensive use of air power in naval aviation .  42   43   44  Austrian forces besieging Venice attempted to launch some 200 incendiary balloons at the besieged city.                                                                                                                                                                                                                                                                                                                                              |\n",
      "| 9919f108-7cd0-409d-8c6f-fd741ba99853 | 0.82734  | 201  Law enforcement  edit  Main article Use of UAVs in law enforcement Police can use drones for applications such as search and rescue and traffic monitoring .  202  Humanitarian aid  edit  See also Delivery drone Drones are increasingly finding their application in humanitarian aid and disaster relief where they are used for a wide range of applications such as delivering food medicine and essential items to remote areas or image mapping before and following disasters.  203  Safety and security  edit  See also List of UAVrelated incidents and Unmanned combat aerial vehicle US Department of Agriculture poster warning about the risks of flying UAVs near wildfires Threats  edit  Nuisance  edit  UAVs can threaten airspace security in numerous ways including unintentional collisions or other interference with other aircraft deliberate attacks or by distracting pilots or flight controllers. The first incident of a droneairplane collision occurred in midOctober 2017 in Quebec City Canada.  204  The first recorded instance of a drone collision with a hot air balloon occurred on 10 August 2018 in Driggs Idaho  United States although there was no significant damage to the balloon nor any injuries to its 3 occupants the balloon pilot reported the incident to the National Transportation Safety Board  stating that I hope this incident helps create a conversation of respect for nature the airspace and rules and regulations.  205  Unauthorized UAV flights into or near major airports have prompted extended shutdowns of commercial flights.  206  Drones caused significant disruption at Gatwick Airport during December 2018  needing the deployment of the British Army.  207   208  In the United States flying close to a wildfire is punishable by a maximum 25000 fine. Nonetheless in 2014 and 2015 firefighting air support in California was hindered on several occasions including at the Lake Fire  209  and the North Fire .  210   211  In response California legislators introduced a bill that would allow firefighters to disable UAVs which invaded restricted airspace.  212  The FAA later required registration of most UAVs. Security vulnerabilities  edit  By 2017 drones were being used to drop contraband into prisons.  213  The interest in UAVs cybersecurity has been raised greatly after the Predator UAV video stream hijacking incident in 2009  214  where Islamic militants used cheap offtheshelf equipment to stream video feeds from a UAV. Another risk is the possibility of hijacking or jamming a UAV in flight. Several security researchers have made public some vulnerabilities in commercial UAVs in some cases even providing full source code or tools to reproduce their attacks.  215  At a workshop on UAVs and privacy in October 2016 researchers from the Federal Trade Commission showed they were able to hack into three different consumer quadcopters and noted that UAV manufacturers can make their UAVs more secure by the basic security measures of encrypting the WiFi signal and adding password protection.  216  Aggression  edit  Many UAVs have been loaded with dangerous payloads andor crashed into targets. Payloads have included or could include explosives chemical radiological or biological hazards. UAVs with generally nonlethal payloads could possibly be hacked and put to malicious purposes. CounterUAV systems CUAS from detection to electronic warfare to UAVs designed to destroy other UAVs are in development and being deployed by states to counter this threat. Such developments have occurred despite the difficulties. As J. Rogers stated in a 2017 interview to AT There is a big debate out there at the moment about what the best way is to counter these small UAVs whether they are used by hobbyists causing a bit of a nuisance or in a more sinister manner by a terrorist actor.  217  Countermeasures  edit  Counter unmanned air system  edit  Further information Electronic warfare Italian Army soldiers of the 17th Antiaircraft Artillery Regiment Sforzesca with a portable drone jammer in Rome Cannon antidrone system The malicious use of UAVs has led to the development of counter unmanned air system CUAS technologies. Automatic tracking and detection of UAVs from commercial cameras have become accurate thanks to the development of deep learning based machine learning algorithms.  218  It is also possible to automatically identify UAVs across different cameras with different viewpoints and hardware specification with reidentification methods.  219  Commercial systems such as the Aaronia AARTOS have been installed on major international airports.  220   221  Once a UAV is detected it can be countered with kinetic force missiles projectiles or another UAV or by nonkinetic force laser microwaves communications jamming.  222  Antiaircraft missile systems such as the Iron Dome are also being enhanced with CUAS technologies. Utilising a smart UAV swarm to counter one or more hostile UAVs is also proposed. |\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "df, response = index_query(user_input)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "print(df.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9882d5d1-8ad4-4e93-88ae-54ce9aefc25e'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodeid = response.source_nodes[0].node_id\n",
    "nodeid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automatic tracking and detection of UAVs from commercial cameras have become accurate thanks to the development of deep learning based machine learning algorithms.  218  It is also possible to automatically identify UAVs across different cameras with different viewpoints and hardware specification with reidentification methods.  219  Commercial systems such as the Aaronia AARTOS have been installed on major international airports.  220   221  Once a UAV is detected it can be countered with kinetic force missiles projectiles or another UAV or by nonkinetic force laser microwaves communications jamming.  222  Antiaircraft missile systems such as the Iron Dome are also being enhanced with CUAS technologies. Utilising a smart UAV swarm to counter one or more hostile UAVs is also proposed.  223  Regulation  edit  Main article Regulation of unmanned aerial vehicles Regulatory bodies around the world are developing unmanned aircraft system traffic management solutions to better integrate UAVs into airspace.  224  The use of unmanned aerial vehicles is becoming increasingly regulated by the civil aviation authorities of individual countries. Regulatory regimes can differ significantly according to drone size and use. The International Civil Aviation Organization ICAO began exploring the use of drone technology as far back as 2005 which resulted in a 2011 report.  225  France was among the first countries to set a national framework based on this report and larger aviation bodies such as the FAA and the EASA quickly followed suit.  226  In 2021 the FAA published a rule requiring all commercially used UAVs and all UAVs regardless of intent weighing 250 g or more to participate in Remote ID  which makes drone locations controller locations and other information public from takeoff to shutdown this rule has since been challenged in the pending federal lawsuit RaceDayQuads v. FAA .  227   228  EU Drone Certification  Class Identification Label  edit  The implementation of the Class Identification Label serves a crucial purpose in the regulation and operation of drones.  229  The label is a verification mechanism designed to confirm that drones within a specific class meet the rigorous standards set by administrations for design and manufacturing.  230  These standards are necessary to ensure the safety and reliability of drones in various industries and applications. By providing this assurance to customers the Class Identification Label helps to increase confidence in drone technology and encourages wider adoption across industries. This in turn contributes to the growth and development of the drone industry and supports the integration of drones into society. Export controls  edit  The export of UAVs or technology capable of carrying a 500\\xa0kg payload at least 300\\xa0km is restricted in many countries by the Missile Technology Control Regime . See also  edit  List of unmanned aerial vehicles Delivery drone Drone in a Box Glide bomb International Aerial Robotics Competition List of films featuring drones List of military electronics of the United States MARSS Interceptor Micromechanical Flying Insect ParcAberporth Quadcopter Radiocontrolled aircraft Autonomous aircraft Optionally piloted vehicle Sypaq Corvo Precision Payload Delivery System Satellite Sentinel Project Tactical Control System UAV ground control station Unmanned underwater vehicle Portals  Aviation Systems science Engineering Telecommunication References  edit  Citations  edit   a b De Gruyter Handbook of Drone Warfare 2024. eISBN PDF 9783110742039.  Tice Brian P. Spring 1991. Unmanned Aerial Vehicles  The Force Multiplier of the 1990s . Airpower Journal . Archived from the original on 24 July 2009 . Retrieved 6 June 2013 . When used UAVs should generally perform missions characterized by the three Ds dull dirty and dangerous.  a b Alvarado Ed 3 May 2021. 237 Ways Drone Applications Revolutionize Business . Drone Industry Insights . Archived from the original on 11 May 2021 . Retrieved 11 May 2021 .  F.  RekabiBana Hu J. T. Krajník Arvin F.  Unified Robust Path Planning and Optimal Trajectory Generation for Efficient 3D Area Coverage of Quadrotor UAVs  IEEE Transactions on Intelligent Transportation Systems 2023.  a b Hu J. Niu H. Carrasco J. Lennox B. Arvin F.  Faulttolerant cooperative navigation of networked UAV swarms for forest fire monitoring  Aerospace Science and Technology 2022.  a b Remote sensing of the environment using unmanned aerial systems UAS . S.l. ELSEVIER  HEALTH SCIENCE. 2023. ISBN 9780323852838 . OCLC 1329422815 . Archived from the original on 27 February 2023 . Retrieved 11 January 2023 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='9882d5d1-8ad4-4e93-88ae-54ce9aefc25e', embedding=None, metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Unmanned_aerial_vehicle.txt', 'file_name': 'Unmanned_aerial_vehicle.txt', 'file_type': 'text/plain', 'file_size': 104466, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7c0b268e-7f65-4502-a93b-a59dfbf6121f', node_type='4', metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Unmanned_aerial_vehicle.txt', 'file_name': 'Unmanned_aerial_vehicle.txt', 'file_type': 'text/plain', 'file_size': 104466, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, hash='102cf06a9cf3514fb2f7af2706c1423bc21df058af027dd17cc6365c3ccbadab'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9919f108-7cd0-409d-8c6f-fd741ba99853', node_type='1', metadata={'file_path': '/storage2/RAG/003_RAG_index-based_llamaindex_deeplake_openai/data/Unmanned_aerial_vehicle.txt', 'file_name': 'Unmanned_aerial_vehicle.txt', 'file_type': 'text/plain', 'file_size': 104466, 'creation_date': '2025-04-03', 'last_modified_date': '2025-04-03'}, hash='c7ec14f4a5b5b1788bd41610bb5b86efcaeca33262b7189f70c9c1ca8a477f57'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='747e9b2f-5f4f-4b22-a16c-e4631c9f577b', node_type='1', metadata={}, hash='587b987e010c98ba87ca92391d7cfa17273e0adf416d5d504ba5a4ae43a8a358')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Automatic tracking and detection of UAVs from commercial cameras have become accurate thanks to the development of deep learning based machine learning algorithms.  218  It is also possible to automatically identify UAVs across different cameras with different viewpoints and hardware specification with reidentification methods.  219  Commercial systems such as the Aaronia AARTOS have been installed on major international airports.  220   221  Once a UAV is detected it can be countered with kinetic force missiles projectiles or another UAV or by nonkinetic force laser microwaves communications jamming.  222  Antiaircraft missile systems such as the Iron Dome are also being enhanced with CUAS technologies. Utilising a smart UAV swarm to counter one or more hostile UAVs is also proposed.  223  Regulation  edit  Main article Regulation of unmanned aerial vehicles Regulatory bodies around the world are developing unmanned aircraft system traffic management solutions to better integrate UAVs into airspace.  224  The use of unmanned aerial vehicles is becoming increasingly regulated by the civil aviation authorities of individual countries. Regulatory regimes can differ significantly according to drone size and use. The International Civil Aviation Organization ICAO began exploring the use of drone technology as far back as 2005 which resulted in a 2011 report.  225  France was among the first countries to set a national framework based on this report and larger aviation bodies such as the FAA and the EASA quickly followed suit.  226  In 2021 the FAA published a rule requiring all commercially used UAVs and all UAVs regardless of intent weighing 250 g or more to participate in Remote ID  which makes drone locations controller locations and other information public from takeoff to shutdown this rule has since been challenged in the pending federal lawsuit RaceDayQuads v. FAA .  227   228  EU Drone Certification  Class Identification Label  edit  The implementation of the Class Identification Label serves a crucial purpose in the regulation and operation of drones.  229  The label is a verification mechanism designed to confirm that drones within a specific class meet the rigorous standards set by administrations for design and manufacturing.  230  These standards are necessary to ensure the safety and reliability of drones in various industries and applications. By providing this assurance to customers the Class Identification Label helps to increase confidence in drone technology and encourages wider adoption across industries. This in turn contributes to the growth and development of the drone industry and supports the integration of drones into society. Export controls  edit  The export of UAVs or technology capable of carrying a 500\\xa0kg payload at least 300\\xa0km is restricted in many countries by the Missile Technology Control Regime . See also  edit  List of unmanned aerial vehicles Delivery drone Drone in a Box Glide bomb International Aerial Robotics Competition List of films featuring drones List of military electronics of the United States MARSS Interceptor Micromechanical Flying Insect ParcAberporth Quadcopter Radiocontrolled aircraft Autonomous aircraft Optionally piloted vehicle Sypaq Corvo Precision Payload Delivery System Satellite Sentinel Project Tactical Control System UAV ground control station Unmanned underwater vehicle Portals  Aviation Systems science Engineering Telecommunication References  edit  Citations  edit   a b De Gruyter Handbook of Drone Warfare 2024. eISBN PDF 9783110742039.  Tice Brian P. Spring 1991. Unmanned Aerial Vehicles  The Force Multiplier of the 1990s . Airpower Journal . Archived from the original on 24 July 2009 . Retrieved 6 June 2013 . When used UAVs should generally perform missions characterized by the three Ds dull dirty and dangerous.  a b Alvarado Ed 3 May 2021. 237 Ways Drone Applications Revolutionize Business . Drone Industry Insights . Archived from the original on 11 May 2021 . Retrieved 11 May 2021 .  F.  RekabiBana Hu J. T. Krajník Arvin F.  Unified Robust Path Planning and Optimal Trajectory Generation for Efficient 3D Area Coverage of Quadrotor UAVs  IEEE Transactions on Intelligent Transportation Systems 2023.  a b Hu J. Niu H. Carrasco J. Lennox B. Arvin F.  Faulttolerant cooperative navigation of networked UAV swarms for forest fire monitoring  Aerospace Science and Technology 2022.  a b Remote sensing of the environment using unmanned aerial systems UAS . S.l. ELSEVIER  HEALTH SCIENCE. 2023. ISBN 9780323852838 . OCLC 1329422815 . Archived from the original on 27 February 2023 . Retrieved 11 January 2023 .', mimetype='text/plain', start_char_idx=51327, end_char_idx=55972, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 9882d5d1-8ad4-4e93-88ae-54ce9aefc25e, Chunk Size: 4645 characters\n",
      "Node ID: cf53226b-ac11-4092-a3b2-9945f3203f87, Chunk Size: 4622 characters\n",
      "Node ID: 9919f108-7cd0-409d-8c6f-fd741ba99853, Chunk Size: 4955 characters\n"
     ]
    }
   ],
   "source": [
    "for node_with_score in response.source_nodes:\n",
    "    node = node_with_score.node\n",
    "    chunk_size = len(node.text)\n",
    "    print(f\"Node ID: {node.id_}, Chunk Size: {chunk_size} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def info_metrics(response):\n",
    "    scores = [node.score for node in response.source_nodes if node.score is not None]\n",
    "    if scores:\n",
    "        weights = np.exp(scores) / np.sum(np.exp(scores))\n",
    "        perf = np.average(scores, weights=weights) / elapsed_time\n",
    "    else:\n",
    "        perf = 0\n",
    "\n",
    "    average_score=np.average(scores, weights=weights)\n",
    "    print(f\"Average score: {average_score:.4f}\")\n",
    "    print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "    print(f\"Performance metric: {perf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.8325\n",
      "Query execution time: 1.5290 seconds\n",
      "Performance metric: 0.5445\n"
     ]
    }
   ],
   "source": [
    "info_metrics(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트리 색인 쿼리 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import TreeIndex\n",
    "\n",
    "tree_index = TreeIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.indices.tree.base.TreeIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tree_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_query_engine = tree_index.as_query_engine(\n",
    "    similarity_top_k=k,\n",
    "    temperature=temp,\n",
    "    num_output=mt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution time: 4.0114 seconds\n",
      "Drones identify vehicles by utilizing convolutional neural networks (CNNs) for image processing.\n",
      "These networks are trained on large datasets to recognize patterns and features in images, allowing\n",
      "drones to distinguish vehicles based on visual information captured by their cameras.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "start_time = time.time()\n",
    "response = tree_query_engine.query(user_input)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drones identify vehicles by utilizing convolutional neural networks (CNNs) for image processing. These networks are trained on large datasets to recognize patterns and features in images, allowing drones to distinguish vehicles based on visual information captured by their cameras.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.774\n",
      "Query execution time: 4.0114 seconds\n",
      "Performance metric: 0.1930\n"
     ]
    }
   ],
   "source": [
    "similarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response.response))\n",
    "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "performance = similarity_score / elapsed_time\n",
    "print(f\"Performance metric: {performance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목록 색인 쿼리 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ListIndex\n",
    "\n",
    "list_index = ListIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.indices.list.base.SummaryIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(list_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_query_engine = list_index.as_query_engine(\n",
    "    similarity_top_k=k,\n",
    "    temperature=temp,\n",
    "    num_output=mt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution time: 19.0948 seconds\n",
      "Drones can identify vehicles through computer vision methods, which analyze images or video from the\n",
      "drone's cameras to detect and recognize vehicles based on visual characteristics. Object detection\n",
      "algorithms, often utilizing convolutional neural networks (CNNs) or other machine learning models,\n",
      "are employed to classify and pinpoint vehicles within the captured scenes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = list_query_engine.query(user_input)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.764\n",
      "Query execution time: 19.0948 seconds\n",
      "Performance metric: 0.0400\n"
     ]
    }
   ],
   "source": [
    "similarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response.response))\n",
    "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "performance = similarity_score / elapsed_time\n",
    "print(f\"Performance metric: {performance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 색인 쿼리 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import KeywordTableIndex\n",
    "\n",
    "keyword_index = KeywordTableIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Document ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binary</td>\n",
       "      <td>e625c299-bf5c-4af2-b9bb-c472fc7f7d15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kerr</td>\n",
       "      <td>e625c299-bf5c-4af2-b9bb-c472fc7f7d15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hole</td>\n",
       "      <td>e625c299-bf5c-4af2-b9bb-c472fc7f7d15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extreme binary black hole geometry</td>\n",
       "      <td>e625c299-bf5c-4af2-b9bb-c472fc7f7d15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general relativity</td>\n",
       "      <td>e625c299-bf5c-4af2-b9bb-c472fc7f7d15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Keyword                           Document ID\n",
       "0                              binary  e625c299-bf5c-4af2-b9bb-c472fc7f7d15\n",
       "1                                kerr  e625c299-bf5c-4af2-b9bb-c472fc7f7d15\n",
       "2                                hole  e625c299-bf5c-4af2-b9bb-c472fc7f7d15\n",
       "3  extreme binary black hole geometry  e625c299-bf5c-4af2-b9bb-c472fc7f7d15\n",
       "4                  general relativity  e625c299-bf5c-4af2-b9bb-c472fc7f7d15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for keyword, doc_ids in keyword_index.index_struct.table.items():\n",
    "    for doc_id in doc_ids:\n",
    "        data.append({\"Keyword\": keyword, \"Document ID\": doc_id})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_query_engine = keyword_index.as_query_engine(\n",
    "    similarity_top_k=k,\n",
    "    temperature=temp,\n",
    "    num_output=mt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution time: 1.8174 seconds\n",
      "Drones can identify vehicles through various methods such as radar-electrooptical data fusion for\n",
      "noncooperative sense and avoid systems. Additionally, drones can utilize advanced technologies like\n",
      "adaptive control systems and artificial intelligence for vehicle identification purposes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "response = keyword_query_engine.query(user_input)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.783\n",
      "Query execution time: 1.8174 seconds\n",
      "Performance metric: 0.4310\n"
     ]
    }
   ],
   "source": [
    "similarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response.response))\n",
    "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "performance = similarity_score / elapsed_time\n",
    "print(f\"Performance metric: {performance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
