{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt') # 문장과 단어를 분리하기 위한 토크나이저 데이터\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def nb_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'happy', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I am happy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent='Knowledge/1.0 (example@google.com)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Retrieval-Augmented Generation\"\n",
    "filename = \"RAG\"\n",
    "maxl = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page - Exists: True\n",
      "Number of tokens: 372\n",
      "Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence\n",
      "(Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large\n",
      "language model (LLM) so that the model responds to user queries with reference to a specified set of\n",
      "documents, using this information to supplement information from its pre-existing training data.\n",
      "This allows LLMs to use domain-specific and/or updated information. Use cases include providing\n",
      "chatbot access to internal company data or generating responses based on authoritative sources. RAG\n",
      "improves large language models (LLMs) by incorporating information retrieval before generating\n",
      "responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from\n",
      "databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving\n",
      "LLM performance, in essence by blending the LLM process with a web search or other document look-up\n",
      "process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led\n",
      "to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases. By\n",
      "dynamically retrieving information, RAG enables AI to provide more accurate responses without\n",
      "frequent retraining. According to IBM, \"RAG also reduces the need for users to continuously train\n",
      "the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower\n",
      "the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\"\n",
      "Beyond efficiency gains, RAG also allows LLMs to include source references in their responses,\n",
      "enabling users to verify information by reviewing cited documents or original sources. This can\n",
      "provide greater transparency, as users can cross-check retrieved content to ensure accuracy and\n",
      "relevance. Retrieval-Augmented Generation (RAG) was first introduced in 2020 by Douwe Kiela, Patrick\n",
      "Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich\n",
      "Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and Sebastian Riedel in their research paper\n",
      "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, at Meta.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "page = wiki.page(topic)\n",
    "if page.exists() == True:\n",
    "    print(\"Page - Exists: %s\" % page.exists())\n",
    "\n",
    "    summary = page.summary\n",
    "    nbt = nb_tokens(summary)\n",
    "    print(f\"Number of tokens: {nbt}\")\n",
    "\n",
    "    wrapped_text = textwrap.fill(summary, width=100)\n",
    "    print(wrapped_text)\n",
    "else:\n",
    "    print(\"Page does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n"
     ]
    }
   ],
   "source": [
    "print(page.fullurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1: 01.AI\n",
      "Link: 01.AI\n",
      "https://en.wikipedia.org/wiki/01.AI\n",
      "Summary: 01.AI (Chinese: 零一万物; pinyin: Língyī Wànwù) is an artificial intelligence (AI) company based in Beijing, China. It focuses on developing open source products.\n",
      "Link 2: 15.ai\n",
      "Link: 15.ai\n",
      "https://en.wikipedia.org/wiki/15.ai\n",
      "Summary: 15.ai was a free non-commercial web application that used artificial intelligence to generate text-to-speech voices of fictional characters from popular media. Created by an anonymous artificial intelligence researcher known as 15, who began developing the technology as a freshman during their undergraduate research at the Massachusetts Institute of Technology, the application allowed users to make characters from video games, television shows, and movies speak custom text with emotional inflections faster than real-time. The platform was notable for its ability to generate convincing voice output using minimal training data—the name \"15.ai\" referenced the creator's claim that a voice could be cloned with just 15 seconds of audio, in contrast to contemporary deep learning speech models which typically required tens of hours of audio data. It was an early example of an application of generative artificial intelligence during the initial stages of the AI boom.\n",
      "Launched in March 2020, 15.ai gained widespread attention in early 2021 when content utilizing it went viral on social media platforms like YouTube and Twitter, and quickly became popular among Internet fandoms, such as the My Little Pony: Friendship Is Magic, Team Fortress 2, and SpongeBob SquarePants fandoms. The service distinguished itself through its support for emotional context in speech generation through emojis, precise pronunciation control through phonetic transcriptions, and multi-speaker capabilities that allowed a single model to generate diverse character voices. 15.ai is credited as the first mainstream platform to popularize AI voice cloning (audio deepfakes) in memes and content creation.\n",
      "Voice actors and industry professionals debated 15.ai's merits for fan creativity versus its potential impact on the profession. While many critics praised the application's uniqueness, accessibility, and emotional control, they also noted technical limitations in areas like prosody options (such as rhythm and loudness) and non-English language support. 15.ai prompted discussions about ethical implications, including concerns about reduction of employment opportunities for voice actors, voice-related fraud, and misuse in explicit content, though 15.ai maintained strict policies against replicating real people's voices.\n",
      "In January 2022, Voiceverse generated controversy when it was discovered that the company had generated audio using 15.ai without attribution and sold it as an NFT (non-fungible token) without permission. News publications universally characterized this incident as Voiceverse having \"stolen\" voice lines from 15.ai. This incident was subsequently documented in resources tracking AI ethics violations and NFT-related controversies.\n",
      "15.ai's approach to data-efficient voice synthesis and emotional expression was influential in subsequent developments in AI text-to-speech technology. The service was ultimately taken offline in September 2022 due to legal issues surrounding artificial intelligence and copyright. Its shutdown was followed by the emergence of various commercial alternatives in subsequent years, with their founders acknowledging 15.ai's pioneering influence in the field of deep learning speech synthesis.\n",
      "Link 3: AI hallucinations\n",
      "Link: AI hallucinations\n",
      "https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\n",
      "Summary: In the field of artificial intelligence (AI), a hallucination or artificial hallucination (also called bullshitting, confabulation or delusion) is a response generated by AI that contains false or misleading information presented as fact. This term draws a loose analogy with human psychology, where hallucination typically involves false percepts. However, there is a key difference: AI hallucination is associated with erroneously constructed responses (confabulation), rather than perceptual experiences.\n",
      "For example, a chatbot powered by large language models (LLMs), like ChatGPT, may embed plausible-sounding random falsehoods within its generated content. Researchers have recognized this issue, and by 2023, analysts estimated that chatbots hallucinate as much as 27% of the time, with factual errors present in 46% of generated texts. Detecting and mitigating these hallucinations pose significant challenges for practical deployment and reliability of LLMs in real-world scenarios. Some researchers believe the specific term \"AI hallucination\" unreasonably anthropomorphizes computers.\n",
      "Link 4: AWS\n",
      "Link: AWS\n",
      "https://en.wikipedia.org/wiki/Amazon_Web_Services\n",
      "Summary: Amazon Web Services, Inc. (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered, pay-as-you-go basis. Clients will often use this in combination with autoscaling (a process that allows a client to use more computing in times of high application usage, and then scale down to reduce costs when there is less traffic). These cloud computing web services provide various services related to networking, compute, storage, middleware, IoT and other processing capacity, as well as software tools via AWS server farms.  This frees clients from managing, scaling, and patching hardware and operating systems. \n",
      "One of the foundational services is Amazon Elastic Compute Cloud (EC2), which allows users to have at their disposal a virtual cluster of computers, with extremely high availability, which can be interacted with over the internet via REST APIs, a CLI or the AWS console.  AWS's virtual computers emulate most of the attributes of a real computer, including hardware central processing units (CPUs) and graphics processing units (GPUs) for processing; local/RAM memory; hard-disk (HDD)/SSD storage; a choice of operating systems; networking; and pre-loaded application software such as web servers, databases, and customer relationship management (CRM).\n",
      "AWS services are delivered to customers via a network of AWS server farms located throughout the world. Fees are based on a combination of usage (known as a \"Pay-as-you-go\" model), hardware, operating system, software, and networking features chosen by the subscriber requiring various degrees of availability, redundancy, security, and service options. Subscribers can pay for a single virtual AWS computer, a dedicated physical computer, or clusters of either. Amazon provides select portions of security for subscribers (e.g. physical security of the data centers) while other aspects of security are the responsibility of the subscriber (e.g. account management, vulnerability scanning, patching). AWS operates from many global geographical regions, including seven in North America.\n",
      "Amazon markets AWS to subscribers as a way of obtaining large-scale computing capacity more quickly and cheaply than building an actual physical server farm. All services are billed based on usage, but each service measures usage in varying ways. As of 2023 Q1, AWS has 31% market share for cloud infrastructure while the next two competitors Microsoft Azure and Google Cloud have 25%, and 11% respectively, according to Synergy Research Group.\n",
      "Link 5: Action selection\n",
      "Link: Action selection\n",
      "https://en.wikipedia.org/wiki/Action_selection\n",
      "Summary: Action selection is a way of characterizing the most basic problem of intelligent systems: what to do next. In artificial intelligence and computational cognitive science, \"the action selection problem\" is typically associated with intelligent agents and animats—artificial systems that exhibit complex behavior in an agent environment. The term is also sometimes used in ethology or animal behavior.\n",
      "One problem for understanding action selection is determining the level of abstraction used for specifying an \"act\". At the most basic level of abstraction, an atomic act could be anything from contracting a muscle cell to provoking a war. Typically for any one action-selection mechanism, the set of possible actions is predefined and fixed.\n",
      "Most researchers working in this field place high demands on their agents:\n",
      "\n",
      "The acting agent typically must select its action in dynamic and unpredictable environments.\n",
      "The agents typically act in real time; therefore they must make decisions in a timely fashion.\n",
      "The agents are normally created to perform several different tasks. These tasks may conflict for resource allocation (e.g. can the agent put out a fire and deliver a cup of coffee at the same time?)\n",
      "The environment the agents operate in may include humans, who may make things more difficult for the agent (either intentionally or by attempting to assist.)\n",
      "The agents themselves are often intended to model animals or humans, and animal/human behaviour is quite complicated.\n",
      "For these reasons, action selection is not trivial and attracts a good deal of research.\n",
      "Link 6: Activation function\n",
      "Link: Activation function\n",
      "https://en.wikipedia.org/wiki/Activation_function\n",
      "Summary: The activation function of a node in an artificial neural network is a function that calculates the output of the node based on its individual inputs and their weights. Nontrivial problems can be solved using only a few nodes if the activation function is nonlinear.\n",
      "Modern activation functions include the logistic (sigmoid) function used in the 2012 speech recognition model developed by Hinton et al; the ReLU used in the 2012 AlexNet computer vision model and in the 2015 ResNet model; and the smooth version of the ReLU, the GELU, which was used in the 2018 BERT model.\n",
      "Link 7: Adobe Firefly\n",
      "Link: Adobe Firefly\n",
      "https://en.wikipedia.org/wiki/Adobe_Firefly\n",
      "Summary: Adobe Firefly is a web app and family of generative artificial intelligence models for creative production. Its capabilities include text-to-image and text-to-video. It is part of Adobe Creative Cloud, and also powers features in other Creative Cloud apps, including Photoshop's Generative Fill tool. Its video models are currently being tested in an open beta phase, and its image generation tools are available via subscription.\n",
      "Adobe Firefly is developed using Adobe's Sensei platform. Firefly is trained with images from Creative Commons, Wikimedia and Flickr Commons as well as 300 million images and videos in Adobe Stock and the public domain. This dependency only on training data for which Adobe owns the license or which is public domain has led them to describe the models' output as \"commercially safe\".\n",
      "Firefly for Enterprise was released on June 22, 2023.\n",
      "Link 8: Adversarial machine learning\n",
      "Link: Adversarial machine learning\n",
      "https://en.wikipedia.org/wiki/Adversarial_machine_learning\n",
      "Summary: Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks. A survey from May 2020 revealed practitioners' common feeling for better protection of machine learning systems in industrial applications.\n",
      "Machine learning techniques are mostly designed to work on specific problem sets, under the assumption that the training and test data are generated from the same statistical distribution (IID). However, this assumption is often dangerously violated in practical high-stake applications, where users may intentionally supply fabricated data that violates the statistical assumption.\n",
      "Most common attacks in adversarial machine learning include evasion attacks, data poisoning attacks, Byzantine attacks and model extraction.\n",
      "Link 9: Alan Turing\n",
      "Link: Alan Turing\n",
      "https://en.wikipedia.org/wiki/Alan_Turing\n",
      "Summary: Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\n",
      "Born in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba method, an electromechanical machine that could find settings for the Enigma machine. He played a crucial role in cracking intercepted messages that enabled the Allies to defeat the Axis powers in many engagements, including the Battle of the Atlantic.\n",
      "After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the University of Manchester, where he contributed to the development of early Manchester computers and became interested in mathematical biology. Turing wrote on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised during his lifetime because much of his work was covered by the Official Secrets Act.\n",
      "In 1952, Turing was prosecuted for homosexual acts. He accepted hormone treatment, a procedure commonly referred to as chemical castration, as an alternative to prison. Turing died on 7 June 1954, aged 41, from cyanide poisoning. An inquest determined his death as suicide, but the evidence is also consistent with accidental poisoning. \n",
      "Following a campaign in 2009, British prime minister Gordon Brown made an official public apology for \"the appalling way [Turing] was treated\". Queen Elizabeth II granted a pardon in 2013. The term \"Alan Turing law\" is used informally to refer to a 2017 law in the UK that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.\n",
      "Turing left an extensive legacy in mathematics and computing which has become widely recognised with statues and many things named after him, including an annual award for computing innovation. His portrait appears on the Bank of England £50 note, first released on 23 June 2021 to coincide with his birthday. The audience vote in a 2019 BBC series named Turing the greatest person of the 20th century.\n",
      "Link 10: AlexNet\n",
      "Link: AlexNet\n",
      "https://en.wikipedia.org/wiki/AlexNet\n",
      "Summary: AlexNet is a convolutional neural network architecture developed for image classification tasks, notably achieving prominence through its performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). It classifies images into 1,000 distinct object categories and is regarded as the first widely recognized application of deep convolutional networks in large-scale visual recognition.\n",
      "Developed in 2012 by Alex Krizhevsky in collaboration with Ilya Sutskever and his Ph.D. advisor Geoffrey Hinton at the University of Toronto, the model contains 60 million parameters and 650,000 neurons. The original paper's primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of graphics processing units (GPUs) during training.\n",
      "The three formed team SuperVision and submitted AlexNet in the ImageNet Large Scale Visual Recognition Challenge on September 30, 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points better than that of the runner-up.\n",
      "The architecture influenced a large number of subsequent work in deep learning, especially in applying neural networks to computer vision.\n",
      "Link 11: Alex Graves (computer scientist)\n",
      "Link: Alex Graves (computer scientist)\n",
      "https://en.wikipedia.org/wiki/Alex_Graves_(computer_scientist)\n",
      "Summary: Alex Graves is a computer scientist.\n",
      "Link 12: Alex Krizhevsky\n",
      "Link: Alex Krizhevsky\n",
      "https://en.wikipedia.org/wiki/Alex_Krizhevsky\n",
      "Summary: Alex Krizhevsky (born 4 March 1986) is a Soviet-born Canadian computer scientist most noted for his work on artificial neural networks and deep learning. In 2012, Krizhevsky, Ilya Sutskever and their PhD advisor Geoffrey Hinton, at the University of Toronto, developed a powerful visual-recognition network AlexNet using only two GeForce NVIDIA GPU cards. This revolutionized research in neural networks. Previously neural networks were trained on CPUs. The transition to GPUs opened the way to the development of advanced AI models.\n",
      "Link 13: Alibaba Group\n",
      "Link: Alibaba Group\n",
      "https://en.wikipedia.org/wiki/Alibaba_Group\n",
      "Summary: Alibaba Group Holding Limited, branded as Alibaba (), is a Chinese multinational technology company specializing in e-commerce, retail, Internet, and technology. Founded on 28 June 1999 in Hangzhou, Zhejiang, the company provides consumer-to-consumer (C2C), business-to-consumer (B2C), and business-to-business (B2B) sales services via Chinese and global marketplaces, as well as local consumer, digital media and entertainment, logistics, and cloud computing services. It owns and operates a diverse portfolio of companies around the world in numerous business sectors.\n",
      "On 19 September 2014, Alibaba's initial public offering (IPO) on the New York Stock Exchange raised US$25 billion, giving the company a market value of US$231 billion and, by far, then the largest IPO in world history. It is one of the top 10 most valuable corporations, and is named the 31st-largest public company in the world on the Forbes Global 2000 2020 list. In January 2018, Alibaba became the second Asian company to break the US$500 billion valuation mark, after its competitor Tencent. As of 2022, Alibaba has the ninth-highest global brand valuation. \n",
      "Alibaba is one of the world's largest retailers and e-commerce companies. In 2020, it was also rated as the fifth-largest artificial intelligence company. It is also one of the biggest venture capital firms and investment corporations in the world, as well as the second largest financial services group behind Visa via its fintech arm Ant Group. The company hosts the largest B2B (Alibaba.com), C2C (Taobao), and B2C (Tmall) marketplaces in the world. It has been expanding into the media industry, with revenues rising by triple percentage points year after year. It also set the record on the 2018 edition of China's Singles' Day, the world's biggest online and offline shopping day.\n",
      "Link 14: Allen Newell\n",
      "Link: Allen Newell\n",
      "https://en.wikipedia.org/wiki/Allen_Newell\n",
      "Summary: Allen Newell (March 19, 1927 – July 19, 1992) was an American researcher in computer science and cognitive psychology at the RAND Corporation and at Carnegie Mellon University's School of Computer Science, Tepper School of Business, and Department of Psychology. He, Herbert A. Simon, and Cliff Shaw contributed to the Information Processing Language (1956) and two of the earliest AI programs, the Logic Theorist (1956) and the General Problem Solver (1957). He and Simon were awarded the ACM's A.M. Turing Award in 1975 for their contributions to artificial intelligence and the psychology of human cognition.\n",
      "Link 15: AlphaFold\n",
      "Link: AlphaFold\n",
      "https://en.wikipedia.org/wiki/AlphaFold\n",
      "Summary: AlphaFold is an artificial intelligence (AI) program developed by DeepMind, a subsidiary of Alphabet, which performs predictions of protein structure. It is designed using deep learning techniques.\n",
      "AlphaFold 1 (2018) placed first in the overall rankings of the 13th Critical Assessment of Structure Prediction (CASP) in December 2018. It was particularly successful at predicting the most accurate structures for targets rated as most difficult by the competition organizers, where no existing template structures were available from proteins with partially similar sequences.\n",
      "AlphaFold 2 (2020) repeated this placement in the CASP14 competition in November 2020. It achieved a level of accuracy much higher than any other entry. It scored above 90 on CASP's global distance test (GDT) for approximately two-thirds of the proteins, a test measuring the similarity between a computationally predicted structure and the experimentally determined structure, where 100 represents a complete match. The inclusion of metagenomic data has improved the quality of the prediction of  MSAs. One of the biggest sources of the training data was the custom-built Big Fantastic Database (BFD) of 65,983,866 protein families, represented as MSAs and hidden Markov models (HMMs), covering 2,204,359,010 protein sequences from reference databases, metagenomes, and metatranscriptomes.\n",
      "AlphaFold 2's results at CASP14 were described as \"astounding\" and \"transformational\". However, some researchers noted that the accuracy was insufficient for a third of its predictions, and that it did not reveal the underlying mechanism or rules of protein folding for the protein folding problem, which remains unsolved.\n",
      "Despite this, the technical achievement was widely recognized. On 15 July 2021, the AlphaFold 2 paper was published in Nature as an advance access publication alongside open source software and a searchable database of species proteomes. As of February 2025, the paper had been cited nearly 32,000 times.\n",
      "AlphaFold 3 was announced on 8 May 2024. It can predict the structure of complexes created by proteins with DNA, RNA, various ligands, and ions. The new prediction method shows a minimum 50% improvement in accuracy for protein interactions with other molecules compared to existing methods. Moreover, for certain key categories of interactions, the prediction accuracy has effectively doubled.\n",
      "Demis Hassabis and John Jumper of Google DeepMind shared one half of the 2024 Nobel Prize in Chemistry, awarded \"for protein structure prediction,\" while the other half went to David Baker \"for computational protein design.\" Hassabis and Jumper had previously won the Breakthrough Prize in Life Sciences and the Albert Lasker Award for Basic Medical Research in 2023 for their leadership of the AlphaFold project.\n",
      "Link 16: AlphaGo\n",
      "Link: AlphaGo\n",
      "https://en.wikipedia.org/wiki/AlphaGo\n",
      "Summary: AlphaGo is a computer program that plays the board game Go. It was developed by the London-based DeepMind Technologies, an acquired subsidiary of Google. Subsequent versions of AlphaGo became increasingly powerful, including a version that competed under the name Master. After retiring from competitive play, AlphaGo Master was succeeded by an even more powerful version known as AlphaGo Zero, which was completely self-taught without learning from human games. AlphaGo Zero was then generalized into a program known as AlphaZero, which played additional games, including chess and shogi.  AlphaZero has in turn been succeeded by a program known as MuZero which learns without being taught the rules.\n",
      "AlphaGo and its successors use a Monte Carlo tree search algorithm to find its moves based on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both from human and computer play. A neural network is trained to identify the best moves and the winning percentages of these moves. This neural network improves the strength of the tree search, resulting in stronger move selection in the next iteration.\n",
      "In October 2015, in a match against Fan Hui, the original AlphaGo became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board. In March 2016, it beat Lee Sedol in a five-game match, the first time a computer Go program has beaten a 9-dan professional without handicap. Although it lost to Lee Sedol in the fourth game, Lee resigned in the final game, giving a final score of 4 games to 1 in favour of AlphaGo. In recognition of the victory, AlphaGo was awarded an honorary 9-dan by the Korea Baduk Association. The lead up and the challenge match with Lee Sedol were documented in a documentary film also titled AlphaGo, directed by Greg Kohs. The win by AlphaGo was chosen by Science as one of the Breakthrough of the Year runners-up on 22 December 2016.\n",
      "At the 2017 Future of Go Summit, the Master version of AlphaGo beat Ke Jie, the number one ranked player in the world at the time, in a three-game match, after which AlphaGo was awarded professional 9-dan by the Chinese Weiqi Association.\n",
      "After the match between AlphaGo and Ke Jie, DeepMind retired AlphaGo, while continuing AI research in other areas. The self-taught AlphaGo Zero achieved a 100–0 victory against the early competitive version of AlphaGo, and its successor AlphaZero was perceived as the world's top player in Go by the end of the 2010s.\n",
      "Link 17: AlphaZero\n",
      "Link: AlphaZero\n",
      "https://en.wikipedia.org/wiki/AlphaZero\n",
      "Summary: AlphaZero is a computer program developed by artificial intelligence research company DeepMind to master the games of chess, shogi and go. This algorithm uses an approach similar to AlphaGo Zero. \n",
      "On December 5, 2017, the DeepMind team released a preprint paper introducing AlphaZero, which would soon play three games by defeating world-champion chess engines Stockfish, Elmo, and the three-day version of AlphaGo Zero. In each case it made use of custom tensor processing units (TPUs) that the Google programs were optimized to use. AlphaZero was trained solely via self-play using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the neural networks, all in parallel, with no access to opening books or endgame tables. After four hours of training, DeepMind estimated AlphaZero was playing chess at a higher Elo rating than Stockfish 8; after nine hours of training, the algorithm defeated Stockfish 8 in a time-controlled 100-game tournament (28 wins, 0 losses, and 72 draws). The trained algorithm played on a single machine with four TPUs. \n",
      "DeepMind's paper on AlphaZero was published in the journal Science on 7 December 2018. While the actual AlphaZero program has not been released to the public, the algorithm described in the paper has been implemented in publicly available software. In 2019, DeepMind published a new paper detailing MuZero, a new algorithm able to generalize AlphaZero's work, playing both Atari and board games without knowledge of the rules or representations of the game.\n",
      "Link 18: Alphabet Inc.\n",
      "Link: Alphabet Inc.\n",
      "https://en.wikipedia.org/wiki/Alphabet_Inc.\n",
      "Summary: Alphabet Inc. is an American multinational technology conglomerate holding company headquartered in Mountain View, California. Alphabet is the world's third-largest technology company by revenue, after Amazon and Apple, and one of the world's most valuable companies. It was created through a restructuring of Google on October 2, 2015, and became the parent holding company of Google and several former Google subsidiaries. It is considered one of the Big Five American information technology companies, alongside Amazon, Apple, Meta (owner of Facebook), and Microsoft.\n",
      "The establishment of Alphabet Inc. was prompted by a desire to make the core Google business \"cleaner and more accountable\" while allowing greater autonomy to group companies that operate in businesses other than Internet services. Founders Larry Page and Sergey Brin announced their resignation from their executive posts in December 2019, with the CEO role to be filled by Sundar Pichai, who is also the CEO of Google. Page and Brin remain employees, board members, and controlling shareholders of Alphabet Inc.\n",
      "Link 19: Andrej Karpathy\n",
      "Link: Andrej Karpathy\n",
      "https://en.wikipedia.org/wiki/Andrej_Karpathy\n",
      "Summary: Andrej Karpathy (born 23 October 1986) is a Slovak-Canadian computer scientist who served as the director of artificial intelligence and Autopilot Vision at Tesla. He co-founded and formerly worked at OpenAI, where he specialized in deep learning and computer vision.\n",
      "Link 20: Andrew Ng\n",
      "Link: Andrew Ng\n",
      "https://en.wikipedia.org/wiki/Andrew_Ng\n",
      "Summary: Andrew Yan-Tak Ng (Chinese: 吳恩達; born April 18, 1976) is a British-American computer scientist and technology entrepreneur focusing on machine learning and artificial intelligence (AI). Ng was a cofounder and head of Google Brain and was the former Chief Scientist at Baidu, building the company's Artificial Intelligence Group into a team of several thousand people.\n",
      "Ng is an adjunct professor at Stanford University (formerly associate professor and Director of its Stanford AI Lab or SAIL). Ng has also worked in the field of online education, cofounding Coursera and DeepLearning.AI. He has spearheaded many efforts to \"democratize deep learning\" teaching over 8 million students through his online courses. Ng is renowned globally in computer science, recognized in Time magazine's 100 Most Influential People in 2012 and Fast Company's Most Creative People in 2014. His influence extends to being named in the Time100 AI Most Influential People in 2023.\n",
      "In 2018, he launched and currently heads the AI Fund, initially a $175-million investment fund for backing artificial intelligence startups. He has founded Landing AI, which provides AI-powered SaaS products.\n",
      "On April 11, 2024, Amazon announced the appointment of Ng to its board of directors.\n",
      "Link 21: Anthropic\n",
      "Link: Anthropic\n",
      "https://en.wikipedia.org/wiki/Anthropic\n",
      "Summary: Anthropic PBC is an American artificial intelligence (AI) startup company founded in 2021. Anthropic has developed a family of large language models (LLMs) named Claude as a competitor to OpenAI's ChatGPT and Google's Gemini. According to the company, it researches and develops AI to \"study their safety properties at the technological frontier\" and use this research to deploy safe models for the public.\n",
      "Anthropic was founded by former members of OpenAI, including siblings Daniela Amodei and Dario Amodei. In September 2023, Amazon announced an investment of up to $4 billion, followed by a $2 billion commitment from Google in the following month.\n",
      "Link 22: Approximate nearest neighbor search\n",
      "Link: Approximate nearest neighbor search\n",
      "https://en.wikipedia.org/wiki/Nearest_neighbor_search\n",
      "Summary: Nearest neighbor search (NNS), as a form of proximity search, is the optimization problem of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. \n",
      "Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set S of points in a space M and a query point q ∈ M, find the closest point in S to q. Donald Knuth in vol. 3 of The Art of Computer Programming (1973) called it the post-office problem, referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a k-NN search, where we need to find the k closest points.\n",
      "Most commonly M is a metric space and dissimilarity is expressed as a distance metric, which is symmetric and satisfies the triangle inequality. Even more common, M is taken to be the d-dimensional vector space where dissimilarity is measured using the Euclidean distance, Manhattan distance or other distance metric. However, the dissimilarity function can be arbitrary. One example is asymmetric Bregman divergence, for which the triangle inequality does not hold.\n",
      "Link 23: ArXiv (identifier)\n",
      "Link: ArXiv (identifier)\n",
      "https://en.wikipedia.org/wiki/ArXiv\n",
      "Summary: arXiv (pronounced as \"archive\"—the X represents the Greek letter chi ⟨χ⟩) is an open-access repository of electronic preprints and postprints (known as e-prints) approved for posting after moderation, but not peer reviewed. It consists of scientific papers in the fields of mathematics, physics, astronomy, electrical engineering, computer science, quantitative biology, statistics, mathematical finance, and economics, which can be accessed online. In many fields of mathematics and physics, almost all scientific papers are self-archived on the arXiv repository before publication in a peer-reviewed journal. Some publishers also grant permission for authors to archive the peer-reviewed postprint. Begun on August 14, 1991, arXiv.org passed the half-million-article milestone on October 3, 2008, had hit a million by the end of 2014 and two million by the end of 2021. As of November 2024, the submission rate is about 24,000 articles per month.\n",
      "Link 24: Ars Technica\n",
      "Link: Ars Technica\n",
      "https://en.wikipedia.org/wiki/Ars_Technica\n",
      "Summary: Ars Technica is a website covering news and opinions in technology, science, politics, and society, created by Ken Fisher and Jon Stokes in 1998. It publishes news, reviews, and guides on issues such as computer hardware and software, science, technology policy, and video games.\n",
      "Ars Technica was privately owned until May 2008, when it was sold to Condé Nast Digital, the online division of Condé Nast Publications. Condé Nast purchased the site, along with two others, for $25 million and added it to the company's Wired Digital group, which also includes Wired and, formerly, Reddit. The staff mostly works from home and has offices in Boston, Chicago, London, New York City, and San Francisco.\n",
      "The operations of Ars Technica are funded primarily by advertising, and it has offered a paid subscription service since 2001.\n",
      "Link 25: Artificial general intelligence\n",
      "Link: Artificial general intelligence\n",
      "https://en.wikipedia.org/wiki/Artificial_general_intelligence\n",
      "Summary: Artificial general intelligence (AGI) is a hypothesized type of highly autonomous artificial intelligence (AI) that would match or surpass human capabilities across most or all economically valuable cognitive work. It contrasts with narrow AI, which is limited to specific tasks. Artificial superintelligence (ASI), on the other hand, refers to AGI that greatly exceeds human cognitive capabilities. AGI is considered one of the definitions of strong AI.\n",
      "Creating AGI is a primary goal of AI research and of companies such as OpenAI, Google, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\n",
      "The timeline for achieving AGI remains a subject of ongoing debate among researchers and experts. As of 2023, some argue that it may be possible in years or decades; others maintain it might take a century or longer; a minority believe it may never be achieved; and another minority claims that it is already here. Notable AI researcher Geoffrey Hinton has expressed concerns about the rapid progress towards AGI, suggesting it could be achieved sooner than many expect.\n",
      "There is debate on the exact definition of AGI and regarding whether modern large language models (LLMs) such as GPT-4 are early forms of AGI. AGI is a common topic in science fiction and futures studies.\n",
      "Contention exists over whether AGI represents an existential risk. Many experts on AI have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\n",
      "Link 26: Artificial intelligence\n",
      "Link: Artificial intelligence\n",
      "https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "Summary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
      "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
      "Link 27: Attention (machine learning)\n",
      "Link: Attention (machine learning)\n",
      "https://en.wikipedia.org/wiki/Attention_(machine_learning)\n",
      "Summary: Attention is a machine learning method that determines the relative importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\n",
      "Unlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\n",
      "Inspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of leveraging information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.\n",
      "Link 28: Aurora (text-to-image model)\n",
      "Link: Aurora (text-to-image model)\n",
      "https://en.wikipedia.org/wiki/Grok_(chatbot)\n",
      "Summary: Grok is a generative artificial intelligence chatbot developed by xAI. Based on the large language model (LLM) of the same name, it was launched in 2023 as an initiative by Elon Musk. The chatbot is advertised as having a \"sense of humor\" and direct access to sister platform X, formerly known as Twitter.\n",
      "Link 29: AutoGPT\n",
      "Link: AutoGPT\n",
      "https://en.wikipedia.org/wiki/AutoGPT\n",
      "Summary: AutoGPT is an open-source \"AI agent\" that, given a goal in natural language, will attempt to achieve it by breaking it into sub-tasks and using the Internet and other tools in an automatic loop. It uses OpenAI's GPT-4 or GPT-3.5 APIs, and is among the first examples of an application using GPT-4 to perform autonomous tasks.\n",
      "Link 30: Autoencoder\n",
      "Link: Autoencoder\n",
      "https://en.wikipedia.org/wiki/Autoencoder\n",
      "Summary: An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction, to generate lower-dimensional embeddings for subsequent use by other machine learning algorithms.\n",
      "Variants exist which aim to make the learned representations assume useful properties. Examples are regularized autoencoders (sparse, denoising and contractive autoencoders), which are effective in learning representations for subsequent classification tasks, and variational autoencoders, which can be used as generative models. Autoencoders are applied to many problems, including facial recognition, feature detection, anomaly detection, and learning the meaning of words. In terms of data synthesis, autoencoders can also be used to randomly generate new data that is similar to the input (training) data.\n",
      "Link 31: Autoregressive model\n",
      "Link: Autoregressive model\n",
      "https://en.wikipedia.org/wiki/Autoregressive_model\n",
      "Summary: In statistics, econometrics, and signal processing, an autoregressive (AR) model is a representation of a type of random process; as such, it can be used to describe certain time-varying processes in nature, economics, behavior, etc. The autoregressive model specifies that the output variable depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term); thus the model is in the form of a stochastic difference equation (or recurrence relation) which should not be confused with a differential equation. Together with the moving-average (MA) model, it is a special case and key component of the more general autoregressive–moving-average (ARMA) and autoregressive integrated moving average (ARIMA) models of time series, which have a more complicated stochastic structure; it is also a special case of the vector autoregressive model (VAR), which consists of a system of more than one interlocking stochastic difference equation in more than one evolving random variable.\n",
      "Unlike the moving-average (MA) model, the autoregressive model is not always stationary, because it may contain a unit root.\n",
      "Large language models are called autoregressive, but they are not a classical autoregressive model in this sense because they are not linear.\n",
      "Link 32: BERT (language model)\n",
      "Link: BERT (language model)\n",
      "https://en.wikipedia.org/wiki/BERT_(language_model)\n",
      "Summary: Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. BERT dramatically improved the state-of-the-art for large language models. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \n",
      "BERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\n",
      "BERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.\n",
      "Link 33: BLOOM (language model)\n",
      "Link: BLOOM (language model)\n",
      "https://en.wikipedia.org/wiki/BLOOM_(language_model)\n",
      "Summary: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a 176-billion-parameter transformer-based autoregressive large language model (LLM). The model, as well as the code base and the data used to train it, are distributed under free licences. BLOOM was trained on approximately 366 billion (1.6TB) tokens from March to July 2022.\n",
      "BLOOM is the main outcome of the BigScience collaborative initiative, a one-year-long research workshop that took place between May 2021 and May 2022. BigScience was led by HuggingFace and involved several hundreds of researchers and engineers from France and abroad representing both the academia and the private sector. BigScience was supported by a large-scale public compute grant on the French public supercomputer Jean Zay, managed by GENCI and IDRIS (CNRS), on which it was trained.\n",
      "BLOOM's training corpus, named ROOTS, combines data extracted from the then-latest version of the web-based OSCAR corpus (38% of ROOTS) and newly collected data extracted from a manually selected and documented list of language data sources. It encompasses 46 natural languages (in amounts ranging from 30% of the whole dataset for English to 0.00002% for Chi Tumbuka) and 13 programming languages.\n",
      "\n",
      "\n",
      "== References ==\n",
      "Link 34: Backpropagation\n",
      "Link: Backpropagation\n",
      "https://en.wikipedia.org/wiki/Backpropagation\n",
      "Summary: In machine learning, backpropagation is a gradient estimation method commonly used for training a neural network to compute its parameter updates.\n",
      "It is an efficient application of the chain rule to neural networks. Backpropagation computes the gradient of a loss function with respect to the weights of the network for a single input–output example, and does so efficiently, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this can be derived through dynamic programming.\n",
      "Strictly speaking, the term backpropagation refers only to an algorithm for efficiently computing the gradient, not how the gradient is used; but the term is often used loosely to refer to the entire learning algorithm – including how the gradient is used, such as by stochastic gradient descent, or as an intermediate step in a more complicated optimizer, such as Adaptive Moment Estimation. The  local minimum convergence, exploding gradient, vanishing gradient, and weak control of learning rate are main disadvantages of these optimization algorithms. The Hessian and quasi-Hessian optimizers solve only local minimum convergence problem, and the backpropagation works longer. These problems caused researchers to develop hybrid and fractional optimization algorithms. \n",
      "Backpropagation had multiple discoveries and partial discoveries, with a tangled history and terminology. See the history section for details. Some other names for the technique include \"reverse mode of automatic differentiation\" or \"reverse accumulation\".\n",
      "Link 35: Baichuan\n",
      "Link: Baichuan\n",
      "https://en.wikipedia.org/wiki/Baichuan\n",
      "Summary: Baichuan AI (Baichuan; Chinese: 百川智能; pinyin: Bǎichuān Zhìnéng) is an artificial intelligence (AI) company based in Beijing, China. As of 2024, it has been dubbed one of China's \"AI Tiger\" companies by investors.\n",
      "Link 36: Baidu\n",
      "Link: Baidu\n",
      "https://en.wikipedia.org/wiki/Baidu\n",
      "Summary: Baidu, Inc. ( BY-doo; Chinese: 百度; pinyin: Bǎidù; lit. 'hundred times') is a Chinese multinational technology company specializing in Internet services and artificial intelligence. It holds a dominant position in China's search engine market (via Baidu Search), and provides a wide variety of other internet services such as Baidu App (Baidu's flagship app for search and newsfeed), Baidu Baike (an online user created Wikipedia-like encyclopedia), iQIYI (a video streaming service), and Baidu Tieba (a keyword-based discussion forum similar to Reddit).\n",
      "Besides its core internet search business, Baidu has diversified into several high-growth areas. The company is a leading player in  autonomous driving (Baidu Apollo), and smart consumer electronics (Xiaodu). With over a decade of investment in artificial intelligence, Baidu is one of the few tech companies globally to offer a full-stack AI stack, including software, chips, cloud infrastructure, foundation models, and applications.\n",
      "The holding company of the group is incorporated in the Cayman Islands. Baidu was incorporated in January 2000 by Robin Li and Eric Xu. Baidu has origins in RankDex, an earlier search engine developed by Robin Li in 1996, before he founded Baidu in 2000. The company is headquartered in Beijing's Haidian District.\n",
      "In December 2007, Baidu became the first Chinese company to be included in the NASDAQ-100 index. As of May 2018, Baidu's market cap rose to US$99 billion. In October 2018, Baidu became the first Chinese firm to join the United States–based computer ethics consortium Partnership on AI. During the 2020s, Baidu has increasingly focused on generative AI related products. \n",
      "The Chinese government views Baidu as one of its national champion corporations.: 156–157\n",
      "Link 37: Batch normalization\n",
      "Link: Batch normalization\n",
      "https://en.wikipedia.org/wiki/Batch_normalization\n",
      "Summary: Batch normalization (also known as batch norm) is a technique used to make training of artificial neural networks faster and more stable by adjusting the inputs to each layer—re-centering them around zero and re-scaling them to a standard size. It was introduced by Sergey Ioffe and Christian Szegedy in 2015.\n",
      "Experts still debate why batch normalization works so well. It was initially thought to tackle internal covariate shift, a problem where parameter initialization and changes in the distribution of the inputs of each layer affect the learning rate of the network. However, newer research suggests it doesn’t fix this shift but instead smooths the objective function—a mathematical guide the network follows to improve—enhancing performance. In very deep networks, batch normalization can initially cause a severe gradient explosion—where updates to the network grow uncontrollably large—but this is managed with shortcuts called skip connections in residual networks. Another theory is that batch normalization adjusts data by handling its size and path separately, speeding up training.\n",
      "Link 38: Bernard Widrow\n",
      "Link: Bernard Widrow\n",
      "https://en.wikipedia.org/wiki/Bernard_Widrow\n",
      "Summary: Bernard Widrow (born December 24, 1929) is a U.S. professor of electrical engineering at Stanford University.  He is the co-inventor of the Widrow–Hoff least mean squares filter (LMS) adaptive algorithm with his then doctoral student Ted Hoff.  The LMS algorithm led to the ADALINE and MADALINE artificial neural networks and to the backpropagation technique. He made other fundamental contributions to the development of  signal processing in the fields of geophysics, adaptive antennas, and adaptive filtering. A summary of his work is.\n",
      "He is the namesake of \"Uncle Bernie's Rule\": the training sample size should be 10 times the number of weights in a network.\n",
      "Link 39: Bias–variance tradeoff\n",
      "Link: Bias–variance tradeoff\n",
      "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\n",
      "Summary: In statistics and machine learning, the bias–variance tradeoff describes the relationship between a model's complexity, the accuracy of its predictions, and how well it can make predictions on previously unseen data that were not used to train the model. In general, as we increase the number of tunable parameters in a model, it becomes more flexible, and can better fit a training data set. It is said to have lower error, or bias. However, for more flexible models, there will tend to be greater variance to the model fit each time we take a set of samples to create a new training data set. It is said that there is greater variance in the model's estimated parameters.\n",
      "The bias–variance dilemma or bias–variance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:\n",
      "\n",
      "The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
      "The variance is an error from sensitivity to small fluctuations in the training set. High variance may result from an algorithm modeling the random noise in the training data (overfitting).\n",
      "The bias–variance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself.\n",
      "Link 40: ChatGPT\n",
      "Link: ChatGPT\n",
      "https://en.wikipedia.org/wiki/ChatGPT\n",
      "Summary: ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is currently based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\n",
      "ChatGPT is built on OpenAI's proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT \"Plus\", \"Pro\", \"Team\", and \"Enterprise\" subscriptions provide additional features such as DALL-E 3 image generation, more capable AI models, and an increased usage limit.\n",
      "By January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months. ChatGPT's release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI's GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of April 2025, ChatGPT's website is among the 10 most-visited websites globally.\n",
      "Link 41: Chatbot\n",
      "Link: Chatbot\n",
      "https://en.wikipedia.org/wiki/Chatbot\n",
      "Summary: A chatbot (originally chatterbot) is a software application or web interface designed to have textual or spoken conversations. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\n",
      "Although chatbots have existed since the late 1960s, the field gained widespread attention in the early 2020s due to the popularity of OpenAI's ChatGPT, followed by alternatives such as Microsoft's Copilot, DeepSeek and Google's Gemini. Such examples reflect the recent practice of basing such products upon broad foundational large language models, such as GPT-4 or the Gemini language model, that get fine-tuned so as to target specific tasks or applications (i.e., simulating human conversation, in the case of chatbots). Chatbots can also be designed or customized to further target even more specific situations and/or particular subject-matter domains.\n",
      "A major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants. Companies spanning a wide range of industries have begun using the latest generative artificial intelligence technologies to power more advanced developments in such areas.\n",
      "Link 42: Chinchilla (language model)\n",
      "Link: Chinchilla (language model)\n",
      "https://en.wikipedia.org/wiki/Chinchilla_(language_model)\n",
      "Summary: Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.\n",
      "Link 43: Claude (language model)\n",
      "Link: Claude (language model)\n",
      "https://en.wikipedia.org/wiki/Claude_(language_model)\n",
      "Summary: Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\n",
      "The Claude 3 family, released in March 2024, consists of three models: Haiku, optimized for speed; Sonnet, which balances capability and performance; and Opus, designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.\n",
      "Link 44: Claude Shannon\n",
      "Link: Claude Shannon\n",
      "https://en.wikipedia.org/wiki/Claude_Shannon\n",
      "Summary: Claude Elwood Shannon (April 30, 1916 – February 24, 2001) was an American mathematician, electrical engineer, computer scientist, cryptographer and inventor, known as the \"father of information theory\" and credited with laying the foundations of the Information Age. Shannon was the first to describe the use of Boolean algebra that are essential to all digital electronic circuits, and was one of the founding fathers of artificial intelligence. Roboticist Rodney Brooks declared that Shannon was the 20th century engineer who contributed the most to 21st century technologies, and mathematician Solomon W. Golomb described his intellectual achievement as \"one of the greatest of the twentieth century\".\n",
      "At the University of Michigan, Shannon dual degreed, graduating with a Bachelor of Science in both electrical engineering and mathematics in 1936. A 21-year-old master's degree student in electrical engineering at MIT, his thesis \"A Symbolic Analysis of Relay and Switching Circuits\" demonstrated that electrical applications of Boolean algebra could construct any logical numerical relationship, thereby establishing the theory behind digital computing and digital circuits. The thesis has been claimed to be the most important master's thesis of all time, having been called the \"birth certificate of the digital revolution\", and winning the 1939 Alfred Noble Prize. He graduated from MIT in 1940 with a PhD in mathematics; his thesis focusing on genetics contained important results, while initially going unpublished.\n",
      "Shannon contributed to the field of cryptanalysis for national defense of the United States during World War II, including his fundamental work on codebreaking and secure telecommunications, writing a paper which is considered one of the foundational pieces of modern cryptography, with his work described as \"a turning point, and marked the closure of classical cryptography and the beginning of modern cryptography\". The work of Shannon was foundational for symmetric-key cryptography, including the work of Horst Feistel, the Data Encryption Standard (DES), and the Advanced Encryption Standard (AES). As a result, Shannon has been called the \"founding father of modern cryptography\".\n",
      "His 1948 paper \"A Mathematical Theory of Communication\" laid the foundations for the field of information theory, referred to as a \"blueprint for the digital era\" by electrical engineer Robert G. Gallager and \"the Magna Carta of the Information Age\" by Scientific American. Golomb compared Shannon's influence on the digital age to that which \"the inventor of the alphabet has had on literature\". Advancements across multiple scientific disciplines utilized Shannon's theory—including the invention of the compact disc, the development of the Internet, the commercialization of mobile telephony, and the understanding of black holes. He also formally introduced the term \"bit\", and was a co-inventor of both pulse-code modulation and the first wearable computer.\n",
      "Shannon made numerous contributions to the field of artificial intelligence, including co-organizing the 1956 Dartmouth workshop considered to be the discipline's founding event, and papers on the programming of chess computers. His Theseus machine was the first electrical device to learn by trial and error, being one of the first examples of artificial intelligence.\n",
      "Link 45: Cliff Shaw\n",
      "Link: Cliff Shaw\n",
      "https://en.wikipedia.org/wiki/Cliff_Shaw\n",
      "Summary: John Clifford Shaw (February 23, 1922 – February 9, 1991) was a systems programmer at the RAND Corporation. He is a coauthor of the first artificial intelligence program, the Logic Theorist, and was one of the developers of General Problem Solver (universal problem solver machine) and Information Processing Language (a programming language of the 1950s). Information Processing Language is considered the true \"father\" of the JOSS language. One of the most significant events that occurred in the programming was the development of the concept of list processing by Allen Newell, Herbert A. Simon and Cliff Shaw during the development of the language IPL-V. He invented the linked list, which remains fundamental in many strands of modern computing technology.\n",
      "Link 46: Cluster analysis\n",
      "Link: Cluster analysis\n",
      "https://en.wikipedia.org/wiki/Cluster_analysis\n",
      "Summary: Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some specific sense defined by the analyst) to each other than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\n",
      "Cluster analysis refers to a family of algorithms and tasks rather than one specific algorithm. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. Clustering can therefore be formulated as a multi-objective optimization problem. The appropriate clustering algorithm and parameter settings (including parameters such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. It is often necessary to modify data preprocessing and model parameters until the result achieves the desired properties.\n",
      "Besides the term clustering, there are a number of terms with similar meanings, including automatic classification, numerical taxonomy, botryology (from Greek: βότρυς 'grape'), typological analysis, and community detection. The subtle differences are often in the use of the results: while in data mining, the resulting groups are the matter of interest, in automatic classification the resulting discriminative power is of interest.\n",
      "Cluster analysis originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.\n",
      "Link 47: Conjugate gradient method\n",
      "Link: Conjugate gradient method\n",
      "https://en.wikipedia.org/wiki/Conjugate_gradient_method\n",
      "Summary: In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-semidefinite. The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition. Large sparse systems often arise when numerically solving partial differential equations or optimization problems.\n",
      "The conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization. It is commonly attributed to Magnus Hestenes and Eduard Stiefel, who programmed it on the Z4, and extensively researched it.\n",
      "The biconjugate gradient method provides a generalization to non-symmetric matrices. Various nonlinear conjugate gradient methods seek minima of nonlinear optimization problems.\n",
      "Link 48: Convolution\n",
      "Link: Convolution\n",
      "https://en.wikipedia.org/wiki/Convolution\n",
      "Summary: In mathematics (in particular, functional analysis), convolution is a mathematical operation on two functions (\n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f}\n",
      "  \n",
      " and \n",
      "  \n",
      "    \n",
      "      \n",
      "        g\n",
      "      \n",
      "    \n",
      "    {\\displaystyle g}\n",
      "  \n",
      ") that produces a third function (\n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        ∗\n",
      "        g\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f*g}\n",
      "  \n",
      "), as the integral of the product of the two functions after one is reflected about the y-axis and shifted.  The term convolution refers to both the resulting function and to the process of computing it. The integral is evaluated for all values of shift, producing the convolution function. The choice of which function is reflected and shifted before the integral does not change the integral result (see commutativity). Graphically, it expresses how the 'shape' of one function is modified by the other.\n",
      "Some features of convolution are similar to cross-correlation: for real-valued functions, of a continuous or discrete variable, convolution (\n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        ∗\n",
      "        g\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f*g}\n",
      "  \n",
      ") differs from cross-correlation (\n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        ⋆\n",
      "        g\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f\\star g}\n",
      "  \n",
      ") only in that either \n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f(x)}\n",
      "  \n",
      " or \n",
      "  \n",
      "    \n",
      "      \n",
      "        g\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle g(x)}\n",
      "  \n",
      " is reflected about the y-axis in convolution; thus it is a cross-correlation of \n",
      "  \n",
      "    \n",
      "      \n",
      "        g\n",
      "        (\n",
      "        −\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle g(-x)}\n",
      "  \n",
      " and \n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f(x)}\n",
      "  \n",
      ", or \n",
      "  \n",
      "    \n",
      "      \n",
      "        f\n",
      "        (\n",
      "        −\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle f(-x)}\n",
      "  \n",
      " and \n",
      "  \n",
      "    \n",
      "      \n",
      "        g\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle g(x)}\n",
      "  \n",
      ". For complex-valued functions, the cross-correlation operator is the adjoint of the convolution operator.\n",
      "Convolution has applications that include probability, statistics, acoustics, spectroscopy, signal processing and image processing, geophysics, engineering, physics, computer vision and differential equations.\n",
      "The convolution can be defined for functions on Euclidean space and other groups (as algebraic structures). For example, periodic functions, such as the discrete-time Fourier transform, can be defined on a circle and convolved by periodic convolution. (See row 18 at DTFT § Properties.) A discrete convolution can be defined for functions on the set of integers.\n",
      "Generalizations of convolution have applications in the field of numerical analysis and numerical linear algebra, and in the design and implementation of finite impulse response filters in signal processing.\n",
      "Computing the inverse of the convolution operation is known as deconvolution.\n",
      "Link 49: Convolutional neural network\n",
      "Link: Convolutional neural network\n",
      "https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
      "Summary: A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced—in some cases—by newer deep learning architectures such as the transformer.\n",
      "Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\n",
      "Some applications of CNNs include: \n",
      "\n",
      "image and video recognition,\n",
      "recommender systems,\n",
      "image classification,\n",
      "image segmentation,\n",
      "medical image analysis,\n",
      "natural language processing,\n",
      "brain–computer interfaces, and\n",
      "financial time series.\n",
      "CNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.\n",
      "Feedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.) Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set.\n",
      "Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field. The receptive fields of different neurons partially overlap such that they cover the entire visual field.\n",
      "CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This simplifies and automates the process, enhancing efficiency and scalability overcoming human-intervention bottlenecks.\n",
      "Link 50: DALL-E\n",
      "Link: DALL-E\n",
      "https://en.wikipedia.org/wiki/DALL-E\n",
      "Summary: DALL-E, DALL-E 2, and DALL-E 3 (stylised DALL·E) are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions known as prompts.\n",
      "The first version of DALL-E was announced in January 2021. In the following year, its successor DALL-E 2 was released. DALL-E 3 was released natively into ChatGPT for ChatGPT Plus and ChatGPT Enterprise customers in October 2023, with availability via OpenAI's API and \"Labs\" platform provided in early November. Microsoft implemented the model in Bing's Image Creator tool and plans to implement it into their Designer app.\n",
      "Link 51: DBRX\n",
      "Link: DBRX\n",
      "https://en.wikipedia.org/wiki/DBRX\n",
      "Summary: DBRX is an open-sourced large language model (LLM) developed by Mosaic ML team at Databricks, released on March 27, 2024. It is a mixture-of-experts transformer model, with 132 billion parameters in total. 36 billion parameters (4 out of 16 experts) are active for each token. The released model comes in either a base foundation model version or an instruction-tuned variant.\n",
      "At the time of its release, DBRX outperformed other prominent open-source models such as Meta's LLaMA 2, Mistral AI's Mixtral, and xAI's Grok, in several benchmarks ranging from language understanding, programming ability and mathematics.\n",
      "It was trained for 2.5 months on 3,072 Nvidia H100s connected by 3.2 terabytes per second bandwidth (InfiniBand), for a training cost of $10m USD.\n",
      "\n",
      "\n",
      "== References ==\n",
      "Link 52: Data augmentation\n",
      "Link: Data augmentation\n",
      "https://en.wikipedia.org/wiki/Data_augmentation\n",
      "Summary: Data augmentation is a statistical technique which allows maximum likelihood estimation from incomplete data. Data augmentation has important applications in Bayesian analysis, and the technique is widely used in machine learning to reduce overfitting when training machine learning models, achieved by training models on several slightly-modified copies of existing data.\n",
      "Link 53: David Silver (computer scientist)\n",
      "Link: David Silver (computer scientist)\n",
      "https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)\n",
      "Summary: David Silver (born 1976) is a principal research scientist at Google DeepMind and a professor at University College London. He has led research on reinforcement learning with AlphaGo, AlphaZero and co-lead on AlphaStar.\n",
      "Link 54: DeepSeek\n",
      "Link: DeepSeek\n",
      "https://en.wikipedia.org/wiki/DeepSeek\n",
      "Summary: Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd., doing business as DeepSeek, is a Chinese artificial intelligence company that develops large language models (LLMs). Based in Hangzhou, Zhejiang, it is owned and funded by the Chinese hedge fund High-Flyer. DeepSeek was founded in July 2023 by Liang Wenfeng, the co-founder of High-Flyer, who also serves as the CEO for both companies. The company launched an eponymous chatbot alongside its DeepSeek-R1 model in January 2025.\n",
      "Released under the MIT License, DeepSeek-R1 provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4 and o1. Its training cost is reported to be significantly lower than other LLMs. The company claims that it trained its V3 model for US$6 million—far less than the US$100 million cost for OpenAI's GPT-4 in 2023—and using approximately one-tenth the computing power consumed by Meta's comparable model, Llama 3.1. DeepSeek's success against larger and more established rivals has been described as \"upending AI\".\n",
      "DeepSeek's models are described as \"open weight,\" meaning the exact parameters are openly shared, although certain usage conditions differ from typical open-source software. The company reportedly recruits AI researchers from top Chinese universities and also hires from outside traditional computer science fields to broaden its models' knowledge and capabilities.\n",
      "DeepSeek significantly reduced training expenses for their R1 model by incorporating techniques such as mixture of experts (MoE) layers. The company also trained its models during ongoing trade restrictions on AI chip exports to China, using weaker AI chips intended for export and employing fewer units overall. Observers say this breakthrough sent \"shock waves\" through the industry, threatening established AI hardware leaders such as Nvidia; Nvidia's share price dropped sharply, losing US$600 billion in market value, the largest single-company decline in U.S. stock market history.\n",
      "Link 55: DeepSeek (chatbot)\n",
      "Link: DeepSeek (chatbot)\n",
      "https://en.wikipedia.org/wiki/DeepSeek_(chatbot)\n",
      "Summary: DeepSeek is a chatbot created by the Chinese artificial intelligence company DeepSeek.\n",
      "Released on 10 January 2025, DeepSeek-R1 surpassed ChatGPT as the most downloaded freeware app on the iOS App Store in the United States by 27 January. DeepSeek's success against larger and more established rivals has been described as \"upending AI\" and initiating \"a global AI space race\". DeepSeek's compliance with Chinese government censorship policies and its data collection practices have also raised concerns over privacy and information control in the model, prompting regulatory scrutiny in multiple countries.\n",
      "Link 56: Deep learning\n",
      "Link: Deep learning\n",
      "https://en.wikipedia.org/wiki/Deep_learning\n",
      "Summary: Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n",
      "Link 57: Deep learning speech synthesis\n",
      "Link: Deep learning speech synthesis\n",
      "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis\n",
      "Summary: Deep learning speech synthesis  refers to the application of deep learning models to generate natural-sounding human speech from written text (text-to-speech) or spectrum (vocoder). Deep neural networks are trained using large amounts of recorded speech and, in the case of a text-to-speech system, the associated labels and/or input text.\n",
      "Link 58: Demis Hassabis\n",
      "Link: Demis Hassabis\n",
      "https://en.wikipedia.org/wiki/Demis_Hassabis\n",
      "Summary: Sir Demis Hassabis (born 27 July 1976) is a British artificial intelligence (AI) researcher, and entrepreneur. He is the chief executive officer and co-founder of Google DeepMind, and Isomorphic Labs, and a UK Government AI Adviser. In 2024, Hassabis and John M. Jumper were jointly awarded the Nobel Prize in Chemistry for their AI research contributions for protein structure prediction.\n",
      "Hassabis is a Fellow of the Royal Society, and has won many prestigious awards for his research work including the Breakthrough Prize, the Canada Gairdner International Award, and the Lasker Award. In 2017 he was appointed a CBE and listed in the Time 100 most influential people list. In 2024 he was knighted for services to AI.\n",
      "Link 59: Dense matrix\n",
      "Link: Dense matrix\n",
      "https://en.wikipedia.org/wiki/Sparse_matrix\n",
      "Summary: In numerical analysis and scientific computing, a sparse matrix or sparse array is a matrix in which most of the elements are zero. There is no strict definition regarding the proportion of zero-value elements for a matrix to qualify as sparse but a common criterion is that the number of non-zero elements is roughly equal to the number of rows or columns. By contrast, if most of the elements are non-zero, the matrix is considered dense. The number of zero-valued elements divided by the total number of elements (e.g., m × n for an m × n matrix) is sometimes referred to as the sparsity of the matrix.\n",
      "Conceptually, sparsity corresponds to systems with few pairwise interactions. For example, consider a line of balls connected by springs from one to the next: this is a sparse system, as only adjacent balls are coupled. By contrast, if the same line of balls were to have springs connecting each ball to all other balls, the system would correspond to a dense matrix. The concept of sparsity is useful in combinatorics and application areas such as network theory and numerical analysis, which typically have a low density of significant data or connections. Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.\n",
      "When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix. Specialized computers have been made for sparse matrices, as they are common in the machine learning field. Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros. Sparse data is by nature more easily compressed and thus requires significantly less storage. Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.\n",
      "Link 60: Differentiable neural computer\n",
      "Link: Differentiable neural computer\n",
      "https://en.wikipedia.org/wiki/Differentiable_neural_computer\n",
      "Summary: In artificial intelligence, a differentiable neural computer (DNC) is a memory augmented neural network architecture (MANN), which is typically (but not by definition) recurrent in its implementation. The model was published in 2016 by Alex Graves et al. of DeepMind.\n",
      "Link 61: Diffusion process\n",
      "Link: Diffusion process\n",
      "https://en.wikipedia.org/wiki/Diffusion_process\n",
      "Summary: In probability theory and statistics, diffusion processes are a class of continuous-time Markov process with almost surely continuous sample paths. Diffusion process is stochastic in nature and hence is used to model many real-life stochastic systems. Brownian motion, reflected Brownian motion and Ornstein–Uhlenbeck processes are examples of diffusion processes. It is used heavily in statistical physics, statistical analysis, information theory, data science, neural networks, finance and marketing.\n",
      "A sample path of a diffusion process models the trajectory of a particle embedded in a flowing fluid and subjected to random displacements due to collisions with other particles, which is called Brownian motion.  The position of the particle is then random; its probability density function as a function of space and time is  governed by a convection–diffusion equation.\n",
      "Link 62: Document retrieval\n",
      "Link: Document retrieval\n",
      "https://en.wikipedia.org/wiki/Document_retrieval\n",
      "Summary: Document retrieval is defined as the matching of some stated user query against a set of free-text records. These records could be any type of mainly unstructured text, such as newspaper articles, real estate records or paragraphs in a manual. User queries can range from multi-sentence full descriptions of an information need to a few words.\n",
      "Document retrieval is sometimes referred to as, or as a branch of, text retrieval. Text retrieval is a branch of information retrieval where the information is stored primarily in the form of text. Text databases became decentralized thanks to the personal computer. Text retrieval is a critical area of study today, since it is the fundamental basis of all internet search engines.\n",
      "Link 63: Doi (identifier)\n",
      "Link: Doi (identifier)\n",
      "https://en.wikipedia.org/wiki/Digital_object_identifier\n",
      "Summary: A digital object identifier (DOI) is a persistent identifier or handle used to uniquely identify various objects, standardized by the International Organization for Standardization (ISO). DOIs are an implementation of the Handle System; they also fit within the URI system (Uniform Resource Identifier). They are widely used to identify academic, professional, and government information, such as journal articles, research reports, data sets, and official publications.\n",
      "A DOI aims to resolve to its target, the information object to which the DOI refers. This is achieved by binding the DOI to metadata about the object, such as a URL where the object is located. Thus, by being actionable and interoperable, a DOI differs from ISBNs or ISRCs which are identifiers only. The DOI system uses the indecs Content Model to represent metadata.\n",
      "The DOI for a document remains fixed over the lifetime of the document, whereas its location and other metadata may change. Referring to an online document by its DOI should provide a more stable link than directly using its URL. But if its URL changes, the publisher must update the metadata for the DOI to maintain the link to the URL. It is the publisher's responsibility to update the DOI database. If they fail to do so, the DOI resolves to a dead link, leaving the DOI useless.\n",
      "The developer and administrator of the DOI system is the International DOI Foundation (IDF), which introduced it in 2000. Organizations that meet the contractual obligations of the DOI system and are willing to pay to become a member of the system can assign DOIs. The DOI system is implemented through a federation of registration agencies coordinated by the IDF. The cumulative number of DOIs has increased exponentially over time, from 50 million registrations in 2011 to 391 million in 2025. The rate of registering organizations (\"members\") has also increased over time from 4,000 in 2011 to 9,500 in 2013, but the federated nature of the system means it's not immediately clear how many members there are in total today. Fake registries have even appeared.\n",
      "Link 64: Dot product\n",
      "Link: Dot product\n",
      "https://en.wikipedia.org/wiki/Dot_product\n",
      "Summary: In mathematics, the dot product or scalar product is an algebraic operation that takes two equal-length sequences of numbers (usually coordinate vectors), and returns a single number. In Euclidean geometry, the dot product of the Cartesian coordinates of two vectors is widely used. It is often called the inner product (or rarely the projection product) of Euclidean space, even though it is not the only inner product that can be defined on Euclidean space (see Inner product space for more). It should not be confused with the cross product.\n",
      "Algebraically, the dot product is the sum of the products of the corresponding entries of the two sequences of numbers. Geometrically, it is the product of the Euclidean magnitudes of the two vectors and the cosine of the angle between them. These definitions are equivalent when using Cartesian coordinates. In modern geometry, Euclidean spaces are often defined by using vector spaces. In this case, the dot product is used for defining lengths (the length of a vector is the square root of the dot product of the vector by itself) and angles (the cosine of the angle between two vectors is the quotient of their dot product by the product of their lengths).\n",
      "The name \"dot product\" is derived from the dot operator \" ⋅ \" that is often used to designate this operation; the alternative name \"scalar product\" emphasizes that the result is a scalar, rather than a vector (as with the vector product in three-dimensional space).\n",
      "Link 65: Double descent\n",
      "Link: Double descent\n",
      "https://en.wikipedia.org/wiki/Double_descent\n",
      "Summary: Double descent in statistics and machine learning is the phenomenon where a model with a small number of parameters and a model with an extremely large number of parameters both have a small training error, but a model whose number of parameters is about the same as the number of data points used to train the model will have a much greater test error than one with a much larger number of parameters. This phenomenon has been considered surprising, as it contradicts assumptions about overfitting in classical machine learning.\n",
      "Link 66: Dream Machine (text-to-video model)\n",
      "Link: Dream Machine (text-to-video model)\n",
      "https://en.wikipedia.org/wiki/Dream_Machine_(text-to-video_model)\n",
      "Summary: Dream Machine is a text-to-video model created by Luma Labs and launched in June 2024. It generates video output based on user prompts or still images. Dream Machine has been noted for its ability to realistically capture motion, while some critics have remarked upon the lack of transparency about its training data. Upon the program's release, users on social media created moving versions of various Internet memes.\n",
      "Link 67: Echo state network\n",
      "Link: Echo state network\n",
      "https://en.wikipedia.org/wiki/Echo_state_network\n",
      "Summary: An echo state network (ESN) is a type of reservoir computer that uses a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned. The weights of output neurons can be learned so that the network can produce or reproduce specific temporal patterns. The main interest of this network is that although its behavior is non-linear, the only weights that are modified during training are for the synapses that connect the hidden neurons to output neurons. Thus, the error function is quadratic with respect to the parameter vector and can be differentiated easily to a linear system.\n",
      "Alternatively, one may consider a nonparametric Bayesian formulation of the output layer, under which: (i) a prior distribution is imposed over the output weights; and (ii) the output weights are marginalized out in the context of prediction generation, given the training data. This idea has been demonstrated in by using Gaussian priors, whereby a Gaussian process model with ESN-driven kernel function is obtained. Such a solution was shown to outperform ESNs with trainable (finite) sets of weights in several benchmarks.\n",
      "Some publicly available efficient implementations of ESNs are aureservoir (a C++ library for various kinds with python/numpy bindings), MATLAB, ReservoirComputing.jl (a Julia-based implementation of various types) and pyESN (for simple ESNs in Python).\n",
      "Link 68: ElevenLabs\n",
      "Link: ElevenLabs\n",
      "https://en.wikipedia.org/wiki/ElevenLabs\n",
      "Summary: ElevenLabs is a software company that specializes in developing natural-sounding speech synthesis software using deep learning.\n",
      "Link 69: Endel (app)\n",
      "Link: Endel (app)\n",
      "https://en.wikipedia.org/wiki/Endel_(app)\n",
      "Summary: Endel is a paid generative music app that creates personalized sound environments (called soundscapes) to match user activities. The app provides preset modes for relaxation, focus, sleep, and moving, and reacts to time of the day, weather, heart rate, and location to create unique compositions.\n",
      "Endel is available on iOS and Android devices, on Apple TV, as a standalone Apple Watch app, and an Amazon Alexa Skill.\n",
      "Link 70: Ernie Bot\n",
      "Link: Ernie Bot\n",
      "https://en.wikipedia.org/wiki/Ernie_Bot\n",
      "Summary: Ernie Bot (Chinese: 文心一言, Pinyin: wénxīn yīyán), full name Enhanced Representation through Knowledge Integration, is an AI chatbot service product of Baidu, released in 2023. It is built on a large language model called ERNIE, which has been in development since 2019.\n",
      "Version, ERNIE 4.0, was announced on October 17, 2023.\n",
      "Version 4.5 and reasoning model ERNIE X1 were released free of charge on March 16, 2025.\n",
      "Link 71: Facial recognition system\n",
      "Link: Facial recognition system\n",
      "https://en.wikipedia.org/wiki/Facial_recognition_system\n",
      "Summary: A facial recognition system is a technology potentially capable of matching a human face from a digital image or a video frame against a database of faces. Such a system is typically employed to authenticate users through ID verification services, and works by pinpointing and measuring facial features from a given image.\n",
      "Development began on similar systems in the 1960s, beginning as a form of computer application. Since their inception, facial recognition systems have seen wider uses in recent times on smartphones and in other forms of technology, such as robotics. Because computerized facial recognition involves the measurement of a human's physiological characteristics, facial recognition systems are categorized as biometrics. Although the accuracy of facial recognition systems as a biometric technology is lower than iris recognition, fingerprint image acquisition, palm recognition or voice recognition, it is widely adopted due to its contactless process. Facial recognition systems have been deployed in advanced human–computer interaction, video surveillance, law enforcement, passenger screening, decisions on employment and housing and automatic indexing of images.\n",
      "Facial recognition systems are employed throughout the world today by governments and private companies. Their effectiveness varies, and some systems have previously been scrapped because of their ineffectiveness. The use of facial recognition systems has also raised controversy, with claims that the systems violate citizens' privacy, commonly make incorrect identifications, encourage gender norms and racial profiling, and do not protect important biometric data. The appearance of synthetic media such as deepfakes has also raised concerns about its security. These claims have led to the ban of facial recognition systems in several cities in the United States. Growing societal concerns led social networking company Meta Platforms to shut down its Facebook facial recognition system in 2021, deleting the face scan data of more than one billion users. The change represented one of the largest shifts in facial recognition usage in the technology's history. IBM also stopped offering facial recognition technology due to similar concerns.\n",
      "Link 72: Fei-Fei Li\n",
      "Link: Fei-Fei Li\n",
      "https://en.wikipedia.org/wiki/Fei-Fei_Li\n",
      "Summary: Fei-Fei Li (Chinese: 李飞飞; pinyin: Lǐ Fēifēi; born in Beijing, China, July 3, 1976) is a Chinese-American computer scientist known for her pioneering work in artificial intelligence (AI), particularly in computer vision. She establishing ImageNet, the dataset that enabled rapid advances in computer vision in the 2010s. She is the Sequoia Capital professor of computer science at Stanford University and former board director at Twitter. Li is a co-director of the Stanford Institute for Human-Centered Artificial Intelligence and a co-director of the Stanford Vision and Learning Lab. She also served as Chief Scientist of AI/ML at Google Cloud and is the director of the Stanford Artificial Intelligence Laboratory from 2013 to 2018.\n",
      "In 2017, she co-founded AI4ALL, a nonprofit organization working to increase diversity and inclusion in the field of artificial intelligence. Her research expertise includes artificial intelligence, machine learning, deep learning, computer vision and cognitive neuroscience.\n",
      "Li was named in the Time 100 AI Most Influential People list in 2023 and received the Intel Lifetime Achievements Innovation Award in the same year for her contributions to artificial intelligence. She was elected as a member of the National Academy of Engineering and the National Academy of Medicine in 2020, and the American Academy of Arts and Sciences in 2021.\n",
      "On August 3, 2023, it was announced that Li was appointed to the United Nations Scientific Advisory Board, established by Secretary-General Antonio Guterres. In 2024, Li made it to the Gold House’s most impactful Asian A100 list. In 2024, Fei-Fei Li, raised $230 million for a startup called World Labs, that she and three colleagues founded to develop a \"spatial intelligence\" AI technology that can understand how the three-dimensional physical world works.\n",
      "Link 73: Flux (text-to-image model)\n",
      "Link: Flux (text-to-image model)\n",
      "https://en.wikipedia.org/wiki/Flux_(text-to-image_model)\n",
      "Summary: Flux (also known as FLUX.1) is a text-to-image model developed by Black Forest Labs, based in Freiburg im Breisgau, Germany. Black Forest Labs were founded by former employees of Stability AI. As with other text-to-image models, Flux generates images from natural language descriptions, called prompts.\n",
      "Link 74: Frank Rosenblatt\n",
      "Link: Frank Rosenblatt\n",
      "https://en.wikipedia.org/wiki/Frank_Rosenblatt\n",
      "Summary: Frank Rosenblatt (July 11, 1928 – July 11, 1971) was an American psychologist notable in the field of artificial intelligence. He is sometimes called the father of deep learning for his pioneering work on artificial neural networks.\n",
      "Link 75: GPT-1\n",
      "Link: GPT-1\n",
      "https://en.wikipedia.org/wiki/GPT-1\n",
      "Summary: Generative Pre-trained Transformer 1 (GPT-1) was the first of OpenAI's large language models following Google's invention of the transformer architecture in 2017. In June 2018, OpenAI released a paper entitled \"Improving Language Understanding by Generative Pre-Training\", in which they introduced that initial model along with the general concept of a generative pre-trained transformer.\n",
      "Up to that point, the best-performing neural NLP models primarily employed supervised learning from large amounts of manually labeled data. This reliance on supervised learning limited their use of datasets that were not well-annotated, in addition to making it prohibitively expensive and time-consuming to train extremely large models; many languages (such as Swahili or Haitian Creole) are difficult to translate and interpret using such models due to a lack of available text for corpus-building. In contrast, a GPT's \"semi-supervised\" approach involved two stages: an unsupervised generative \"pre-training\" stage in which a language modeling objective was used to set initial parameters, and a supervised discriminative \"fine-tuning\" stage in which these parameters were adapted to a target task.\n",
      "The use of a transformer architecture, as opposed to previous techniques involving attention-augmented RNNs, provided GPT models with a more structured memory than could be achieved through recurrent mechanisms; this resulted in \"robust transfer performance across diverse tasks\".\n",
      "Link 76: GPT-2\n",
      "Link: GPT-2\n",
      "https://en.wikipedia.org/wiki/GPT-2\n",
      "Summary: Generative Pre-trained Transformer 2 (GPT-2) is a large language model by OpenAI and the second in their foundational series of GPT models. GPT-2 was pre-trained on a dataset of 8 million web pages. It was partially released in February 2019, followed by full release of the 1.5-billion-parameter model on November 5, 2019.\n",
      "GPT-2 was created as a \"direct scale-up\" of GPT-1 with a ten-fold increase in both its parameter count and the size of its training dataset. It is a general-purpose learner and its ability to perform the various tasks was a consequence of its general ability to accurately predict the next item in a sequence, which enabled it to translate texts, answer questions about a topic from a text, summarize passages from a larger text, and generate text output on a level sometimes indistinguishable from that of humans; however, it could become repetitive or nonsensical when generating long passages. It was superseded by the GPT-3 and GPT-4 models, which are no longer open source.\n",
      "GPT-2 has, like its predecessor GPT-1 and its successors GPT-3 and GPT-4, a generative pre-trained transformer architecture, implementing a deep neural network, specifically a transformer model, which uses attention instead of older recurrence- and convolution-based architectures. Attention mechanisms allow the model to selectively focus on segments of input text it predicts to be the most relevant. This model allows for greatly increased parallelization, and outperforms previous benchmarks for RNN/CNN/LSTM-based models.\n",
      "Link 77: GPT-3\n",
      "Link: GPT-3\n",
      "https://en.wikipedia.org/wiki/GPT-3\n",
      "Summary: Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\n",
      "Like its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\n",
      "On September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.\n",
      "Link 78: GPT-4\n",
      "Link: GPT-4\n",
      "https://en.wikipedia.org/wiki/GPT-4\n",
      "Summary: Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model trained and created by OpenAI and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI's API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.: 2 \n",
      "Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has not revealed technical details and statistics about GPT-4, such as the precise size of the model.\n",
      "Link 79: GPT-4.5\n",
      "Link: GPT-4.5\n",
      "https://en.wikipedia.org/wiki/GPT-4.5\n",
      "Summary: GPT-4.5 (codenamed Orion) is a large language model within OpenAI's GPT series. It was released on February 27, 2025. GPT-4.5 can be accessed by Plus and Pro users through the model picker on web, mobile, and desktop, with plans to expand to other tiers. It can also be accessed via the OpenAI API or the OpenAI Developer Playground.\n",
      "Link 80: GPT-4o\n",
      "Link: GPT-4o\n",
      "https://en.wikipedia.org/wiki/GPT-4o\n",
      "Summary: GPT-4o (\"o\" for \"omni\") is a multilingual, multimodal generative pre-trained transformer developed by OpenAI and released in May 2024. GPT-4o is free, but ChatGPT Plus subscribers have higher usage limits. It can process and generate text, images and audio. Its application programming interface (API) is faster and cheaper than its predecessor, GPT-4 Turbo.\n",
      "Link 81: GPT-J\n",
      "Link: GPT-J\n",
      "https://en.wikipedia.org/wiki/GPT-J\n",
      "Summary: GPT-J or GPT-J-6B is an open-source large language model (LLM) developed by EleutherAI in 2021. As the name suggests, it is a generative pre-trained transformer model designed to produce human-like text that continues from a prompt. The optional \"6B\" in the name refers to the fact that it has 6 billion parameters. The model is available on GitHub, but the web interface no longer communicates with the model. Development stopped in 2021.\n",
      "Link 82: Gated recurrent unit\n",
      "Link: Gated recurrent unit\n",
      "https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
      "Summary: Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al. The GRU is like a long short-term memory (LSTM) with a gating mechanism to input or forget certain features, but lacks a context vector or output gate, resulting in fewer parameters than LSTM. \n",
      "GRU's performance on certain tasks of polyphonic music modeling, speech signal modeling and natural language processing was found to be similar to that of LSTM. GRUs showed that gating is indeed helpful in general, and Bengio's team came to no concrete conclusion on which of the two gating units was better.\n",
      "Link 83: Gating mechanism\n",
      "Link: Gating mechanism\n",
      "https://en.wikipedia.org/wiki/Gating_mechanism\n",
      "Summary: In neural networks, the gating mechanism is an architectural motif for controlling the flow of activation and gradient signals. They are most prominently used in recurrent neural networks (RNNs), but have also found applications in other architectures.\n",
      "Link 84: Gemini (chatbot)\n",
      "Link: Gemini (chatbot)\n",
      "https://en.wikipedia.org/wiki/Gemini_(chatbot)\n",
      "Summary: Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name, it was launched in 2023 in response to the rise of OpenAI's ChatGPT. It was previously based on the LaMDA and PaLM LLMs.\n",
      "LaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI's launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in a limited capacity in March 2023 before expanding to other countries in May. Bard took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. In February 2024, Bard and Duet AI, another artificial intelligence product from Google, were unified under the Gemini brand, coinciding with the launch of an Android app.\n",
      "Gemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with people commenting on its bias as \"wokeness\".\n",
      "Link 85: Gemini (language model)\n",
      "Link: Gemini (language model)\n",
      "https://en.wikipedia.org/wiki/Gemini_(language_model)\n",
      "Summary: Gemini is a family of multimodal large language models developed by Google DeepMind, and the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name. In March 2025, Gemini 2.5 Pro Experimental was rated as highly competitive.\n",
      "Link 86: Generative adversarial network\n",
      "Link: Generative adversarial network\n",
      "https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
      "Summary: A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks compete with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.\n",
      "Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\n",
      "The core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\n",
      "GANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.\n",
      "Link 87: Generative artificial intelligence\n",
      "Link: Generative artificial intelligence\n",
      "https://en.wikipedia.org/wiki/Generative_artificial_intelligence\n",
      "Summary: Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \n",
      "Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\n",
      "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\n",
      "Link 88: Generative pre-trained transformer\n",
      "Link: Generative pre-trained transformer\n",
      "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n",
      "Summary: A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\n",
      "The first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\n",
      "The term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce's \"EinsteinGPT\" (for CRM) and Bloomberg's \"BloombergGPT\" (for finance).\n",
      "Link 89: Geoffrey Hinton\n",
      "Link: Geoffrey Hinton\n",
      "https://en.wikipedia.org/wiki/Geoffrey_Hinton\n",
      "Summary: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, cognitive psychologist, and Nobel laureate in physics, known for his work on artificial neural networks, which earned him the title \"the Godfather of AI\".\n",
      "Hinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google (Google Brain) and the University of Toronto before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n",
      "With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky and Ilya Sutskever for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.\n",
      "Hinton received the 2018 Turing Award, often referred to as the \"Nobel Prize of Computing\", together with Yoshua Bengio and Yann LeCun for their work on deep learning. They are sometimes referred to as the \"Godfathers of Deep Learning\" and have continued to give public talks together. He was also awarded, along with John Hopfield, the 2024 Nobel Prize in Physics for foundational discoveries and inventions that enable machine learning with artificial neural networks.\n",
      "In May 2023, Hinton announced his resignation from Google to be able to \"freely speak out about the risks of A.I.\" He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence. He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes. After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.\n",
      "Link 90: GloVe\n",
      "Link: GloVe\n",
      "https://en.wikipedia.org/wiki/GloVe\n",
      "Summary: GloVe, coined from Global Vectors, is a model for distributed word representation. The model is an unsupervised learning algorithm for obtaining vector representations for words. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. As log-bilinear regression model for unsupervised learning of word representations, it combines the features of two model families, namely the global matrix factorization and local context window methods.\n",
      "It is developed as an open-source project at Stanford and was launched in 2014. It was designed as a competitor to word2vec, and the original paper noted multiple improvements of GloVe over word2vec. As of 2022, both approaches are outdated, and Transformer-based models, such as BERT, which add multiple neural-network attention layers on top of a word embedding model similar to Word2vec, have come to be regarded as the state of the art in NLP.\n",
      "Link 91: Google Bard\n",
      "Link: Google Bard\n",
      "https://en.wikipedia.org/wiki/Gemini_(chatbot)\n",
      "Summary: Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name, it was launched in 2023 in response to the rise of OpenAI's ChatGPT. It was previously based on the LaMDA and PaLM LLMs.\n",
      "LaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI's launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in a limited capacity in March 2023 before expanding to other countries in May. Bard took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. In February 2024, Bard and Duet AI, another artificial intelligence product from Google, were unified under the Gemini brand, coinciding with the launch of an Android app.\n",
      "Gemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with people commenting on its bias as \"wokeness\".\n",
      "Link 92: Google DeepMind\n",
      "Link: Google DeepMind\n",
      "https://en.wikipedia.org/wiki/Google_DeepMind\n",
      "Summary: DeepMind Technologies Limited, trading as Google DeepMind or simply DeepMind, is a British–American artificial intelligence research laboratory which serves as a subsidiary of Alphabet Inc. Founded in the UK in 2010, it was acquired by Google in 2014 and merged with Google AI's Google Brain division to become Google DeepMind in April 2023. The company is headquartered in London, with research centres in the United States, Canada, France, Germany and Switzerland.\n",
      "DeepMind introduced neural Turing machines (neural networks that can access external memory like a conventional Turing machine), resulting in a computer that loosely resembles short-term memory in the human brain.\n",
      "DeepMind has created neural network models to play video games and board games. It made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film. A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning.\n",
      "In 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold. In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database. AlphaFold's database of predictions achieved state of the art records on benchmark tests for protein folding algorithms, although each individual prediction still requires confirmation by experimental tests. AlphaFold3 was released in May 2024, making structural predictions for the interaction of proteins with various molecules. It achieved new standards on various benchmarks, raising the state of the art accuracies from 28 and 52 percent to 65 and 76 percent.\n",
      "Link 93: Gradient descent\n",
      "Link: Gradient descent\n",
      "https://en.wikipedia.org/wiki/Gradient_descent\n",
      "Summary: Gradient descent is a method for unconstrained mathematical optimization. It is a first-order iterative algorithm for minimizing a differentiable multivariate function.\n",
      "The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a trajectory that maximizes that function; the procedure is then known as gradient ascent.\n",
      "It is particularly useful in machine learning for minimizing the cost or loss function. Gradient descent should not be confused with local search algorithms, although both are iterative methods for optimization.\n",
      "Gradient descent is generally attributed to Augustin-Louis Cauchy, who first suggested it in 1847. Jacques Hadamard independently proposed a similar method in 1907. Its convergence properties for non-linear optimization problems were first studied by Haskell Curry in 1944, with the method becoming increasingly well-studied and used in the following decades.\n",
      "A simple extension of gradient descent, stochastic gradient descent, serves as the most basic algorithm used for training most deep networks today.\n",
      "Link 94: Graph neural network\n",
      "Link: Graph neural network\n",
      "https://en.wikipedia.org/wiki/Graph_neural_network\n",
      "Summary: Graph neural networks (GNN) are specialized artificial neural networks that are designed for tasks whose inputs are graphs.\n",
      "One prominent example is molecular drug design.  Each input sample is a graph representation of a molecule, where atoms form the nodes and chemical bonds between atoms form the edges.  In addition to the graph representation, the input also includes known chemical properties for each of the atoms.  Dataset samples may thus differ in length, reflecting the varying numbers of atoms in molecules, and the varying number of bonds between them. The task is to predict the efficacy of a given molecule for a specific medical application, like eliminating E. coli bacteria.\n",
      "The key design element of GNNs is the use of pairwise message passing, such that graph nodes iteratively update their representations by exchanging information with their neighbors. Several GNN architectures have been proposed, which implement different flavors of message passing,  started by recursive or convolutional constructive approaches. As of 2022, it is an open question whether it is possible to define GNN architectures \"going beyond\" message passing, or instead every GNN can be built on message passing over suitably defined graphs.\n",
      "\n",
      "In the more general subject of \"geometric deep learning\", certain existing neural network architectures can be interpreted as GNNs operating on suitably defined graphs. A convolutional neural network layer, in the context of computer vision, can be considered a GNN applied to graphs whose nodes are pixels and only adjacent pixels are connected by edges in the graph. A transformer layer, in natural language processing, can be considered a GNN applied to complete graphs whose nodes are words or tokens in a passage of natural language text.\n",
      "Relevant application domains for GNNs include natural language processing, social networks, citation networks, molecular biology, chemistry, physics and NP-hard combinatorial optimization problems.\n",
      "Open source libraries implementing GNNs include PyTorch Geometric (PyTorch), TensorFlow GNN (TensorFlow), Deep Graph Library (framework agnostic), jraph (Google JAX), and GraphNeuralNetworks.jl/GeometricFlux.jl (Julia, Flux).\n",
      "Link 95: Grok (chatbot)\n",
      "Link: Grok (chatbot)\n",
      "https://en.wikipedia.org/wiki/Grok_(chatbot)\n",
      "Summary: Grok is a generative artificial intelligence chatbot developed by xAI. Based on the large language model (LLM) of the same name, it was launched in 2023 as an initiative by Elon Musk. The chatbot is advertised as having a \"sense of humor\" and direct access to sister platform X, formerly known as Twitter.\n",
      "Link 96: Hallucination (artificial intelligence)\n",
      "Link: Hallucination (artificial intelligence)\n",
      "https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\n",
      "Summary: In the field of artificial intelligence (AI), a hallucination or artificial hallucination (also called bullshitting, confabulation or delusion) is a response generated by AI that contains false or misleading information presented as fact. This term draws a loose analogy with human psychology, where hallucination typically involves false percepts. However, there is a key difference: AI hallucination is associated with erroneously constructed responses (confabulation), rather than perceptual experiences.\n",
      "For example, a chatbot powered by large language models (LLMs), like ChatGPT, may embed plausible-sounding random falsehoods within its generated content. Researchers have recognized this issue, and by 2023, analysts estimated that chatbots hallucinate as much as 27% of the time, with factual errors present in 46% of generated texts. Detecting and mitigating these hallucinations pose significant challenges for practical deployment and reliability of LLMs in real-world scenarios. Some researchers believe the specific term \"AI hallucination\" unreasonably anthropomorphizes computers.\n",
      "Link 97: Handwriting recognition\n",
      "Link: Handwriting recognition\n",
      "https://en.wikipedia.org/wiki/Handwriting_recognition\n",
      "Summary: Handwriting recognition (HWR), also known as handwritten text recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices. The image of the written text may be sensed \"off line\" from a piece of paper by optical scanning (optical character recognition) or intelligent word recognition. Alternatively, the movements of the pen tip may be sensed \"on line\", for example by a pen-based computer screen surface, a generally easier task as there are more clues available. A handwriting recognition system handles formatting, performs correct segmentation into characters, and finds the most possible words.\n",
      "Link 98: Herbert A. Simon\n",
      "Link: Herbert A. Simon\n",
      "https://en.wikipedia.org/wiki/Herbert_A._Simon\n",
      "Summary: Herbert Alexander Simon (June 15, 1916 – February 9, 2001) was an American scholar whose work influenced the fields of computer science, economics, and cognitive psychology. His primary research interest was decision-making within organizations and he is best known for the theories of \"bounded rationality\" and \"satisficing\". He received the Turing Award in 1975 and the Nobel Memorial Prize in Economic Sciences in 1978. His research was noted for its interdisciplinary nature, spanning the fields of cognitive science, computer science, public administration, management, and political science. He was at Carnegie Mellon University for most of his career, from 1949 to 2001, where he helped found the Carnegie Mellon School of Computer Science, one of the first such departments in the world.\n",
      "Notably, Simon was among the pioneers of several modern-day scientific domains such as artificial intelligence, information processing, decision-making, problem-solving, organization theory, and complex systems. He was among the earliest to analyze the architecture of complexity and to propose a preferential attachment mechanism to explain power law distributions.\n",
      "Link 99: Highway network\n",
      "Link: Highway network\n",
      "https://en.wikipedia.org/wiki/Highway_network\n",
      "Summary: In machine learning, the Highway Network was the first working very deep feedforward neural network with hundreds of layers, much deeper than previous neural networks.\n",
      "It uses skip connections modulated by learned gating mechanisms to regulate information flow, inspired by long short-term memory (LSTM) recurrent neural networks.\n",
      "The advantage of the Highway Network over other deep learning architectures is its ability to overcome or partially prevent the vanishing gradient problem, thus improving its optimization. Gating mechanisms are used to facilitate information flow across the many layers (\"information highways\").\n",
      "Highway Networks have found use in text sequence labeling and speech recognition tasks.\n",
      "In 2014, the state of the art was training deep neural networks with 20 to 30 layers. Stacking too many layers led to a steep reduction in training accuracy, known as the \"degradation\" problem. In 2015, two techniques were developed to train such networks: the Highway Network (published in May), and the residual neural network, or ResNet (December). ResNet behaves like an open-gated Highway Net.\n",
      "Link 100: History of artificial intelligence\n",
      "Link: History of artificial intelligence\n",
      "https://en.wikipedia.org/wiki/History_of_artificial_intelligence\n",
      "Summary: The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain.\n",
      "The field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956. Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.\n",
      "Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat. In 1974, criticism from James Lighthill and pressure from the U.S.A. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems  reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names.\n",
      "In the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases.\n",
      "Investment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, prompting debate about the future of AI and its impact on society.\n"
     ]
    }
   ],
   "source": [
    "links = page.links\n",
    "\n",
    "urls = []\n",
    "counter = 0\n",
    "for link in links:\n",
    "    try:\n",
    "        counter += 1\n",
    "        print(f\"Link {counter}: {link}\")\n",
    "        summary = wiki.page(link).summary\n",
    "        print(f\"Link: {link}\")\n",
    "        print(wiki.page(link).fullurl)\n",
    "        urls.append(wiki.page(link).fullurl)\n",
    "        print(f\"Summary: {summary}\")\n",
    "        if counter >= maxl:\n",
    "            break\n",
    "    except page.exists() == False:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['https://en.wikipedia.org/wiki/01.AI', 'https://en.wikipedia.org/wiki/15.ai', 'https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)', 'https://en.wikipedia.org/wiki/Amazon_Web_Services', 'https://en.wikipedia.org/wiki/Action_selection', 'https://en.wikipedia.org/wiki/Activation_function', 'https://en.wikipedia.org/wiki/Adobe_Firefly', 'https://en.wikipedia.org/wiki/Adversarial_machine_learning', 'https://en.wikipedia.org/wiki/Alan_Turing', 'https://en.wikipedia.org/wiki/AlexNet', 'https://en.wikipedia.org/wiki/Alex_Graves_(computer_scientist)', 'https://en.wikipedia.org/wiki/Alex_Krizhevsky', 'https://en.wikipedia.org/wiki/Alibaba_Group', 'https://en.wikipedia.org/wiki/Allen_Newell', 'https://en.wikipedia.org/wiki/AlphaFold', 'https://en.wikipedia.org/wiki/AlphaGo', 'https://en.wikipedia.org/wiki/AlphaZero', 'https://en.wikipedia.org/wiki/Alphabet_Inc.', 'https://en.wikipedia.org/wiki/Andrej_Karpathy', 'https://en.wikipedia.org/wiki/Andrew_Ng', 'https://en.wikipedia.org/wiki/Anthropic', 'https://en.wikipedia.org/wiki/Nearest_neighbor_search', 'https://en.wikipedia.org/wiki/ArXiv', 'https://en.wikipedia.org/wiki/Ars_Technica', 'https://en.wikipedia.org/wiki/Artificial_general_intelligence', 'https://en.wikipedia.org/wiki/Artificial_intelligence', 'https://en.wikipedia.org/wiki/Attention_(machine_learning)', 'https://en.wikipedia.org/wiki/Grok_(chatbot)', 'https://en.wikipedia.org/wiki/AutoGPT', 'https://en.wikipedia.org/wiki/Autoencoder', 'https://en.wikipedia.org/wiki/Autoregressive_model', 'https://en.wikipedia.org/wiki/BERT_(language_model)', 'https://en.wikipedia.org/wiki/BLOOM_(language_model)', 'https://en.wikipedia.org/wiki/Backpropagation', 'https://en.wikipedia.org/wiki/Baichuan', 'https://en.wikipedia.org/wiki/Baidu', 'https://en.wikipedia.org/wiki/Batch_normalization', 'https://en.wikipedia.org/wiki/Bernard_Widrow', 'https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff', 'https://en.wikipedia.org/wiki/ChatGPT', 'https://en.wikipedia.org/wiki/Chatbot', 'https://en.wikipedia.org/wiki/Chinchilla_(language_model)', 'https://en.wikipedia.org/wiki/Claude_(language_model)', 'https://en.wikipedia.org/wiki/Claude_Shannon', 'https://en.wikipedia.org/wiki/Cliff_Shaw', 'https://en.wikipedia.org/wiki/Cluster_analysis', 'https://en.wikipedia.org/wiki/Conjugate_gradient_method', 'https://en.wikipedia.org/wiki/Convolution', 'https://en.wikipedia.org/wiki/Convolutional_neural_network', 'https://en.wikipedia.org/wiki/DALL-E', 'https://en.wikipedia.org/wiki/DBRX', 'https://en.wikipedia.org/wiki/Data_augmentation', 'https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)', 'https://en.wikipedia.org/wiki/DeepSeek', 'https://en.wikipedia.org/wiki/DeepSeek_(chatbot)', 'https://en.wikipedia.org/wiki/Deep_learning', 'https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis', 'https://en.wikipedia.org/wiki/Demis_Hassabis', 'https://en.wikipedia.org/wiki/Sparse_matrix', 'https://en.wikipedia.org/wiki/Differentiable_neural_computer', 'https://en.wikipedia.org/wiki/Diffusion_process', 'https://en.wikipedia.org/wiki/Document_retrieval', 'https://en.wikipedia.org/wiki/Digital_object_identifier', 'https://en.wikipedia.org/wiki/Dot_product', 'https://en.wikipedia.org/wiki/Double_descent', 'https://en.wikipedia.org/wiki/Dream_Machine_(text-to-video_model)', 'https://en.wikipedia.org/wiki/Echo_state_network', 'https://en.wikipedia.org/wiki/ElevenLabs', 'https://en.wikipedia.org/wiki/Endel_(app)', 'https://en.wikipedia.org/wiki/Ernie_Bot', 'https://en.wikipedia.org/wiki/Facial_recognition_system', 'https://en.wikipedia.org/wiki/Fei-Fei_Li', 'https://en.wikipedia.org/wiki/Flux_(text-to-image_model)', 'https://en.wikipedia.org/wiki/Frank_Rosenblatt', 'https://en.wikipedia.org/wiki/GPT-1', 'https://en.wikipedia.org/wiki/GPT-2', 'https://en.wikipedia.org/wiki/GPT-3', 'https://en.wikipedia.org/wiki/GPT-4', 'https://en.wikipedia.org/wiki/GPT-4.5', 'https://en.wikipedia.org/wiki/GPT-4o', 'https://en.wikipedia.org/wiki/GPT-J', 'https://en.wikipedia.org/wiki/Gated_recurrent_unit', 'https://en.wikipedia.org/wiki/Gating_mechanism', 'https://en.wikipedia.org/wiki/Gemini_(chatbot)', 'https://en.wikipedia.org/wiki/Gemini_(language_model)', 'https://en.wikipedia.org/wiki/Generative_adversarial_network', 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer', 'https://en.wikipedia.org/wiki/Geoffrey_Hinton', 'https://en.wikipedia.org/wiki/GloVe', 'https://en.wikipedia.org/wiki/Gemini_(chatbot)', 'https://en.wikipedia.org/wiki/Google_DeepMind', 'https://en.wikipedia.org/wiki/Gradient_descent', 'https://en.wikipedia.org/wiki/Graph_neural_network', 'https://en.wikipedia.org/wiki/Grok_(chatbot)', 'https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)', 'https://en.wikipedia.org/wiki/Handwriting_recognition', 'https://en.wikipedia.org/wiki/Herbert_A._Simon', 'https://en.wikipedia.org/wiki/Highway_network', 'https://en.wikipedia.org/wiki/History_of_artificial_intelligence']\n"
     ]
    }
   ],
   "source": [
    "print(counter)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "links = page.links\n",
    "\n",
    "fname = filename + \"_citations.txt\"\n",
    "with open(fname, \"w\") as file:\n",
    "    file.write(f\"Citation. In Wikipedia, The Free Encyclopedia. Pages retrieved from the following Wikipedia contributors on {datetime.now()}\\n\")\n",
    "    file.write(\"Root page: \" + page.fullurl + \"\\n\")\n",
    "\n",
    "    counter = 0\n",
    "    urls = []\n",
    "    urls.append(page.fullurl)\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            counter += 1\n",
    "            page_detail = wiki.page(link)\n",
    "            summary = page_detail.summary\n",
    "\n",
    "            file.write(f\"Link {counter}: {link}\\n\")\n",
    "            file.write(f\"Link: {link}\\n\")\n",
    "            file.write(f\"{page_detail.fullurl}\\n\")\n",
    "            urls.append(page_detail.fullurl)\n",
    "            file.write(f\"Summary: {summary}\\n\")\n",
    "\n",
    "            if counter >= maxl:\n",
    "                break\n",
    "        except wiki.exceptions.PageError:\n",
    "            continue\n",
    "    \n",
    "    file.write(f\"Total links processd: {counter}\\n\")\n",
    "    file.write(\"URLs:\\n\")\n",
    "    file.write(\"\\n\".join(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Retrieval-augmented_generation',\n",
       " 'https://en.wikipedia.org/wiki/01.AI',\n",
       " 'https://en.wikipedia.org/wiki/15.ai',\n",
       " 'https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)',\n",
       " 'https://en.wikipedia.org/wiki/Amazon_Web_Services',\n",
       " 'https://en.wikipedia.org/wiki/Action_selection',\n",
       " 'https://en.wikipedia.org/wiki/Activation_function',\n",
       " 'https://en.wikipedia.org/wiki/Adobe_Firefly',\n",
       " 'https://en.wikipedia.org/wiki/Adversarial_machine_learning',\n",
       " 'https://en.wikipedia.org/wiki/Alan_Turing',\n",
       " 'https://en.wikipedia.org/wiki/AlexNet',\n",
       " 'https://en.wikipedia.org/wiki/Alex_Graves_(computer_scientist)',\n",
       " 'https://en.wikipedia.org/wiki/Alex_Krizhevsky',\n",
       " 'https://en.wikipedia.org/wiki/Alibaba_Group',\n",
       " 'https://en.wikipedia.org/wiki/Allen_Newell',\n",
       " 'https://en.wikipedia.org/wiki/AlphaFold',\n",
       " 'https://en.wikipedia.org/wiki/AlphaGo',\n",
       " 'https://en.wikipedia.org/wiki/AlphaZero',\n",
       " 'https://en.wikipedia.org/wiki/Alphabet_Inc.',\n",
       " 'https://en.wikipedia.org/wiki/Andrej_Karpathy',\n",
       " 'https://en.wikipedia.org/wiki/Andrew_Ng',\n",
       " 'https://en.wikipedia.org/wiki/Anthropic',\n",
       " 'https://en.wikipedia.org/wiki/Nearest_neighbor_search',\n",
       " 'https://en.wikipedia.org/wiki/ArXiv',\n",
       " 'https://en.wikipedia.org/wiki/Ars_Technica',\n",
       " 'https://en.wikipedia.org/wiki/Artificial_general_intelligence',\n",
       " 'https://en.wikipedia.org/wiki/Artificial_intelligence',\n",
       " 'https://en.wikipedia.org/wiki/Attention_(machine_learning)',\n",
       " 'https://en.wikipedia.org/wiki/Grok_(chatbot)',\n",
       " 'https://en.wikipedia.org/wiki/AutoGPT',\n",
       " 'https://en.wikipedia.org/wiki/Autoencoder',\n",
       " 'https://en.wikipedia.org/wiki/Autoregressive_model',\n",
       " 'https://en.wikipedia.org/wiki/BERT_(language_model)',\n",
       " 'https://en.wikipedia.org/wiki/BLOOM_(language_model)',\n",
       " 'https://en.wikipedia.org/wiki/Backpropagation',\n",
       " 'https://en.wikipedia.org/wiki/Baichuan',\n",
       " 'https://en.wikipedia.org/wiki/Baidu',\n",
       " 'https://en.wikipedia.org/wiki/Batch_normalization',\n",
       " 'https://en.wikipedia.org/wiki/Bernard_Widrow',\n",
       " 'https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff',\n",
       " 'https://en.wikipedia.org/wiki/ChatGPT',\n",
       " 'https://en.wikipedia.org/wiki/Chatbot',\n",
       " 'https://en.wikipedia.org/wiki/Chinchilla_(language_model)',\n",
       " 'https://en.wikipedia.org/wiki/Claude_(language_model)',\n",
       " 'https://en.wikipedia.org/wiki/Claude_Shannon',\n",
       " 'https://en.wikipedia.org/wiki/Cliff_Shaw',\n",
       " 'https://en.wikipedia.org/wiki/Cluster_analysis',\n",
       " 'https://en.wikipedia.org/wiki/Conjugate_gradient_method',\n",
       " 'https://en.wikipedia.org/wiki/Convolution',\n",
       " 'https://en.wikipedia.org/wiki/Convolutional_neural_network',\n",
       " 'https://en.wikipedia.org/wiki/DALL-E',\n",
       " 'https://en.wikipedia.org/wiki/DBRX',\n",
       " 'https://en.wikipedia.org/wiki/Data_augmentation',\n",
       " 'https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)',\n",
       " 'https://en.wikipedia.org/wiki/DeepSeek',\n",
       " 'https://en.wikipedia.org/wiki/DeepSeek_(chatbot)',\n",
       " 'https://en.wikipedia.org/wiki/Deep_learning',\n",
       " 'https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis',\n",
       " 'https://en.wikipedia.org/wiki/Demis_Hassabis',\n",
       " 'https://en.wikipedia.org/wiki/Sparse_matrix',\n",
       " 'https://en.wikipedia.org/wiki/Differentiable_neural_computer',\n",
       " 'https://en.wikipedia.org/wiki/Diffusion_process',\n",
       " 'https://en.wikipedia.org/wiki/Document_retrieval',\n",
       " 'https://en.wikipedia.org/wiki/Digital_object_identifier',\n",
       " 'https://en.wikipedia.org/wiki/Dot_product',\n",
       " 'https://en.wikipedia.org/wiki/Double_descent',\n",
       " 'https://en.wikipedia.org/wiki/Dream_Machine_(text-to-video_model)',\n",
       " 'https://en.wikipedia.org/wiki/Echo_state_network',\n",
       " 'https://en.wikipedia.org/wiki/ElevenLabs',\n",
       " 'https://en.wikipedia.org/wiki/Endel_(app)',\n",
       " 'https://en.wikipedia.org/wiki/Ernie_Bot',\n",
       " 'https://en.wikipedia.org/wiki/Facial_recognition_system',\n",
       " 'https://en.wikipedia.org/wiki/Fei-Fei_Li',\n",
       " 'https://en.wikipedia.org/wiki/Flux_(text-to-image_model)',\n",
       " 'https://en.wikipedia.org/wiki/Frank_Rosenblatt',\n",
       " 'https://en.wikipedia.org/wiki/GPT-1',\n",
       " 'https://en.wikipedia.org/wiki/GPT-2',\n",
       " 'https://en.wikipedia.org/wiki/GPT-3',\n",
       " 'https://en.wikipedia.org/wiki/GPT-4',\n",
       " 'https://en.wikipedia.org/wiki/GPT-4.5',\n",
       " 'https://en.wikipedia.org/wiki/GPT-4o',\n",
       " 'https://en.wikipedia.org/wiki/GPT-J',\n",
       " 'https://en.wikipedia.org/wiki/Gated_recurrent_unit',\n",
       " 'https://en.wikipedia.org/wiki/Gating_mechanism',\n",
       " 'https://en.wikipedia.org/wiki/Gemini_(chatbot)',\n",
       " 'https://en.wikipedia.org/wiki/Gemini_(language_model)',\n",
       " 'https://en.wikipedia.org/wiki/Generative_adversarial_network',\n",
       " 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence',\n",
       " 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer',\n",
       " 'https://en.wikipedia.org/wiki/Geoffrey_Hinton',\n",
       " 'https://en.wikipedia.org/wiki/GloVe',\n",
       " 'https://en.wikipedia.org/wiki/Gemini_(chatbot)',\n",
       " 'https://en.wikipedia.org/wiki/Google_DeepMind',\n",
       " 'https://en.wikipedia.org/wiki/Gradient_descent',\n",
       " 'https://en.wikipedia.org/wiki/Graph_neural_network',\n",
       " 'https://en.wikipedia.org/wiki/Grok_(chatbot)',\n",
       " 'https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)',\n",
       " 'https://en.wikipedia.org/wiki/Handwriting_recognition',\n",
       " 'https://en.wikipedia.org/wiki/Herbert_A._Simon',\n",
       " 'https://en.wikipedia.org/wiki/Highway_network',\n",
       " 'https://en.wikipedia.org/wiki/History_of_artificial_intelligence']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs have been written to urls.txt\n"
     ]
    }
   ],
   "source": [
    "ufname = filename + \"_urls.txt\"\n",
    "with open(ufname, 'w') as file:\n",
    "    for url in urls:\n",
    "        file.write(url + '\\n')\n",
    "\n",
    "print(\"URLs have been written to urls.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read URLs:\n",
      "https://en.wikipedia.org/wiki/Retrieval-augmented_generation\n",
      "https://en.wikipedia.org/wiki/01.AI\n",
      "https://en.wikipedia.org/wiki/15.ai\n",
      "https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\n",
      "https://en.wikipedia.org/wiki/Amazon_Web_Services\n",
      "https://en.wikipedia.org/wiki/Action_selection\n",
      "https://en.wikipedia.org/wiki/Activation_function\n",
      "https://en.wikipedia.org/wiki/Adobe_Firefly\n",
      "https://en.wikipedia.org/wiki/Adversarial_machine_learning\n",
      "https://en.wikipedia.org/wiki/Alan_Turing\n",
      "https://en.wikipedia.org/wiki/AlexNet\n",
      "https://en.wikipedia.org/wiki/Alex_Graves_(computer_scientist)\n",
      "https://en.wikipedia.org/wiki/Alex_Krizhevsky\n",
      "https://en.wikipedia.org/wiki/Alibaba_Group\n",
      "https://en.wikipedia.org/wiki/Allen_Newell\n",
      "https://en.wikipedia.org/wiki/AlphaFold\n",
      "https://en.wikipedia.org/wiki/AlphaGo\n",
      "https://en.wikipedia.org/wiki/AlphaZero\n",
      "https://en.wikipedia.org/wiki/Alphabet_Inc.\n",
      "https://en.wikipedia.org/wiki/Andrej_Karpathy\n",
      "https://en.wikipedia.org/wiki/Andrew_Ng\n",
      "https://en.wikipedia.org/wiki/Anthropic\n",
      "https://en.wikipedia.org/wiki/Nearest_neighbor_search\n",
      "https://en.wikipedia.org/wiki/ArXiv\n",
      "https://en.wikipedia.org/wiki/Ars_Technica\n",
      "https://en.wikipedia.org/wiki/Artificial_general_intelligence\n",
      "https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "https://en.wikipedia.org/wiki/Attention_(machine_learning)\n",
      "https://en.wikipedia.org/wiki/Grok_(chatbot)\n",
      "https://en.wikipedia.org/wiki/AutoGPT\n",
      "https://en.wikipedia.org/wiki/Autoencoder\n",
      "https://en.wikipedia.org/wiki/Autoregressive_model\n",
      "https://en.wikipedia.org/wiki/BERT_(language_model)\n",
      "https://en.wikipedia.org/wiki/BLOOM_(language_model)\n",
      "https://en.wikipedia.org/wiki/Backpropagation\n",
      "https://en.wikipedia.org/wiki/Baichuan\n",
      "https://en.wikipedia.org/wiki/Baidu\n",
      "https://en.wikipedia.org/wiki/Batch_normalization\n",
      "https://en.wikipedia.org/wiki/Bernard_Widrow\n",
      "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\n",
      "https://en.wikipedia.org/wiki/ChatGPT\n",
      "https://en.wikipedia.org/wiki/Chatbot\n",
      "https://en.wikipedia.org/wiki/Chinchilla_(language_model)\n",
      "https://en.wikipedia.org/wiki/Claude_(language_model)\n",
      "https://en.wikipedia.org/wiki/Claude_Shannon\n",
      "https://en.wikipedia.org/wiki/Cliff_Shaw\n",
      "https://en.wikipedia.org/wiki/Cluster_analysis\n",
      "https://en.wikipedia.org/wiki/Conjugate_gradient_method\n",
      "https://en.wikipedia.org/wiki/Convolution\n",
      "https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
      "https://en.wikipedia.org/wiki/DALL-E\n",
      "https://en.wikipedia.org/wiki/DBRX\n",
      "https://en.wikipedia.org/wiki/Data_augmentation\n",
      "https://en.wikipedia.org/wiki/David_Silver_(computer_scientist)\n",
      "https://en.wikipedia.org/wiki/DeepSeek\n",
      "https://en.wikipedia.org/wiki/DeepSeek_(chatbot)\n",
      "https://en.wikipedia.org/wiki/Deep_learning\n",
      "https://en.wikipedia.org/wiki/Deep_learning_speech_synthesis\n",
      "https://en.wikipedia.org/wiki/Demis_Hassabis\n",
      "https://en.wikipedia.org/wiki/Sparse_matrix\n",
      "https://en.wikipedia.org/wiki/Differentiable_neural_computer\n",
      "https://en.wikipedia.org/wiki/Diffusion_process\n",
      "https://en.wikipedia.org/wiki/Document_retrieval\n",
      "https://en.wikipedia.org/wiki/Digital_object_identifier\n",
      "https://en.wikipedia.org/wiki/Dot_product\n",
      "https://en.wikipedia.org/wiki/Double_descent\n",
      "https://en.wikipedia.org/wiki/Dream_Machine_(text-to-video_model)\n",
      "https://en.wikipedia.org/wiki/Echo_state_network\n",
      "https://en.wikipedia.org/wiki/ElevenLabs\n",
      "https://en.wikipedia.org/wiki/Endel_(app)\n",
      "https://en.wikipedia.org/wiki/Ernie_Bot\n",
      "https://en.wikipedia.org/wiki/Facial_recognition_system\n",
      "https://en.wikipedia.org/wiki/Fei-Fei_Li\n",
      "https://en.wikipedia.org/wiki/Flux_(text-to-image_model)\n",
      "https://en.wikipedia.org/wiki/Frank_Rosenblatt\n",
      "https://en.wikipedia.org/wiki/GPT-1\n",
      "https://en.wikipedia.org/wiki/GPT-2\n",
      "https://en.wikipedia.org/wiki/GPT-3\n",
      "https://en.wikipedia.org/wiki/GPT-4\n",
      "https://en.wikipedia.org/wiki/GPT-4.5\n",
      "https://en.wikipedia.org/wiki/GPT-4o\n",
      "https://en.wikipedia.org/wiki/GPT-J\n",
      "https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
      "https://en.wikipedia.org/wiki/Gating_mechanism\n",
      "https://en.wikipedia.org/wiki/Gemini_(chatbot)\n",
      "https://en.wikipedia.org/wiki/Gemini_(language_model)\n",
      "https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
      "https://en.wikipedia.org/wiki/Generative_artificial_intelligence\n",
      "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer\n",
      "https://en.wikipedia.org/wiki/Geoffrey_Hinton\n",
      "https://en.wikipedia.org/wiki/GloVe\n",
      "https://en.wikipedia.org/wiki/Gemini_(chatbot)\n",
      "https://en.wikipedia.org/wiki/Google_DeepMind\n",
      "https://en.wikipedia.org/wiki/Gradient_descent\n",
      "https://en.wikipedia.org/wiki/Graph_neural_network\n",
      "https://en.wikipedia.org/wiki/Grok_(chatbot)\n",
      "https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\n",
      "https://en.wikipedia.org/wiki/Handwriting_recognition\n",
      "https://en.wikipedia.org/wiki/Herbert_A._Simon\n",
      "https://en.wikipedia.org/wiki/Highway_network\n",
      "https://en.wikipedia.org/wiki/History_of_artificial_intelligence\n"
     ]
    }
   ],
   "source": [
    "with open(ufname, 'r') as file:\n",
    "    urls = [line.strip() for line in file]\n",
    "\n",
    "print(\"Read URLs:\")\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
