{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        use_idf=True,\n",
    "        norm='l2',\n",
    "        ngram_range=(1, 2),\n",
    "        sublinear_tf=True,\n",
    "        analyzer='word'\n",
    "    )\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy 모델을 적재한다.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmatized_words = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        lemmatized_words.append(token.lemma_)\n",
    "    return lemmatized_words\n",
    "\n",
    "def expand_with_synonyms(words):\n",
    "    expanded_words = words.copy()\n",
    "    for word in words:\n",
    "        expanded_words.extend(get_synonyms(word))\n",
    "    return expanded_words\n",
    "\n",
    "def calculate_enhanced_similarity(text1, text2):\n",
    "    words1 = preprocess_text(text1)\n",
    "    words2 = preprocess_text(text2)\n",
    "\n",
    "    words1_expanded = expand_with_synonyms(words1)\n",
    "    words2_expanded = expand_with_synonyms(words2)\n",
    "\n",
    "    freq1 = Counter(words1_expanded)\n",
    "    freq2 = Counter(words2_expanded)\n",
    "\n",
    "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
    "    \n",
    "    vector1 = [freq1[word] for word in unique_words]\n",
    "    vector2 = [freq2[word] for word in unique_words]\n",
    "\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    \n",
    "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_formatted_response(response):\n",
    "    wrapper = textwrap.TextWrapper(width=150)\n",
    "    wrapped_text = wrapper.fill(text=response)\n",
    "    print(\"Response:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(wrapped_text)\n",
    "    print(\"-\" * 20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match_keyword_search(query, db_records):\n",
    "    best_score = 0\n",
    "    best_record = None\n",
    "\n",
    "    query_keywords = set(query.lower().split())\n",
    "    for record in db_records:\n",
    "        record_keywords = set(record.lower().split())\n",
    "        common_keywords = query_keywords.intersection(record_keywords)\n",
    "        current_score = len(common_keywords)\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_record = record\n",
    "    \n",
    "    return best_score, best_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_records = [\n",
    "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
    "    \"It innovatively combines the capabilities of neural network-based language models with retrieval systems to enhance the generation of text, making it more accurate, informative, and contextually relevant.\",\n",
    "    \"This methodology leverages the strengths of both generative and retrieval architectures to tackle complex tasks that require not only linguistic fluency but also factual correctness and depth of knowledge.\",\n",
    "    \"At the core of Retrieval Augmented Generation (RAG) is a generative model, typically a transformer-based neural network, similar to those used in models like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers).\",\n",
    "    \"This component is responsible for producing coherent and contextually appropriate language outputs based on a mixture of input prompts and additional information fetched by the retrieval component.\",\n",
    "    \"Complementing the language model is the retrieval system, which is usually built on a database of documents or a corpus of texts.\",\n",
    "    \"This system uses techniques from information retrieval to find and fetch documents that are relevant to the input query or prompt.\",\n",
    "    \"The mechanism of relevance determination can range from simple keyword matching to more complex semantic search algorithms which interpret the meaning behind the query to find the best matches.\",\n",
    "    \"This component merges the outputs from the language model and the retrieval system.\",\n",
    "    \"It effectively synthesizes the raw data fetched by the retrieval system into the generative process of the language model.\",\n",
    "    \"The integrator ensures that the information from the retrieval system is seamlessly incorporated into the final text output, enhancing the model's ability to generate responses that are not only fluent and grammatically correct but also rich in factual details and context-specific nuances.\",\n",
    "    \"When a query or prompt is received, the system first processes it to understand the requirement or the context.\",\n",
    "    \"Based on the processed query, the retrieval system searches through its database to find relevant documents or information snippets.\",\n",
    "    \"This retrieval is guided by the similarity of content in the documents to the query, which can be determined through various techniques like vector embeddings or semantic similarity measures.\",\n",
    "    \"The retrieved documents are then fed into the language model.\",\n",
    "    \"In some implementations, this integration happens at the token level, where the model can access and incorporate specific pieces of information from the retrieved texts dynamically as it generates each part of the response.\",\n",
    "    \"The language model, now augmented with direct access to retrieved information, generates a response.\",\n",
    "    \"This response is not only influenced by the training of the model but also by the specific facts and details contained in the retrieved documents, making it more tailored and accurate.\",\n",
    "    \"By directly incorporating information from external sources, Retrieval Augmented Generation (RAG) models can produce responses that are more factual and relevant to the given query.\",\n",
    "    \"This is particularly useful in domains like medical advice, technical support, and other areas where precision and up-to-date knowledge are crucial.\",\n",
    "    \"Retrieval Augmented Generation (RAG) systems can dynamically adapt to new information since they retrieve data in real-time from their databases.\",\n",
    "    \"This allows them to remain current with the latest knowledge and trends without needing frequent retraining.\",\n",
    "    \"With access to a wide range of documents, Retrieval Augmented Generation (RAG) systems can provide detailed and nuanced answers that a standalone language model might not be capable of generating based solely on its pre-trained knowledge.\",\n",
    "    \"While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\",\n",
    "    \"These include the complexity of integrating retrieval and generation systems, the computational overhead associated with real-time data retrieval, and the need for maintaining a large, up-to-date, and high-quality database of retrievable texts.\",\n",
    "    \"Furthermore, ensuring the relevance and accuracy of the retrieved information remains a significant challenge, as does managing the potential for introducing biases or errors from the external sources.\",\n",
    "    \"In summary, Retrieval Augmented Generation represents a significant advancement in the field of artificial intelligence, merging the best of retrieval-based and generative technologies to create systems that not only understand and generate natural language but also deeply comprehend and utilize the vast amounts of information available in textual form.\",\n",
    "    \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best keyword Score: 3\n",
      "Response:\n",
      "--------------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Define a RAG store\"\n",
    "\n",
    "best_keyword_score, best_keyword_record = find_best_match_keyword_search(query, db_records)\n",
    "print(f\"Best keyword Score: {best_keyword_score}\")\n",
    "print_formatted_response(best_keyword_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.126\n"
     ]
    }
   ],
   "source": [
    "score = calculate_cosine_similarity(query, best_keyword_record)\n",
    "print(f\"Best Cosine Similarity Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define a RAG store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity Score: 0.642\n"
     ]
    }
   ],
   "source": [
    "response = best_keyword_record\n",
    "print(query, \": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, response)\n",
    "print(f\"Enhanced Similarity Score: {similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "Define a RAG store: A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "augmented_input = query + \": \" + best_keyword_record\n",
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "gptmodel = \"gpt-4o\"\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_full_text(itext):\n",
    "    text_input = '\\n'.join(itext)\n",
    "    prompt = f\"\"\"\n",
    "    Please elaborate on the following content and translate the result in \"KOREAN\":\\n{text_input}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=gptmodel,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert Natural Language Processing exercise expert. \"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"1. You can explain read the input and answer in detail\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "A RAG (Retrieval-Augmented Generation) vector store is a specialized database or dataset designed to store and manage vectorized data points. These\n",
      "data points are typically numerical representations of information, such as text, images, or other types of data, that have been transformed into\n",
      "vectors. The purpose of a RAG vector store is to facilitate efficient retrieval and manipulation of these vectorized data points, often used in\n",
      "machine learning and artificial intelligence applications to enhance the performance of models by providing relevant context or information during the\n",
      "generation process.  Korean Translation: RAG 벡터 저장소는 벡터화된 데이터 포인트를 저장하고 관리하기 위해 설계된 특수한 데이터베이스 또는 데이터셋입니다. 이러한 데이터 포인트는 일반적으로 텍스트, 이미지 또는 기타 유형의 데이터를\n",
      "벡터로 변환한 수치적 표현입니다. RAG 벡터 저장소의 목적은 이러한 벡터화된 데이터 포인트의 효율적인 검색과 조작을 용이하게 하는 것으로, 주로 기계 학습 및 인공지능 응용 프로그램에서 모델의 성능을 향상시키기 위해 관련된 컨텍스트나 정보를 제공하는 데 사용됩니다.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(text_input, records):\n",
    "    best_score = 0\n",
    "    best_record = None\n",
    "    for record in records:\n",
    "        current_score = calculate_cosine_similarity(text_input, record)\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_record = record\n",
    "    return best_score, best_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_similarity_score, best_similarity_record = find_best_match(query, db_records)\n",
    "print_formatted_response(best_similarity_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.126\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define a RAG store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity: 0.642\n"
     ]
    }
   ],
   "source": [
    "response = best_similarity_record\n",
    "print(query, \": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, best_similarity_record)\n",
    "print(f\"Enhanced Similarity: {similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "Define a RAG store: A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "augmented_input = query + \": \" + best_similarity_record\n",
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "A RAG (Retrieval-Augmented Generation) vector store is a specialized database or dataset designed to store and manage vectorized data points. These\n",
      "data points are typically numerical representations of information, often derived from text or other forms of data, that have been transformed into\n",
      "vectors. The purpose of a RAG vector store is to facilitate efficient retrieval and manipulation of these vectors, which can be used in various\n",
      "applications such as machine learning, natural language processing, and information retrieval. By storing data in vector form, it becomes easier to\n",
      "perform operations like similarity searches, clustering, and classification, which are essential for tasks that involve understanding and generating\n",
      "human-like text or other complex data interactions.  Korean Translation: RAG(검색 증강 생성) 벡터 저장소는 벡터화된 데이터 포인트를 저장하고 관리하기 위해 설계된 특수한 데이터베이스 또는 데이터셋입니다.\n",
      "이러한 데이터 포인트는 일반적으로 텍스트 또는 기타 형태의 데이터에서 파생된 정보를 수치적으로 표현한 것으로, 벡터로 변환된 것입니다. RAG 벡터 저장소의 목적은 이러한 벡터의 효율적인 검색 및 조작을 용이하게 하는 것으로, 이는 기계 학습, 자연어 처리 및 정보\n",
      "검색과 같은 다양한 응용 프로그램에서 사용될 수 있습니다. 데이터를 벡터 형태로 저장함으로써 유사성 검색, 클러스터링 및 분류와 같은 작업을 수행하기가 쉬워지며, 이는 인간과 유사한 텍스트 생성 또는 기타 복잡한 데이터 상호작용을 포함하는 작업에 필수적입니다.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def setup_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(records)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def find_best_match(query, vectorizer, tfidf_matrix):\n",
    "    query_tfidf = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
    "    best_index = similarities.argmax()\n",
    "    best_score = similarities[0, best_index]\n",
    "    return best_score, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
    "best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
    "best_matching_record = db_records[best_index]\n",
    "\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>access</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accurate</th>\n",
       "      <th>adapt</th>\n",
       "      <th>additional</th>\n",
       "      <th>advancement</th>\n",
       "      <th>advice</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>allows</th>\n",
       "      <th>...</th>\n",
       "      <th>vector</th>\n",
       "      <th>vectorized</th>\n",
       "      <th>when</th>\n",
       "      <th>where</th>\n",
       "      <th>which</th>\n",
       "      <th>while</th>\n",
       "      <th>wide</th>\n",
       "      <th>with</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260582</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  access  accuracy  accurate  adapt  additional  advancement  \\\n",
       "0      0.0     0.0       0.0  0.000000    0.0    0.000000          0.0   \n",
       "1      0.0     0.0       0.0  0.216364    0.0    0.000000          0.0   \n",
       "2      0.0     0.0       0.0  0.000000    0.0    0.000000          0.0   \n",
       "3      0.0     0.0       0.0  0.000000    0.0    0.000000          0.0   \n",
       "4      0.0     0.0       0.0  0.000000    0.0    0.236479          0.0   \n",
       "\n",
       "   advice  algorithms  allows  ...  vector  vectorized  when  where  which  \\\n",
       "0     0.0         0.0     0.0  ...     0.0         0.0   0.0    0.0    0.0   \n",
       "1     0.0         0.0     0.0  ...     0.0         0.0   0.0    0.0    0.0   \n",
       "2     0.0         0.0     0.0  ...     0.0         0.0   0.0    0.0    0.0   \n",
       "3     0.0         0.0     0.0  ...     0.0         0.0   0.0    0.0    0.0   \n",
       "4     0.0         0.0     0.0  ...     0.0         0.0   0.0    0.0    0.0   \n",
       "\n",
       "   while  wide      with    within  without  \n",
       "0    0.0   0.0  0.000000  0.260582      0.0  \n",
       "1    0.0   0.0  0.160278  0.000000      0.0  \n",
       "2    0.0   0.0  0.000000  0.000000      0.0  \n",
       "3    0.0   0.0  0.000000  0.000000      0.0  \n",
       "4    0.0   0.0  0.000000  0.000000      0.0  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "Define a RAG store: A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "augmented_input = query + \": \" + best_matching_record\n",
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalComponent:\n",
    "\n",
    "    def __init__(self, method='vector'):\n",
    "        self.method = method\n",
    "        if self.method == 'vector' or self.method == 'indexed':\n",
    "            self.vectorizer = TfidfVectorizer()\n",
    "            self.tfidf_matrix = None\n",
    "    \n",
    "    def fit(self, records):\n",
    "        self.documents = records\n",
    "        if self.method == 'vector' or self.method == 'indexed':\n",
    "            self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
    "    \n",
    "    def retrieve(self, query):\n",
    "        if self.method == 'keyword':\n",
    "            return self.keyword_search(query)\n",
    "        elif self.method == 'vector':\n",
    "            return self.vector_search(query)\n",
    "        elif self.method == 'indexed':\n",
    "            return self.indexed_search(query)\n",
    "    \n",
    "    def keyword_search(self, query):\n",
    "        best_score = 0\n",
    "        best_record = None\n",
    "        query_keywords = set(query.lower().split())\n",
    "        for index, doc in enumerate(self.documents):\n",
    "            doc_keywords = set(doc.lower().split())\n",
    "            common_keywords = query_keywords.intersection(doc_keywords)\n",
    "            score = len(common_keywords)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_record = self.documents[index]\n",
    "        return best_record\n",
    "    \n",
    "    def vector_search(self, query):\n",
    "        query_tfidf = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
    "        best_index = similarities.argmax()\n",
    "        return db_records[best_index]\n",
    "    \n",
    "    def indexed_search(self, query):\n",
    "        query_tfidf = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
    "        best_index = similarities.argmax()\n",
    "        return db_records[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieval = RetrievalComponent(method='vector')\n",
    "retrieval.fit(db_records)\n",
    "\n",
    "best_matching_record = retrieval.retrieve(query)\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
